{"version":3,"file":"urql-exchange-graphcache.mjs","sources":["../src/helpers/help.ts","../src/ast/node.ts","../src/ast/variables.ts","../src/ast/traversal.ts","../src/ast/schemaPredicates.ts","../src/store/keys.ts","../src/store/data.ts","../src/operations/shared.ts","../src/operations/query.ts","../src/operations/invalidate.ts","../src/operations/write.ts","../src/store/store.ts","../src/ast/schema.ts","../src/helpers/operation.ts","../src/cacheExchange.ts","../src/offlineExchange.ts"],"sourcesContent":["// These are guards that are used throughout the codebase to warn or error on\n// unexpected behaviour or conditions.\n// Every warning and error comes with a number that uniquely identifies them.\n// You can read more about the messages themselves in `docs/graphcache/errors.md`\n\nimport type {\n  ExecutableDefinitionNode,\n  InlineFragmentNode,\n} from '@0no-co/graphql.web';\nimport type { Logger } from '../types';\nimport { Kind } from '@0no-co/graphql.web';\n\nexport type ErrorCode =\n  | 1\n  | 2\n  | 3\n  | 4\n  | 5\n  | 6\n  | 7\n  | 8\n  | 9\n  | 10\n  | 11\n  | 12\n  | 13\n  | 14\n  | 15\n  | 16\n  | 17\n  | 18\n  | 19\n  | 20\n  | 21\n  | 22\n  | 23\n  | 24\n  | 25\n  | 26\n  | 27\n  | 28;\n\ntype DebugNode = ExecutableDefinitionNode | InlineFragmentNode;\n\n// URL unfurls to https://formidable.com/open-source/urql/docs/graphcache/errors/\nconst helpUrl = '\\nhttps://bit.ly/2XbVrpR#';\nconst cache = new Set<string>();\n\nexport const currentDebugStack: string[] = [];\n\nexport const popDebugNode = () => currentDebugStack.pop();\n\nexport const pushDebugNode = (typename: void | string, node: DebugNode) => {\n  let identifier = '';\n  if (node.kind === Kind.INLINE_FRAGMENT) {\n    identifier = typename\n      ? `Inline Fragment on \"${typename}\"`\n      : 'Inline Fragment';\n  } else if (node.kind === Kind.OPERATION_DEFINITION) {\n    const name = node.name ? `\"${node.name.value}\"` : 'Unnamed';\n    identifier = `${name} ${node.operation}`;\n  } else if (node.kind === Kind.FRAGMENT_DEFINITION) {\n    identifier = `\"${node.name.value}\" Fragment`;\n  }\n\n  if (identifier) {\n    currentDebugStack.push(identifier);\n  }\n};\n\nconst getDebugOutput = (): string =>\n  currentDebugStack.length\n    ? '\\n(Caused At: ' + currentDebugStack.join(', ') + ')'\n    : '';\n\nexport function invariant(\n  condition: any,\n  message: string,\n  code: ErrorCode\n): asserts condition {\n  if (!condition) {\n    let errorMessage = message || 'Minfied Error #' + code + '\\n';\n    if (process.env.NODE_ENV !== 'production') {\n      errorMessage += getDebugOutput();\n    }\n\n    const error = new Error(errorMessage + helpUrl + code);\n    error.name = 'Graphcache Error';\n    throw error;\n  }\n}\n\nexport function warn(\n  message: string,\n  code: ErrorCode,\n  logger: Logger | undefined\n) {\n  if (!cache.has(message)) {\n    if (logger) {\n      logger('warn', message + getDebugOutput() + helpUrl + code);\n    } else {\n      console.warn(message + getDebugOutput() + helpUrl + code);\n    }\n    cache.add(message);\n  }\n}\n","import type {\n  NamedTypeNode,\n  NameNode,\n  DirectiveNode,\n  SelectionNode,\n  SelectionSetNode,\n  FieldNode,\n  FragmentDefinitionNode,\n} from '@0no-co/graphql.web';\n\nimport type { FormattedNode } from '@urql/core';\n\nexport type SelectionSet = readonly FormattedNode<SelectionNode>[];\n\nconst EMPTY_DIRECTIVES: Record<string, DirectiveNode | undefined> = {};\n\n/** Returns the directives dictionary of a given node */\nexport const getDirectives = (node: {\n  _directives?: Record<string, DirectiveNode | undefined>;\n}) => node._directives || EMPTY_DIRECTIVES;\n\n/** Returns the name of a given node */\nexport const getName = (node: { name: NameNode }): string => node.name.value;\n\nexport const getFragmentTypeName = (node: FragmentDefinitionNode): string =>\n  node.typeCondition.name.value;\n\n/** Returns either the field's name or the field's alias */\nexport const getFieldAlias = (node: FieldNode): string =>\n  node.alias ? node.alias.value : node.name.value;\n\nconst emptySelectionSet: SelectionSet = [];\n\n/** Returns the SelectionSet for a given inline or defined fragment node */\nexport const getSelectionSet = (node: {\n  selectionSet?: FormattedNode<SelectionSetNode>;\n}): FormattedNode<SelectionSet> =>\n  (node.selectionSet\n    ? node.selectionSet.selections\n    : emptySelectionSet) as FormattedNode<SelectionSet>;\n\nexport const getTypeCondition = (node: {\n  typeCondition?: NamedTypeNode;\n}): string | null =>\n  node.typeCondition ? node.typeCondition.name.value : null;\n","import type {\n  FieldNode,\n  DirectiveNode,\n  OperationDefinitionNode,\n} from '@0no-co/graphql.web';\nimport { valueFromASTUntyped } from '@0no-co/graphql.web';\n\nimport { getName } from './node';\n\nimport type { Variables } from '../types';\n\n/** Evaluates a fields arguments taking vars into account */\nexport const getFieldArguments = (\n  node: FieldNode | DirectiveNode,\n  vars: Variables\n): null | Variables => {\n  let args: null | Variables = null;\n  if (node.arguments) {\n    for (let i = 0, l = node.arguments.length; i < l; i++) {\n      const arg = node.arguments[i];\n      const value = valueFromASTUntyped(arg.value, vars);\n      if (value !== undefined && value !== null) {\n        if (!args) args = {};\n        args[getName(arg)] = value as any;\n      }\n    }\n  }\n  return args;\n};\n\n/** Returns a filtered form of variables with values missing that the query doesn't require */\nexport const filterVariables = (\n  node: OperationDefinitionNode,\n  input: void | object\n) => {\n  if (!input || !node.variableDefinitions) {\n    return undefined;\n  }\n\n  const vars = {};\n  for (let i = 0, l = node.variableDefinitions.length; i < l; i++) {\n    const name = getName(node.variableDefinitions[i].variable);\n    vars[name] = input[name];\n  }\n\n  return vars;\n};\n\n/** Returns a normalized form of variables with defaulted values */\nexport const normalizeVariables = (\n  node: OperationDefinitionNode,\n  input: void | Record<string, unknown>\n): Variables => {\n  const vars = {};\n  if (!input) return vars;\n\n  if (node.variableDefinitions) {\n    for (let i = 0, l = node.variableDefinitions.length; i < l; i++) {\n      const def = node.variableDefinitions[i];\n      const name = getName(def.variable);\n      vars[name] =\n        input[name] === undefined && def.defaultValue\n          ? valueFromASTUntyped(def.defaultValue, input)\n          : input[name];\n    }\n  }\n\n  for (const key in input) {\n    if (!(key in vars)) vars[key] = input[key];\n  }\n\n  return vars;\n};\n","import type {\n  SelectionNode,\n  DocumentNode,\n  OperationDefinitionNode,\n  FragmentSpreadNode,\n  InlineFragmentNode,\n} from '@0no-co/graphql.web';\nimport { valueFromASTUntyped, Kind } from '@0no-co/graphql.web';\n\nimport type { FormattedNode } from '@urql/core';\nimport { getName, getDirectives } from './node';\nimport { invariant } from '../helpers/help';\nimport type { Fragments, Variables } from '../types';\n\nfunction getMainOperation(\n  doc: FormattedNode<DocumentNode>\n): FormattedNode<OperationDefinitionNode>;\nfunction getMainOperation(doc: DocumentNode): OperationDefinitionNode;\n\n/** Returns the main operation's definition */\nfunction getMainOperation(doc: DocumentNode): OperationDefinitionNode {\n  for (let i = 0; i < doc.definitions.length; i++) {\n    if (doc.definitions[i].kind === Kind.OPERATION_DEFINITION) {\n      return doc.definitions[i] as FormattedNode<OperationDefinitionNode>;\n    }\n  }\n\n  invariant(\n    false,\n    'Invalid GraphQL document: All GraphQL documents must contain an OperationDefinition' +\n      'node for a query, subscription, or mutation.',\n    1\n  );\n}\n\nexport { getMainOperation };\n\n/** Returns a mapping from fragment names to their selections */\nexport const getFragments = (doc: FormattedNode<DocumentNode>): Fragments => {\n  const fragments: Fragments = {};\n  for (let i = 0; i < doc.definitions.length; i++) {\n    const node = doc.definitions[i];\n    if (node.kind === Kind.FRAGMENT_DEFINITION) {\n      fragments[getName(node)] = node;\n    }\n  }\n\n  return fragments;\n};\n\n/** Resolves @include and @skip directives to determine whether field is included. */\nexport const shouldInclude = (\n  node: FormattedNode<SelectionNode>,\n  vars: Variables\n): boolean => {\n  const directives = getDirectives(node);\n  if (directives.include || directives.skip) {\n    // Finds any @include or @skip directive that forces the node to be skipped\n    for (const name in directives) {\n      const directive = directives[name];\n      if (\n        directive &&\n        (name === 'include' || name === 'skip') &&\n        directive.arguments &&\n        directive.arguments[0] &&\n        getName(directive.arguments[0]) === 'if'\n      ) {\n        // Return whether this directive forces us to skip\n        // `@include(if: false)` or `@skip(if: true)`\n        const value = valueFromASTUntyped(directive.arguments[0].value, vars);\n        return name === 'include' ? !!value : !value;\n      }\n    }\n  }\n  return true;\n};\n\n/** Resolves @defer directive to determine whether a fragment is potentially skipped. */\nexport const isDeferred = (\n  node: FormattedNode<FragmentSpreadNode | InlineFragmentNode>,\n  vars: Variables\n): boolean => {\n  const { defer } = getDirectives(node);\n  if (defer) {\n    for (const argument of defer.arguments || []) {\n      if (getName(argument) === 'if') {\n        // Return whether `@defer(if: )` is enabled\n        return !!valueFromASTUntyped(argument.value, vars);\n      }\n    }\n    return true;\n  }\n\n  return false;\n};\n\n/** Resolves @_optional and @_required directive to determine whether the fields in a fragment are conaidered optional. */\nexport const isOptional = (\n  node: FormattedNode<FragmentSpreadNode | InlineFragmentNode>\n): boolean | undefined => {\n  const { optional, required } = getDirectives(node);\n  if (required) {\n    return false;\n  }\n\n  if (optional) {\n    return true;\n  }\n\n  return undefined;\n};\n","import type {\n  InlineFragmentNode,\n  FragmentDefinitionNode,\n} from '@0no-co/graphql.web';\n\nimport { warn, invariant } from '../helpers/help';\nimport { getTypeCondition } from './node';\nimport type { SchemaIntrospector, SchemaObject } from './schema';\n\nimport type {\n  KeyingConfig,\n  UpdatesConfig,\n  ResolverConfig,\n  OptimisticMutationConfig,\n  Logger,\n} from '../types';\n\nconst BUILTIN_NAME = '__';\n\nexport const isFieldNullable = (\n  schema: SchemaIntrospector,\n  typename: string,\n  fieldName: string,\n  logger: Logger | undefined\n): boolean => {\n  const field = getField(schema, typename, fieldName, logger);\n  return !!field && field.type.kind !== 'NON_NULL';\n};\n\nexport const isListNullable = (\n  schema: SchemaIntrospector,\n  typename: string,\n  fieldName: string,\n  logger: Logger | undefined\n): boolean => {\n  const field = getField(schema, typename, fieldName, logger);\n  if (!field) return false;\n  const ofType =\n    field.type.kind === 'NON_NULL' ? field.type.ofType : field.type;\n  return ofType.kind === 'LIST' && ofType.ofType.kind !== 'NON_NULL';\n};\n\nexport const isFieldAvailableOnType = (\n  schema: SchemaIntrospector,\n  typename: string,\n  fieldName: string,\n  logger: Logger | undefined\n): boolean =>\n  fieldName.indexOf(BUILTIN_NAME) === 0 ||\n  typename.indexOf(BUILTIN_NAME) === 0 ||\n  !!getField(schema, typename, fieldName, logger);\n\nexport const isInterfaceOfType = (\n  schema: SchemaIntrospector,\n  node: InlineFragmentNode | FragmentDefinitionNode,\n  typename: string | void\n): boolean => {\n  if (!typename) return false;\n  const typeCondition = getTypeCondition(node);\n  if (!typeCondition || typename === typeCondition) {\n    return true;\n  } else if (\n    schema.types!.has(typeCondition) &&\n    schema.types!.get(typeCondition)!.kind === 'OBJECT'\n  ) {\n    return typeCondition === typename;\n  }\n\n  expectAbstractType(schema, typeCondition!);\n  expectObjectType(schema, typename!);\n  return schema.isSubType(typeCondition, typename);\n};\n\nconst getField = (\n  schema: SchemaIntrospector,\n  typename: string,\n  fieldName: string,\n  logger: Logger | undefined\n) => {\n  if (\n    fieldName.indexOf(BUILTIN_NAME) === 0 ||\n    typename.indexOf(BUILTIN_NAME) === 0\n  )\n    return;\n\n  expectObjectType(schema, typename);\n  const object = schema.types!.get(typename) as SchemaObject;\n  const field = object.fields()[fieldName];\n  if (!field) {\n    warn(\n      'Invalid field: The field `' +\n        fieldName +\n        '` does not exist on `' +\n        typename +\n        '`, ' +\n        'but the GraphQL document expects it to exist.\\n' +\n        'Traversal will continue, however this may lead to undefined behavior!',\n      4,\n      logger\n    );\n  }\n\n  return field;\n};\n\nfunction expectObjectType(schema: SchemaIntrospector, typename: string) {\n  invariant(\n    schema.types!.has(typename) &&\n      schema.types!.get(typename)!.kind === 'OBJECT',\n    'Invalid Object type: The type `' +\n      typename +\n      '` is not an object in the defined schema, ' +\n      'but the GraphQL document is traversing it.',\n    3\n  );\n}\n\nfunction expectAbstractType(schema: SchemaIntrospector, typename: string) {\n  invariant(\n    schema.types!.has(typename) &&\n      (schema.types!.get(typename)!.kind === 'INTERFACE' ||\n        schema.types!.get(typename)!.kind === 'UNION'),\n    'Invalid Abstract type: The type `' +\n      typename +\n      '` is not an Interface or Union type in the defined schema, ' +\n      'but a fragment in the GraphQL document is using it as a type condition.',\n    5\n  );\n}\n\nexport function expectValidKeyingConfig(\n  schema: SchemaIntrospector,\n  keys: KeyingConfig,\n  logger: Logger | undefined\n): void {\n  if (process.env.NODE_ENV !== 'production') {\n    for (const key in keys) {\n      if (!schema.types!.has(key)) {\n        warn(\n          'Invalid Object type: The type `' +\n            key +\n            '` is not an object in the defined schema, but the `keys` option is referencing it.',\n          20,\n          logger\n        );\n      }\n    }\n  }\n}\n\nexport function expectValidUpdatesConfig(\n  schema: SchemaIntrospector,\n  updates: UpdatesConfig,\n  logger: Logger | undefined\n): void {\n  if (process.env.NODE_ENV === 'production') {\n    return;\n  }\n\n  for (const typename in updates) {\n    if (!updates[typename]) {\n      continue;\n    } else if (!schema.types!.has(typename)) {\n      let addition = '';\n\n      if (\n        typename === 'Mutation' &&\n        schema.mutation &&\n        schema.mutation !== 'Mutation'\n      ) {\n        addition +=\n          '\\nMaybe your config should reference `' + schema.mutation + '`?';\n      } else if (\n        typename === 'Subscription' &&\n        schema.subscription &&\n        schema.subscription !== 'Subscription'\n      ) {\n        addition +=\n          '\\nMaybe your config should reference `' + schema.subscription + '`?';\n      }\n\n      return warn(\n        'Invalid updates type: The type `' +\n          typename +\n          '` is not an object in the defined schema, but the `updates` config is referencing it.' +\n          addition,\n        21,\n        logger\n      );\n    }\n\n    const fields = (schema.types!.get(typename)! as SchemaObject).fields();\n    for (const fieldName in updates[typename]!) {\n      if (!fields[fieldName]) {\n        warn(\n          'Invalid updates field: `' +\n            fieldName +\n            '` on `' +\n            typename +\n            '` is not in the defined schema, but the `updates` config is referencing it.',\n          22,\n          logger\n        );\n      }\n    }\n  }\n}\n\nfunction warnAboutResolver(name: string, logger: Logger | undefined): void {\n  warn(\n    `Invalid resolver: \\`${name}\\` is not in the defined schema, but the \\`resolvers\\` option is referencing it.`,\n    23,\n    logger\n  );\n}\n\nfunction warnAboutAbstractResolver(\n  name: string,\n  kind: 'UNION' | 'INTERFACE',\n  logger: Logger | undefined\n): void {\n  warn(\n    `Invalid resolver: \\`${name}\\` does not match to a concrete type in the schema, but the \\`resolvers\\` option is referencing it. Implement the resolver for the types that ${\n      kind === 'UNION' ? 'make up the union' : 'implement the interface'\n    } instead.`,\n    26,\n    logger\n  );\n}\n\nexport function expectValidResolversConfig(\n  schema: SchemaIntrospector,\n  resolvers: ResolverConfig,\n  logger: Logger | undefined\n): void {\n  if (process.env.NODE_ENV === 'production') {\n    return;\n  }\n\n  for (const key in resolvers) {\n    if (key === 'Query') {\n      if (schema.query) {\n        const validQueries = (\n          schema.types!.get(schema.query) as SchemaObject\n        ).fields();\n        for (const resolverQuery in resolvers.Query || {}) {\n          if (!validQueries[resolverQuery]) {\n            warnAboutResolver('Query.' + resolverQuery, logger);\n          }\n        }\n      } else {\n        warnAboutResolver('Query', logger);\n      }\n    } else {\n      if (!schema.types!.has(key)) {\n        warnAboutResolver(key, logger);\n      } else if (\n        schema.types!.get(key)!.kind === 'INTERFACE' ||\n        schema.types!.get(key)!.kind === 'UNION'\n      ) {\n        warnAboutAbstractResolver(\n          key,\n          schema.types!.get(key)!.kind as 'INTERFACE' | 'UNION',\n          logger\n        );\n      } else {\n        const validTypeProperties = (\n          schema.types!.get(key) as SchemaObject\n        ).fields();\n        for (const resolverProperty in resolvers[key] || {}) {\n          if (!validTypeProperties[resolverProperty]) {\n            warnAboutResolver(key + '.' + resolverProperty, logger);\n          }\n        }\n      }\n    }\n  }\n}\n\nexport function expectValidOptimisticMutationsConfig(\n  schema: SchemaIntrospector,\n  optimisticMutations: OptimisticMutationConfig,\n  logger: Logger | undefined\n): void {\n  if (process.env.NODE_ENV === 'production') {\n    return;\n  }\n\n  if (schema.mutation) {\n    const validMutations = (\n      schema.types!.get(schema.mutation) as SchemaObject\n    ).fields();\n    for (const mutation in optimisticMutations) {\n      if (!validMutations[mutation]) {\n        warn(\n          `Invalid optimistic mutation field: \\`${mutation}\\` is not a mutation field in the defined schema, but the \\`optimistic\\` option is referencing it.`,\n          24,\n          logger\n        );\n      }\n    }\n  }\n}\n","import { stringifyVariables } from '@urql/core';\nimport type { FieldArgs, FieldInfo, KeyInfo } from '../types';\n\nexport const keyOfField = (fieldName: string, args?: FieldArgs) =>\n  args ? `${fieldName}(${stringifyVariables(args)})` : fieldName;\n\nexport const joinKeys = (parentKey: string, key: string) =>\n  `${parentKey}.${key}`;\n\nexport const fieldInfoOfKey = (fieldKey: string): FieldInfo => {\n  const parenIndex = fieldKey.indexOf('(');\n  if (parenIndex > -1) {\n    return {\n      fieldKey,\n      fieldName: fieldKey.slice(0, parenIndex),\n      arguments: JSON.parse(fieldKey.slice(parenIndex + 1, -1)),\n    };\n  } else {\n    return {\n      fieldKey,\n      fieldName: fieldKey,\n      arguments: null,\n    };\n  }\n};\n\nexport const serializeKeys = (entityKey: string, fieldKey: string) =>\n  `${entityKey.replace(/\\./g, '%2e')}.${fieldKey}`;\n\nexport const deserializeKeyInfo = (key: string): KeyInfo => {\n  const dotIndex = key.indexOf('.');\n  const entityKey = key.slice(0, dotIndex).replace(/%2e/g, '.');\n  const fieldKey = key.slice(dotIndex + 1);\n  return { entityKey, fieldKey };\n};\n","import { stringifyVariables } from '@urql/core';\n\nimport type {\n  Link,\n  EntityField,\n  FieldInfo,\n  StorageAdapter,\n  SerializedEntries,\n  Dependencies,\n  OperationType,\n  DataField,\n  Data,\n} from '../types';\n\nimport {\n  serializeKeys,\n  deserializeKeyInfo,\n  fieldInfoOfKey,\n  joinKeys,\n} from './keys';\n\nimport { invariant, currentDebugStack } from '../helpers/help';\n\ntype Dict<T> = Record<string, T>;\ntype KeyMap<T> = Map<string, T>;\ntype OperationMap<T> = Map<number, T>;\n\ninterface NodeMap<T> {\n  optimistic: OperationMap<KeyMap<Dict<T | undefined>>>;\n  base: KeyMap<Dict<T>>;\n}\n\nexport interface InMemoryData {\n  /** Flag for whether the data is waiting for hydration */\n  hydrating: boolean;\n  /** Flag for whether deferred tasks have been scheduled yet */\n  defer: boolean;\n  /** A list of entities that have been flagged for gargabe collection since no references to them are left */\n  gc: Set<string>;\n  /** A list of entity+field keys that will be persisted */\n  persist: Set<string>;\n  /** The API's \"Query\" typename which is needed to filter dependencies */\n  queryRootKey: string;\n  /** Number of references to each entity (except \"Query\") */\n  refCount: KeyMap<number>;\n  /** A map of entity fields (key-value entries per entity) */\n  records: NodeMap<EntityField>;\n  /** A map of entity links which are connections from one entity to another (key-value entries per entity) */\n  links: NodeMap<Link>;\n  /** A map of typename to a list of entity-keys belonging to said type */\n  types: Map<string, Set<string>>;\n  /** A set of Query operation keys that are in-flight and deferred/streamed */\n  deferredKeys: Set<number>;\n  /** A set of Query operation keys that are in-flight and awaiting a result */\n  commutativeKeys: Set<number>;\n  /** A set of Query operation keys that have been written to */\n  dirtyKeys: Set<number>;\n  /** The order of optimistic layers */\n  optimisticOrder: number[];\n  /** This may be a persistence adapter that will receive changes in a batch */\n  storage: StorageAdapter | null;\n  /** A map of all the types we have encountered that did not map directly to a concrete type */\n  abstractToConcreteMap: Map<string, Set<string>>;\n}\n\nlet currentOwnership: null | WeakSet<any> = null;\nlet currentDataMapping: null | WeakMap<any, any> = null;\nlet currentData: null | InMemoryData = null;\nlet currentOptimisticKey: null | number = null;\nexport let currentOperation: null | OperationType = null;\nexport let currentDependencies: null | Dependencies = null;\nexport let currentForeignData = false;\nexport let currentOptimistic = false;\n\nexport function makeData(data: DataField | void, isArray?: false): Data;\nexport function makeData(data: DataField | void, isArray: true): DataField[];\n\n/** Creates a new data object unless it's been created in this data run */\nexport function makeData(data?: DataField | void, isArray?: boolean) {\n  let newData: Data | Data[] | undefined;\n  if (data) {\n    if (currentOwnership!.has(data)) return data;\n    newData = currentDataMapping!.get(data) as any;\n  }\n\n  if (newData == null) {\n    newData = (isArray ? [] : {}) as any;\n  }\n\n  if (data) {\n    currentDataMapping!.set(data, newData);\n  }\n\n  currentOwnership!.add(newData);\n  return newData;\n}\n\nexport const ownsData = (data?: Data): boolean =>\n  !!data && currentOwnership!.has(data);\n\n/** Before reading or writing the global state needs to be initialised */\nexport const initDataState = (\n  operationType: OperationType,\n  data: InMemoryData,\n  layerKey?: number | null,\n  isOptimistic?: boolean,\n  isForeignData?: boolean\n) => {\n  currentOwnership = new WeakSet();\n  currentDataMapping = new WeakMap();\n  currentOperation = operationType;\n  currentData = data;\n  currentDependencies = new Set();\n  currentOptimistic = !!isOptimistic;\n  currentForeignData = !!isForeignData;\n  if (process.env.NODE_ENV !== 'production') {\n    currentDebugStack.length = 0;\n  }\n\n  if (!layerKey) {\n    currentOptimisticKey = null;\n  } else if (currentOperation === 'read') {\n    // We don't create new layers for read operations and instead simply\n    // apply the currently available layer, if any\n    currentOptimisticKey = layerKey;\n  } else if (\n    isOptimistic ||\n    data.hydrating ||\n    data.optimisticOrder.length > 1\n  ) {\n    // If this operation isn't optimistic and we see it for the first time,\n    // then it must've been optimistic in the past, so we can proactively\n    // clear the optimistic data before writing\n    if (!isOptimistic && !data.commutativeKeys.has(layerKey)) {\n      reserveLayer(data, layerKey);\n    } else if (isOptimistic) {\n      if (\n        data.optimisticOrder.indexOf(layerKey) !== -1 &&\n        !data.commutativeKeys.has(layerKey)\n      ) {\n        data.optimisticOrder.splice(data.optimisticOrder.indexOf(layerKey), 1);\n      }\n      // NOTE: This optimally shouldn't happen as it implies that an optimistic\n      // write is being performed after a concrete write.\n      data.commutativeKeys.delete(layerKey);\n    }\n\n    // An optimistic update of a mutation may force an optimistic layer,\n    // or this Query update may be applied optimistically since it's part\n    // of a commutative chain\n    currentOptimisticKey = layerKey;\n    createLayer(data, layerKey);\n  } else {\n    // Otherwise we don't create an optimistic layer and clear the\n    // operation's one if it already exists\n    // We also do this when only one layer exists to avoid having to squash\n    // any layers at the end of writing this layer\n    currentOptimisticKey = null;\n    deleteLayer(data, layerKey);\n  }\n};\n\n/** Reset the data state after read/write is complete */\nexport const clearDataState = () => {\n  // NOTE: This is only called to check for the invariant to pass\n  if (process.env.NODE_ENV !== 'production') {\n    getCurrentDependencies();\n  }\n\n  const data = currentData!;\n  const layerKey = currentOptimisticKey;\n  currentOptimistic = false;\n  currentOptimisticKey = null;\n\n  // Determine whether the current operation has been a commutative layer\n  if (\n    !data.hydrating &&\n    layerKey &&\n    data.optimisticOrder.indexOf(layerKey) > -1\n  ) {\n    // Squash all layers in reverse order (low priority upwards) that have\n    // been written already\n    let i = data.optimisticOrder.length;\n    while (\n      --i >= 0 &&\n      data.dirtyKeys.has(data.optimisticOrder[i]) &&\n      data.commutativeKeys.has(data.optimisticOrder[i])\n    )\n      squashLayer(data.optimisticOrder[i]);\n  }\n\n  currentOwnership = null;\n  currentDataMapping = null;\n  currentOperation = null;\n  currentData = null;\n  currentDependencies = null;\n  if (process.env.NODE_ENV !== 'production') {\n    currentDebugStack.length = 0;\n  }\n\n  if (process.env.NODE_ENV !== 'test') {\n    // Schedule deferred tasks if we haven't already, and if either a persist or GC run\n    // are likely to be needed\n    if (!data.defer && (data.storage || !data.optimisticOrder.length)) {\n      data.defer = true;\n      setTimeout(() => {\n        initDataState('read', data, null);\n        gc();\n        persistData();\n        clearDataState();\n        data.defer = false;\n      });\n    }\n  }\n};\n\n/** Initialises then resets the data state, which may squash this layer if necessary */\nexport const noopDataState = (\n  data: InMemoryData,\n  layerKey: number | null,\n  isOptimistic?: boolean\n) => {\n  if (layerKey && !isOptimistic) data.deferredKeys.delete(layerKey);\n  initDataState('write', data, layerKey, isOptimistic);\n  clearDataState();\n};\n\n/** As we're writing, we keep around all the records and links we've read or have written to */\nexport const getCurrentDependencies = (): Dependencies => {\n  invariant(\n    currentDependencies !== null,\n    'Invalid Cache call: The cache may only be accessed or mutated during' +\n      'operations like write or query, or as part of its resolvers, updaters, ' +\n      'or optimistic configs.',\n    2\n  );\n\n  return currentDependencies;\n};\n\nconst DEFAULT_EMPTY_SET = new Set<string>();\nexport const make = (queryRootKey: string): InMemoryData => ({\n  hydrating: false,\n  defer: false,\n  gc: new Set(),\n  types: new Map(),\n  persist: new Set(),\n  queryRootKey,\n  refCount: new Map(),\n  links: {\n    optimistic: new Map(),\n    base: new Map(),\n  },\n  abstractToConcreteMap: new Map(),\n  records: {\n    optimistic: new Map(),\n    base: new Map(),\n  },\n  deferredKeys: new Set(),\n  commutativeKeys: new Set(),\n  dirtyKeys: new Set(),\n  optimisticOrder: [],\n  storage: null,\n});\n\n/** Adds a node value to a NodeMap (taking optimistic values into account */\nconst setNode = <T>(\n  map: NodeMap<T>,\n  entityKey: string,\n  fieldKey: string,\n  value: T\n) => {\n  if (process.env.NODE_ENV !== 'production') {\n    invariant(\n      currentOperation !== 'read',\n      'Invalid Cache write: You may not write to the cache during cache reads. ' +\n        ' Accesses to `cache.writeFragment`, `cache.updateQuery`, and `cache.link` may ' +\n        ' not be made inside `resolvers` for instance.',\n      27\n    );\n  }\n\n  // Optimistic values are written to a map in the optimistic dict\n  // All other values are written to the base map\n  const keymap: KeyMap<Dict<T | undefined>> = currentOptimisticKey\n    ? map.optimistic.get(currentOptimisticKey)!\n    : map.base;\n\n  // On the map itself we get or create the entity as a dict\n  let entity = keymap.get(entityKey) as Dict<T | undefined>;\n  if (entity === undefined) {\n    keymap.set(entityKey, (entity = Object.create(null)));\n  }\n\n  // If we're setting undefined we delete the node's entry\n  // On optimistic layers we actually set undefined so it can\n  // override the base value\n  if (value === undefined && !currentOptimisticKey) {\n    delete entity[fieldKey];\n  } else {\n    entity[fieldKey] = value;\n  }\n};\n\n/** Gets a node value from a NodeMap (taking optimistic values into account */\nconst getNode = <T>(\n  map: NodeMap<T>,\n  entityKey: string,\n  fieldKey: string\n): T | undefined => {\n  let node: Dict<T | undefined> | undefined;\n  // A read may be initialised to skip layers until its own, which is useful for\n  // reading back written data. It won't skip over optimistic layers however\n  let skip =\n    !currentOptimistic &&\n    currentOperation === 'read' &&\n    currentOptimisticKey &&\n    currentData!.commutativeKeys.has(currentOptimisticKey);\n  // This first iterates over optimistic layers (in order)\n  for (let i = 0, l = currentData!.optimisticOrder.length; i < l; i++) {\n    const layerKey = currentData!.optimisticOrder[i];\n    const optimistic = map.optimistic.get(layerKey);\n    // If we're reading starting from a specific layer, we skip until a match\n    skip = skip && layerKey !== currentOptimisticKey;\n    // If the node and node value exists it is returned, including undefined\n    if (\n      optimistic &&\n      (!skip || !currentData!.commutativeKeys.has(layerKey)) &&\n      (!currentOptimistic ||\n        currentOperation === 'write' ||\n        currentData!.commutativeKeys.has(layerKey)) &&\n      (node = optimistic.get(entityKey)) !== undefined &&\n      fieldKey in node\n    ) {\n      return node[fieldKey];\n    }\n  }\n\n  // Otherwise we read the non-optimistic base value\n  node = map.base.get(entityKey);\n  return node !== undefined ? node[fieldKey] : undefined;\n};\n\nexport function getRefCount(entityKey: string): number {\n  return currentData!.refCount.get(entityKey) || 0;\n}\n\n/** Adjusts the reference count of an entity on a refCount dict by \"by\" and updates the gc */\nconst updateRCForEntity = (entityKey: string, by: number): void => {\n  // Retrieve the reference count and adjust it by \"by\"\n  const count = getRefCount(entityKey);\n  const newCount = count + by > 0 ? count + by : 0;\n  currentData!.refCount.set(entityKey, newCount);\n  // Add it to the garbage collection batch if it needs to be deleted or remove it\n  // from the batch if it needs to be kept\n  if (!newCount) currentData!.gc.add(entityKey);\n  else if (!count && newCount) currentData!.gc.delete(entityKey);\n};\n\n/** Adjusts the reference counts of all entities of a link on a refCount dict by \"by\" and updates the gc */\nconst updateRCForLink = (link: Link | undefined, by: number): void => {\n  if (Array.isArray(link)) {\n    for (let i = 0, l = link.length; i < l; i++) updateRCForLink(link[i], by);\n  } else if (typeof link === 'string') {\n    updateRCForEntity(link, by);\n  }\n};\n\n/** Writes all parsed FieldInfo objects of a given node dict to a given array if it hasn't been seen */\nconst extractNodeFields = <T>(\n  fieldInfos: FieldInfo[],\n  seenFieldKeys: Set<string>,\n  node: Dict<T> | undefined\n): void => {\n  if (node !== undefined) {\n    for (const fieldKey in node) {\n      if (!seenFieldKeys.has(fieldKey)) {\n        // If the node hasn't been seen the serialized fieldKey is turnt back into\n        // a rich FieldInfo object that also contains the field's name and arguments\n        fieldInfos.push(fieldInfoOfKey(fieldKey));\n        seenFieldKeys.add(fieldKey);\n      }\n    }\n  }\n};\n\n/** Writes all parsed FieldInfo objects of all nodes in a NodeMap to a given array */\nconst extractNodeMapFields = <T>(\n  fieldInfos: FieldInfo[],\n  seenFieldKeys: Set<string>,\n  entityKey: string,\n  map: NodeMap<T>\n) => {\n  // Extracts FieldInfo for the entity in the base map\n  extractNodeFields(fieldInfos, seenFieldKeys, map.base.get(entityKey));\n\n  // Then extracts FieldInfo for the entity from the optimistic maps\n  for (let i = 0, l = currentData!.optimisticOrder.length; i < l; i++) {\n    const optimistic = map.optimistic.get(currentData!.optimisticOrder[i]);\n    if (optimistic !== undefined) {\n      extractNodeFields(fieldInfos, seenFieldKeys, optimistic.get(entityKey));\n    }\n  }\n};\n\n/** Garbage collects all entities that have been marked as having no references */\nexport const gc = () => {\n  // If we're currently awaiting deferred results, abort GC run\n  if (currentData!.optimisticOrder.length) return;\n\n  // Iterate over all entities that have been marked for deletion\n  // Entities have been marked for deletion in `updateRCForEntity` if\n  // their reference count dropped to 0\n  for (const entityKey of currentData!.gc.keys()) {\n    // Remove the current key from the GC batch\n    currentData!.gc.delete(entityKey);\n\n    // Check first whether the entity has any references,\n    // if so, we skip it from the GC run\n    const rc = getRefCount(entityKey);\n    if (rc > 0) continue;\n\n    const record = currentData!.records.base.get(entityKey);\n    // Delete the reference count, and delete the entity from the GC batch\n    currentData!.refCount.delete(entityKey);\n    currentData!.records.base.delete(entityKey);\n\n    const typename = (record && record.__typename) as string | undefined;\n    if (typename) {\n      const type = currentData!.types.get(typename);\n      if (type) type.delete(entityKey);\n    }\n\n    const linkNode = currentData!.links.base.get(entityKey);\n    if (linkNode) {\n      currentData!.links.base.delete(entityKey);\n      for (const fieldKey in linkNode) updateRCForLink(linkNode[fieldKey], -1);\n    }\n  }\n};\n\nconst updateDependencies = (entityKey: string, fieldKey?: string) => {\n  if (entityKey !== currentData!.queryRootKey) {\n    currentDependencies!.add(entityKey);\n  } else if (fieldKey !== undefined && fieldKey !== '__typename') {\n    currentDependencies!.add(joinKeys(entityKey, fieldKey));\n  }\n};\n\nconst updatePersist = (entityKey: string, fieldKey: string) => {\n  if (!currentOptimistic && currentData!.storage) {\n    currentData!.persist.add(serializeKeys(entityKey, fieldKey));\n  }\n};\n\n/** Reads an entity's field (a \"record\") from data */\nexport const readRecord = (\n  entityKey: string,\n  fieldKey: string\n): EntityField => {\n  if (currentOperation === 'read') {\n    updateDependencies(entityKey, fieldKey);\n  }\n  return getNode(currentData!.records, entityKey, fieldKey);\n};\n\n/** Reads an entity's link from data */\nexport const readLink = (\n  entityKey: string,\n  fieldKey: string\n): Link | undefined => {\n  if (currentOperation === 'read') {\n    updateDependencies(entityKey, fieldKey);\n  }\n  return getNode(currentData!.links, entityKey, fieldKey);\n};\n\nexport const getEntitiesForType = (typename: string): Set<string> =>\n  currentData!.types.get(typename) || DEFAULT_EMPTY_SET;\n\nexport const writeType = (typename: string, entityKey: string) => {\n  const existingTypes = currentData!.types.get(typename);\n  if (!existingTypes) {\n    const typeSet = new Set<string>();\n    typeSet.add(entityKey);\n    currentData!.types.set(typename, typeSet);\n  } else {\n    existingTypes.add(entityKey);\n  }\n};\n\nexport const getConcreteTypes = (typename: string): Set<string> =>\n  currentData!.abstractToConcreteMap.get(typename) || DEFAULT_EMPTY_SET;\n\nexport const isSeenConcreteType = (typename: string): boolean =>\n  currentData!.types.has(typename);\n\nexport const writeConcreteType = (\n  abstractType: string,\n  concreteType: string\n) => {\n  const existingTypes = currentData!.abstractToConcreteMap.get(abstractType);\n  if (!existingTypes) {\n    const typeSet = new Set<string>();\n    typeSet.add(concreteType);\n    currentData!.abstractToConcreteMap.set(abstractType, typeSet);\n  } else {\n    existingTypes.add(concreteType);\n  }\n};\n\n/** Writes an entity's field (a \"record\") to data */\nexport const writeRecord = (\n  entityKey: string,\n  fieldKey: string,\n  value?: EntityField\n) => {\n  const existing = getNode(currentData!.records, entityKey, fieldKey);\n  if (!isEqualLinkOrScalar(existing, value)) {\n    updateDependencies(entityKey, fieldKey);\n    updatePersist(entityKey, fieldKey);\n  }\n\n  setNode(currentData!.records, entityKey, fieldKey, value);\n};\n\nexport const hasField = (entityKey: string, fieldKey: string): boolean =>\n  readRecord(entityKey, fieldKey) !== undefined ||\n  readLink(entityKey, fieldKey) !== undefined;\n\n/** Writes an entity's link to data */\nexport const writeLink = (\n  entityKey: string,\n  fieldKey: string,\n  link?: Link | undefined\n) => {\n  // Retrieve the link NodeMap from either an optimistic or the base layer\n  const links = currentOptimisticKey\n    ? currentData!.links.optimistic.get(currentOptimisticKey)\n    : currentData!.links.base;\n  // Update the reference count for the link\n  if (!currentOptimisticKey) {\n    const entityLinks = links && links.get(entityKey);\n    updateRCForLink(entityLinks && entityLinks[fieldKey], -1);\n    updateRCForLink(link, 1);\n  }\n  const existing = getNode(currentData!.links, entityKey, fieldKey);\n  if (!isEqualLinkOrScalar(existing, link)) {\n    updateDependencies(entityKey, fieldKey);\n    updatePersist(entityKey, fieldKey);\n  }\n\n  // Update the link\n  setNode(currentData!.links, entityKey, fieldKey, link);\n};\n\n/** Reserves an optimistic layer and preorders it */\nexport const reserveLayer = (\n  data: InMemoryData,\n  layerKey: number,\n  hasNext?: boolean\n) => {\n  // Find the current index for the layer, and remove it from\n  // the order if it exists already\n  let index = data.optimisticOrder.indexOf(layerKey);\n  if (index > -1) data.optimisticOrder.splice(index, 1);\n\n  if (hasNext) {\n    data.deferredKeys.add(layerKey);\n    // If the layer has future results then we'll move it past any layer that's\n    // still empty, so currently pending operations will take precedence over it\n    for (\n      index = index > -1 ? index : 0;\n      index < data.optimisticOrder.length &&\n      !data.deferredKeys.has(data.optimisticOrder[index]) &&\n      (!data.dirtyKeys.has(data.optimisticOrder[index]) ||\n        !data.commutativeKeys.has(data.optimisticOrder[index]));\n      index++\n    );\n  } else {\n    data.deferredKeys.delete(layerKey);\n    // Protect optimistic layers from being turned into non-optimistic layers\n    // while preserving optimistic data\n    if (index > -1 && !data.commutativeKeys.has(layerKey))\n      clearLayer(data, layerKey);\n    index = 0;\n  }\n\n  // Register the layer with the deferred or \"top\" index and\n  // mark it as commutative\n  data.optimisticOrder.splice(index, 0, layerKey);\n  data.commutativeKeys.add(layerKey);\n};\n\n/** Checks whether a given layer exists */\nexport const hasLayer = (data: InMemoryData, layerKey: number) =>\n  data.commutativeKeys.has(layerKey) ||\n  data.optimisticOrder.indexOf(layerKey) > -1;\n\n/** Creates an optimistic layer of links and records */\nconst createLayer = (data: InMemoryData, layerKey: number) => {\n  if (data.optimisticOrder.indexOf(layerKey) === -1) {\n    data.optimisticOrder.unshift(layerKey);\n  }\n\n  if (!data.dirtyKeys.has(layerKey)) {\n    data.dirtyKeys.add(layerKey);\n    data.links.optimistic.set(layerKey, new Map());\n    data.records.optimistic.set(layerKey, new Map());\n  }\n};\n\n/** Clears all links and records of an optimistic layer */\nconst clearLayer = (data: InMemoryData, layerKey: number) => {\n  if (data.dirtyKeys.has(layerKey)) {\n    data.dirtyKeys.delete(layerKey);\n    data.records.optimistic.delete(layerKey);\n    data.links.optimistic.delete(layerKey);\n    data.deferredKeys.delete(layerKey);\n  }\n};\n\n/** Deletes links and records of an optimistic layer, and the layer itself */\nconst deleteLayer = (data: InMemoryData, layerKey: number) => {\n  const index = data.optimisticOrder.indexOf(layerKey);\n  if (index > -1) {\n    data.optimisticOrder.splice(index, 1);\n    data.commutativeKeys.delete(layerKey);\n  }\n\n  clearLayer(data, layerKey);\n};\n\n/** Merges an optimistic layer of links and records into the base data */\nconst squashLayer = (layerKey: number) => {\n  // Hide current dependencies from squashing operations\n  const previousDependencies = currentDependencies;\n  currentDependencies = new Set();\n  currentOperation = 'write';\n\n  const links = currentData!.links.optimistic.get(layerKey);\n  if (links) {\n    for (const entry of links.entries()) {\n      const entityKey = entry[0];\n      const keyMap = entry[1];\n      for (const fieldKey in keyMap) {\n        writeLink(entityKey, fieldKey, keyMap[fieldKey]);\n      }\n    }\n  }\n\n  const records = currentData!.records.optimistic.get(layerKey);\n  if (records) {\n    for (const entry of records.entries()) {\n      const entityKey = entry[0];\n      const keyMap = entry[1];\n      for (const fieldKey in keyMap) {\n        writeRecord(entityKey, fieldKey, keyMap[fieldKey]);\n      }\n    }\n  }\n\n  currentDependencies = previousDependencies;\n  deleteLayer(currentData!, layerKey);\n};\n\n/** Return an array of FieldInfo (info on all the fields and their arguments) for a given entity */\nexport const inspectFields = (entityKey: string): FieldInfo[] => {\n  const { links, records } = currentData!;\n  const fieldInfos: FieldInfo[] = [];\n  const seenFieldKeys: Set<string> = new Set();\n  // Update dependencies\n  updateDependencies(entityKey);\n  // Extract FieldInfos to the fieldInfos array for links and records\n  // This also deduplicates by keeping track of fieldKeys in the seenFieldKeys Set\n  extractNodeMapFields(fieldInfos, seenFieldKeys, entityKey, links);\n  extractNodeMapFields(fieldInfos, seenFieldKeys, entityKey, records);\n  return fieldInfos;\n};\n\nexport const persistData = () => {\n  if (currentData!.storage) {\n    currentOptimistic = true;\n    currentOperation = 'read';\n    const entries: SerializedEntries = {};\n    for (const key of currentData!.persist.keys()) {\n      const { entityKey, fieldKey } = deserializeKeyInfo(key);\n      let x: void | Link | EntityField;\n      if ((x = readLink(entityKey, fieldKey)) !== undefined) {\n        entries[key] = `:${stringifyVariables(x)}`;\n      } else if ((x = readRecord(entityKey, fieldKey)) !== undefined) {\n        entries[key] = stringifyVariables(x);\n      } else {\n        entries[key] = undefined;\n      }\n    }\n\n    currentOptimistic = false;\n    currentData!.storage.writeData(entries);\n    currentData!.persist.clear();\n  }\n};\n\nexport const hydrateData = (\n  data: InMemoryData,\n  storage: StorageAdapter,\n  entries: SerializedEntries\n) => {\n  initDataState('write', data, null);\n\n  for (const key in entries) {\n    const value = entries[key];\n    if (value !== undefined) {\n      const { entityKey, fieldKey } = deserializeKeyInfo(key);\n      if (value[0] === ':') {\n        if (readLink(entityKey, fieldKey) === undefined)\n          writeLink(entityKey, fieldKey, JSON.parse(value.slice(1)));\n      } else {\n        if (readRecord(entityKey, fieldKey) === undefined)\n          writeRecord(entityKey, fieldKey, JSON.parse(value));\n      }\n    }\n  }\n\n  data.storage = storage;\n  data.hydrating = false;\n  clearDataState();\n};\n\nfunction isEqualLinkOrScalar(\n  a: Link | EntityField | undefined,\n  b: Link | EntityField | undefined\n) {\n  if (typeof a !== typeof b) return false;\n  if (a !== b) return false;\n  if (Array.isArray(a) && Array.isArray(b)) {\n    if (a.length !== b.length) return false;\n    return !a.some((el, index) => el !== b[index]);\n  }\n\n  return true;\n}\n","import type { CombinedError, ErrorLike, FormattedNode } from '@urql/core';\n\nimport type {\n  InlineFragmentNode,\n  FragmentDefinitionNode,\n} from '@0no-co/graphql.web';\nimport { Kind } from '@0no-co/graphql.web';\n\nimport type { SelectionSet } from '../ast';\nimport {\n  isDeferred,\n  getTypeCondition,\n  getSelectionSet,\n  getName,\n  isOptional,\n} from '../ast';\n\nimport { warn, pushDebugNode, popDebugNode } from '../helpers/help';\nimport {\n  hasField,\n  currentOperation,\n  currentOptimistic,\n  writeConcreteType,\n  getConcreteTypes,\n  isSeenConcreteType,\n} from '../store/data';\nimport { keyOfField } from '../store/keys';\nimport type { Store } from '../store/store';\n\nimport { getFieldArguments, shouldInclude, isInterfaceOfType } from '../ast';\n\nimport type {\n  Fragments,\n  Variables,\n  DataField,\n  NullArray,\n  Link,\n  Entity,\n  Data,\n  Logger,\n} from '../types';\n\nexport interface Context {\n  store: Store;\n  variables: Variables;\n  fragments: Fragments;\n  parentTypeName: string;\n  parentKey: string;\n  parentFieldKey: string;\n  parent: Data;\n  fieldName: string;\n  error: ErrorLike | undefined;\n  partial: boolean;\n  hasNext: boolean;\n  optimistic: boolean;\n  __internal: {\n    path: Array<string | number>;\n    errorMap: { [path: string]: ErrorLike } | undefined;\n  };\n}\n\nexport let contextRef: Context | null = null;\nexport let deferRef = false;\nexport let optionalRef: boolean | undefined = undefined;\n\n// Checks whether the current data field is a cache miss because of a GraphQLError\nexport const getFieldError = (ctx: Context): ErrorLike | undefined =>\n  ctx.__internal.path.length > 0 && ctx.__internal.errorMap\n    ? ctx.__internal.errorMap[ctx.__internal.path.join('.')]\n    : undefined;\n\nexport const makeContext = (\n  store: Store,\n  variables: Variables,\n  fragments: Fragments,\n  typename: string,\n  entityKey: string,\n  error: CombinedError | undefined\n): Context => {\n  const ctx: Context = {\n    store,\n    variables,\n    fragments,\n    parent: { __typename: typename },\n    parentTypeName: typename,\n    parentKey: entityKey,\n    parentFieldKey: '',\n    fieldName: '',\n    error: undefined,\n    partial: false,\n    hasNext: false,\n    optimistic: currentOptimistic,\n    __internal: {\n      path: [],\n      errorMap: undefined,\n    },\n  };\n\n  if (error && error.graphQLErrors) {\n    for (let i = 0; i < error.graphQLErrors.length; i++) {\n      const graphQLError = error.graphQLErrors[i];\n      if (graphQLError.path && graphQLError.path.length) {\n        if (!ctx.__internal.errorMap)\n          ctx.__internal.errorMap = Object.create(null);\n        ctx.__internal.errorMap![graphQLError.path.join('.')] = graphQLError;\n      }\n    }\n  }\n\n  return ctx;\n};\n\nexport const updateContext = (\n  ctx: Context,\n  data: Data,\n  typename: string,\n  entityKey: string,\n  fieldKey: string,\n  fieldName: string\n) => {\n  contextRef = ctx;\n  ctx.parent = data;\n  ctx.parentTypeName = typename;\n  ctx.parentKey = entityKey;\n  ctx.parentFieldKey = fieldKey;\n  ctx.fieldName = fieldName;\n  ctx.error = getFieldError(ctx);\n};\n\nconst isFragmentHeuristicallyMatching = (\n  node: FormattedNode<InlineFragmentNode | FragmentDefinitionNode>,\n  typename: void | string,\n  entityKey: string,\n  vars: Variables,\n  logger?: Logger\n) => {\n  if (!typename) return false;\n  const typeCondition = getTypeCondition(node);\n  if (!typeCondition || typename === typeCondition) return true;\n\n  warn(\n    'Heuristic Fragment Matching: A fragment is trying to match against the `' +\n      typename +\n      '` type, ' +\n      'but the type condition is `' +\n      typeCondition +\n      '`. Since GraphQL allows for interfaces `' +\n      typeCondition +\n      '` may be an ' +\n      'interface.\\nA schema needs to be defined for this match to be deterministic, ' +\n      'otherwise the fragment will be matched heuristically!',\n    16,\n    logger\n  );\n\n  return !getSelectionSet(node).some(node => {\n    if (node.kind !== Kind.FIELD) return false;\n    const fieldKey = keyOfField(getName(node), getFieldArguments(node, vars));\n    return !hasField(entityKey, fieldKey);\n  });\n};\n\nexport class SelectionIterator {\n  typename: undefined | string;\n  entityKey: string;\n  ctx: Context;\n  stack: {\n    selectionSet: FormattedNode<SelectionSet>;\n    index: number;\n    defer: boolean;\n    optional: boolean | undefined;\n  }[];\n\n  // NOTE: Outside of this file, we expect `_defer` to always be reset to `false`\n  constructor(\n    typename: undefined | string,\n    entityKey: string,\n    _defer: false,\n    _optional: undefined,\n    selectionSet: FormattedNode<SelectionSet>,\n    ctx: Context\n  );\n  // NOTE: Inside this file we expect the state to be recursively passed on\n  constructor(\n    typename: undefined | string,\n    entityKey: string,\n    _defer: boolean,\n    _optional: undefined | boolean,\n    selectionSet: FormattedNode<SelectionSet>,\n    ctx: Context\n  );\n\n  constructor(\n    typename: undefined | string,\n    entityKey: string,\n    _defer: boolean,\n    _optional: boolean | undefined,\n    selectionSet: FormattedNode<SelectionSet>,\n    ctx: Context\n  ) {\n    this.typename = typename;\n    this.entityKey = entityKey;\n    this.ctx = ctx;\n    this.stack = [\n      {\n        selectionSet,\n        index: 0,\n        defer: _defer,\n        optional: _optional,\n      },\n    ];\n  }\n\n  next() {\n    while (this.stack.length > 0) {\n      let state = this.stack[this.stack.length - 1];\n      while (state.index < state.selectionSet.length) {\n        const select = state.selectionSet[state.index++];\n        if (!shouldInclude(select, this.ctx.variables)) {\n          /*noop*/\n        } else if (select.kind !== Kind.FIELD) {\n          // A fragment is either referred to by FragmentSpread or inline\n          const fragment =\n            select.kind !== Kind.INLINE_FRAGMENT\n              ? this.ctx.fragments[getName(select)]\n              : select;\n          if (fragment) {\n            const isMatching =\n              !fragment.typeCondition ||\n              (this.ctx.store.schema\n                ? isInterfaceOfType(\n                    this.ctx.store.schema,\n                    fragment,\n                    this.typename\n                  )\n                : (currentOperation === 'read' &&\n                    isFragmentMatching(\n                      fragment.typeCondition.name.value,\n                      this.typename\n                    )) ||\n                  isFragmentHeuristicallyMatching(\n                    fragment,\n                    this.typename,\n                    this.entityKey,\n                    this.ctx.variables,\n                    this.ctx.store.logger\n                  ));\n            if (\n              isMatching ||\n              (currentOperation === 'write' && !this.ctx.store.schema)\n            ) {\n              if (process.env.NODE_ENV !== 'production')\n                pushDebugNode(this.typename, fragment);\n              const isFragmentOptional = isOptional(select);\n              if (\n                isMatching &&\n                fragment.typeCondition &&\n                this.typename !== fragment.typeCondition.name.value\n              ) {\n                writeConcreteType(\n                  fragment.typeCondition.name.value,\n                  this.typename!\n                );\n              }\n\n              this.stack.push(\n                (state = {\n                  selectionSet: getSelectionSet(fragment),\n                  index: 0,\n                  defer: state.defer || isDeferred(select, this.ctx.variables),\n                  optional:\n                    isFragmentOptional !== undefined\n                      ? isFragmentOptional\n                      : state.optional,\n                })\n              );\n            }\n          }\n        } else if (currentOperation === 'write' || !select._generated) {\n          deferRef = state.defer;\n          optionalRef = state.optional;\n          return select;\n        }\n      }\n      this.stack.pop();\n      if (process.env.NODE_ENV !== 'production') popDebugNode();\n    }\n    return undefined;\n  }\n}\n\nconst isFragmentMatching = (typeCondition: string, typename: string | void) => {\n  if (!typename) return false;\n  if (typeCondition === typename) return true;\n\n  const isProbableAbstractType = !isSeenConcreteType(typeCondition);\n  if (!isProbableAbstractType) return false;\n\n  const types = getConcreteTypes(typeCondition);\n  return types.size && types.has(typename);\n};\n\nexport const ensureData = (x: DataField): Data | NullArray<Data> | null =>\n  x == null ? null : (x as Data | NullArray<Data>);\n\nexport const ensureLink = (store: Store, ref: Link<Entity>): Link => {\n  if (!ref) {\n    return ref || null;\n  } else if (Array.isArray(ref)) {\n    const link = new Array(ref.length);\n    for (let i = 0, l = link.length; i < l; i++)\n      link[i] = ensureLink(store, ref[i]);\n    return link;\n  }\n\n  const link = store.keyOfEntity(ref);\n  if (!link && ref && typeof ref === 'object') {\n    warn(\n      \"Can't generate a key for link(...) item.\" +\n        '\\nYou have to pass an `id` or `_id` field or create a custom `keys` config for `' +\n        ref.__typename +\n        '`.',\n      12,\n      store.logger\n    );\n  }\n\n  return link;\n};\n","import type { FormattedNode, CombinedError } from '@urql/core';\nimport { formatDocument } from '@urql/core';\n\nimport type {\n  FieldNode,\n  DocumentNode,\n  FragmentDefinitionNode,\n} from '@0no-co/graphql.web';\n\nimport type { SelectionSet } from '../ast';\nimport {\n  getSelectionSet,\n  getName,\n  getFragmentTypeName,\n  getFieldAlias,\n  getFragments,\n  getMainOperation,\n  normalizeVariables,\n  getFieldArguments,\n  getDirectives,\n} from '../ast';\n\nimport type {\n  Variables,\n  Data,\n  DataField,\n  Link,\n  OperationRequest,\n  Dependencies,\n  Resolver,\n} from '../types';\n\nimport { joinKeys, keyOfField } from '../store/keys';\nimport type { Store } from '../store/store';\nimport * as InMemoryData from '../store/data';\nimport { warn, pushDebugNode, popDebugNode } from '../helpers/help';\n\nimport type { Context } from './shared';\nimport {\n  SelectionIterator,\n  ensureData,\n  makeContext,\n  updateContext,\n  getFieldError,\n  deferRef,\n  optionalRef,\n} from './shared';\n\nimport {\n  isFieldAvailableOnType,\n  isFieldNullable,\n  isListNullable,\n} from '../ast';\n\nexport interface QueryResult {\n  dependencies: Dependencies;\n  partial: boolean;\n  hasNext: boolean;\n  data: null | Data;\n}\n\n/** Reads a GraphQL query from the cache.\n * @internal\n */\nexport const __initAnd_query = (\n  store: Store,\n  request: OperationRequest,\n  data?: Data | null | undefined,\n  error?: CombinedError | undefined,\n  key?: number\n): QueryResult => {\n  InMemoryData.initDataState('read', store.data, key);\n  const result = _query(store, request, data, error);\n  InMemoryData.clearDataState();\n  return result;\n};\n\n/** Reads a GraphQL query from the cache.\n * @internal\n */\nexport const _query = (\n  store: Store,\n  request: OperationRequest,\n  input?: Data | null | undefined,\n  error?: CombinedError | undefined\n): QueryResult => {\n  const query = formatDocument(request.query);\n  const operation = getMainOperation(query);\n  const rootKey = store.rootFields[operation.operation];\n  const rootSelect = getSelectionSet(operation);\n\n  const ctx = makeContext(\n    store,\n    normalizeVariables(operation, request.variables),\n    getFragments(query),\n    rootKey,\n    rootKey,\n    error\n  );\n\n  if (process.env.NODE_ENV !== 'production') {\n    pushDebugNode(rootKey, operation);\n  }\n\n  // NOTE: This may reuse \"previous result data\" as indicated by the\n  // `originalData` argument in readRoot(). This behaviour isn't used\n  // for readSelection() however, which always produces results from\n  // scratch\n  const data =\n    rootKey !== ctx.store.rootFields['query']\n      ? readRoot(ctx, rootKey, rootSelect, input || InMemoryData.makeData())\n      : readSelection(\n          ctx,\n          rootKey,\n          rootSelect,\n          input || InMemoryData.makeData()\n        );\n\n  if (process.env.NODE_ENV !== 'production') {\n    popDebugNode();\n    InMemoryData.getCurrentDependencies();\n  }\n\n  return {\n    dependencies: InMemoryData.currentDependencies!,\n    partial: ctx.partial || !data,\n    hasNext: ctx.hasNext,\n    data: data || null,\n  };\n};\n\nconst readRoot = (\n  ctx: Context,\n  entityKey: string,\n  select: FormattedNode<SelectionSet>,\n  input: Data\n): Data => {\n  const typename = ctx.store.rootNames[entityKey]\n    ? entityKey\n    : input.__typename;\n  if (typeof typename !== 'string') {\n    return input;\n  }\n\n  const selection = new SelectionIterator(\n    entityKey,\n    entityKey,\n    false,\n    undefined,\n    select,\n    ctx\n  );\n\n  let node: FormattedNode<FieldNode> | void;\n  let hasChanged = InMemoryData.currentForeignData;\n  const output = InMemoryData.makeData(input);\n  while ((node = selection.next())) {\n    const fieldAlias = getFieldAlias(node);\n    const fieldValue = input[fieldAlias];\n    // Add the current alias to the walked path before processing the field's value\n    ctx.__internal.path.push(fieldAlias);\n    // We temporarily store the data field in here, but undefined\n    // means that the value is missing from the cache\n    let dataFieldValue: void | DataField;\n    if (node.selectionSet && fieldValue !== null) {\n      dataFieldValue = readRootField(\n        ctx,\n        getSelectionSet(node),\n        ensureData(fieldValue)\n      );\n    } else {\n      dataFieldValue = fieldValue;\n    }\n\n    // Check for any referential changes in the field's value\n    hasChanged = hasChanged || dataFieldValue !== fieldValue;\n    if (dataFieldValue !== undefined) output[fieldAlias] = dataFieldValue!;\n\n    // After processing the field, remove the current alias from the path again\n    ctx.__internal.path.pop();\n  }\n\n  return hasChanged ? output : input;\n};\n\nconst readRootField = (\n  ctx: Context,\n  select: FormattedNode<SelectionSet>,\n  originalData: Link<Data>\n): Link<Data> => {\n  if (Array.isArray(originalData)) {\n    const newData = new Array(originalData.length);\n    let hasChanged = InMemoryData.currentForeignData;\n    for (let i = 0, l = originalData.length; i < l; i++) {\n      // Add the current index to the walked path before reading the field's value\n      ctx.__internal.path.push(i);\n      // Recursively read the root field's value\n      newData[i] = readRootField(ctx, select, originalData[i]);\n      hasChanged = hasChanged || newData[i] !== originalData[i];\n      // After processing the field, remove the current index from the path\n      ctx.__internal.path.pop();\n    }\n\n    return hasChanged ? newData : originalData;\n  } else if (originalData === null) {\n    return null;\n  }\n\n  // Write entity to key that falls back to the given parentFieldKey\n  const entityKey = ctx.store.keyOfEntity(originalData);\n  if (entityKey !== null) {\n    // We assume that since this is used for result data this can never be undefined,\n    // since the result data has already been written to the cache\n    return readSelection(ctx, entityKey, select, originalData) || null;\n  } else {\n    return readRoot(ctx, originalData.__typename, select, originalData);\n  }\n};\n\nexport const _queryFragment = (\n  store: Store,\n  query: FormattedNode<DocumentNode>,\n  entity: Partial<Data> | string,\n  variables?: Variables,\n  fragmentName?: string\n): Data | null => {\n  const fragments = getFragments(query);\n\n  let fragment: FormattedNode<FragmentDefinitionNode>;\n  if (fragmentName) {\n    fragment = fragments[fragmentName]!;\n    if (!fragment) {\n      warn(\n        'readFragment(...) was called with a fragment name that does not exist.\\n' +\n          'You provided ' +\n          fragmentName +\n          ' but could only find ' +\n          Object.keys(fragments).join(', ') +\n          '.',\n        6,\n        store.logger\n      );\n\n      return null;\n    }\n  } else {\n    const names = Object.keys(fragments);\n    fragment = fragments[names[0]]!;\n    if (!fragment) {\n      warn(\n        'readFragment(...) was called with an empty fragment.\\n' +\n          'You have to call it with at least one fragment in your GraphQL document.',\n        6,\n        store.logger\n      );\n\n      return null;\n    }\n  }\n\n  const typename = getFragmentTypeName(fragment);\n  if (typeof entity !== 'string' && !entity.__typename)\n    entity.__typename = typename;\n  const entityKey = store.keyOfEntity(entity as Data);\n  if (!entityKey) {\n    warn(\n      \"Can't generate a key for readFragment(...).\\n\" +\n        'You have to pass an `id` or `_id` field or create a custom `keys` config for `' +\n        typename +\n        '`.',\n      7,\n      store.logger\n    );\n\n    return null;\n  }\n\n  if (process.env.NODE_ENV !== 'production') {\n    pushDebugNode(typename, fragment);\n  }\n\n  const ctx = makeContext(\n    store,\n    variables || {},\n    fragments,\n    typename,\n    entityKey,\n    undefined\n  );\n\n  const result =\n    readSelection(\n      ctx,\n      entityKey,\n      getSelectionSet(fragment),\n      InMemoryData.makeData()\n    ) || null;\n\n  if (process.env.NODE_ENV !== 'production') {\n    popDebugNode();\n  }\n\n  return result;\n};\n\nfunction getFieldResolver(\n  directives: ReturnType<typeof getDirectives>,\n  typename: string,\n  fieldName: string,\n  ctx: Context\n): Resolver | void {\n  const resolvers = ctx.store.resolvers[typename];\n  const fieldResolver = resolvers && resolvers[fieldName];\n\n  let directiveResolver: Resolver | undefined;\n  for (const name in directives) {\n    const directiveNode = directives[name];\n    if (\n      directiveNode &&\n      name !== 'include' &&\n      name !== 'skip' &&\n      ctx.store.directives[name]\n    ) {\n      directiveResolver = ctx.store.directives[name](\n        getFieldArguments(directiveNode, ctx.variables)\n      );\n      if (process.env.NODE_ENV === 'production') return directiveResolver;\n      break;\n    }\n  }\n\n  if (fieldResolver && directiveResolver) {\n    warn(\n      `A resolver and directive is being used at \"${typename}.${fieldName}\" simultaneously. Only the directive will apply.`,\n      28,\n      ctx.store.logger\n    );\n  }\n\n  return directiveResolver || fieldResolver;\n}\n\nconst readSelection = (\n  ctx: Context,\n  key: string,\n  select: FormattedNode<SelectionSet>,\n  input: Data,\n  result?: Data\n): Data | undefined => {\n  const { store } = ctx;\n  const isQuery = key === store.rootFields.query;\n\n  const entityKey = (result && store.keyOfEntity(result)) || key;\n  if (!isQuery && !!ctx.store.rootNames[entityKey]) {\n    warn(\n      'Invalid root traversal: A selection was being read on `' +\n        entityKey +\n        '` which is an uncached root type.\\n' +\n        'The `' +\n        ctx.store.rootFields.mutation +\n        '` and `' +\n        ctx.store.rootFields.subscription +\n        '` types are special ' +\n        'Operation Root Types and cannot be read back from the cache.',\n      25,\n      store.logger\n    );\n  }\n\n  const typename = !isQuery\n    ? InMemoryData.readRecord(entityKey, '__typename') ||\n      (result && result.__typename)\n    : key;\n\n  if (typeof typename !== 'string') {\n    return;\n  } else if (result && typename !== result.__typename) {\n    warn(\n      'Invalid resolver data: The resolver at `' +\n        entityKey +\n        '` returned an ' +\n        'invalid typename that could not be reconciled with the cache.',\n      8,\n      store.logger\n    );\n\n    return;\n  }\n\n  const selection = new SelectionIterator(\n    typename,\n    entityKey,\n    false,\n    undefined,\n    select,\n    ctx\n  );\n\n  let hasFields = false;\n  let hasNext = false;\n  let hasChanged = InMemoryData.currentForeignData;\n  let node: FormattedNode<FieldNode> | void;\n  const hasPartials = ctx.partial;\n  const output = InMemoryData.makeData(input);\n  while ((node = selection.next()) !== undefined) {\n    // Derive the needed data from our node.\n    const fieldName = getName(node);\n    const fieldArgs = getFieldArguments(node, ctx.variables);\n    const fieldAlias = getFieldAlias(node);\n    const directives = getDirectives(node);\n    const resolver = getFieldResolver(directives, typename, fieldName, ctx);\n    const fieldKey = keyOfField(fieldName, fieldArgs);\n    const key = joinKeys(entityKey, fieldKey);\n    const fieldValue = InMemoryData.readRecord(entityKey, fieldKey);\n    const resultValue = result ? result[fieldName] : undefined;\n\n    if (process.env.NODE_ENV !== 'production' && store.schema && typename) {\n      isFieldAvailableOnType(\n        store.schema,\n        typename,\n        fieldName,\n        ctx.store.logger\n      );\n    }\n\n    // Add the current alias to the walked path before processing the field's value\n    ctx.__internal.path.push(fieldAlias);\n    // We temporarily store the data field in here, but undefined\n    // means that the value is missing from the cache\n    let dataFieldValue: void | DataField = undefined;\n\n    if (fieldName === '__typename') {\n      // We directly assign the typename as it's already available\n      dataFieldValue = typename;\n    } else if (resultValue !== undefined && node.selectionSet === undefined) {\n      // The field is a scalar and can be retrieved directly from the result\n      dataFieldValue = resultValue;\n    } else if (InMemoryData.currentOperation === 'read' && resolver) {\n      // We have a resolver for this field.\n      // Prepare the actual fieldValue, so that the resolver can use it,\n      // as to avoid the user having to do `cache.resolve(parent, info.fieldKey)`\n      // only to get a scalar value.\n      let parent = output;\n      if (node.selectionSet === undefined && fieldValue !== undefined) {\n        parent = {\n          ...output,\n          [fieldAlias]: fieldValue,\n          [fieldName]: fieldValue,\n        };\n      }\n\n      // We have to update the information in context to reflect the info\n      // that the resolver will receive\n      updateContext(ctx, parent, typename, entityKey, fieldKey, fieldName);\n\n      dataFieldValue = resolver(\n        parent,\n        fieldArgs || ({} as Variables),\n        store,\n        ctx\n      );\n\n      if (node.selectionSet) {\n        // When it has a selection set we are resolving an entity with a\n        // subselection. This can either be a list or an object.\n        dataFieldValue = resolveResolverResult(\n          ctx,\n          typename,\n          fieldName,\n          key,\n          getSelectionSet(node),\n          (output[fieldAlias] !== undefined\n            ? output[fieldAlias]\n            : input[fieldAlias]) as Data,\n          dataFieldValue,\n          InMemoryData.ownsData(input)\n        );\n      }\n\n      if (\n        store.schema &&\n        dataFieldValue === null &&\n        !isFieldNullable(store.schema, typename, fieldName, ctx.store.logger)\n      ) {\n        // Special case for when null is not a valid value for the\n        // current field\n        return undefined;\n      }\n    } else if (!node.selectionSet) {\n      // The field is a scalar but isn't on the result, so it's retrieved from the cache\n      dataFieldValue = fieldValue;\n    } else if (resultValue !== undefined) {\n      // We start walking the nested resolver result here\n      dataFieldValue = resolveResolverResult(\n        ctx,\n        typename,\n        fieldName,\n        key,\n        getSelectionSet(node),\n        (output[fieldAlias] !== undefined\n          ? output[fieldAlias]\n          : input[fieldAlias]) as Data,\n        resultValue,\n        InMemoryData.ownsData(input)\n      );\n    } else {\n      // Otherwise we attempt to get the missing field from the cache\n      const link = InMemoryData.readLink(entityKey, fieldKey);\n\n      if (link !== undefined) {\n        dataFieldValue = resolveLink(\n          ctx,\n          link,\n          typename,\n          fieldName,\n          getSelectionSet(node),\n          (output[fieldAlias] !== undefined\n            ? output[fieldAlias]\n            : input[fieldAlias]) as Data,\n          InMemoryData.ownsData(input)\n        );\n      } else if (typeof fieldValue === 'object' && fieldValue !== null) {\n        // The entity on the field was invalid but can still be recovered\n        dataFieldValue = fieldValue;\n      }\n    }\n\n    // Now that dataFieldValue has been retrieved it'll be set on data\n    // If it's uncached (undefined) but nullable we can continue assembling\n    // a partial query result\n    if (\n      !deferRef &&\n      dataFieldValue === undefined &&\n      (directives.optional ||\n        (optionalRef && !directives.required) ||\n        !!getFieldError(ctx) ||\n        (!directives.required &&\n          store.schema &&\n          isFieldNullable(store.schema, typename, fieldName, ctx.store.logger)))\n    ) {\n      // The field is uncached or has errored, so it'll be set to null and skipped\n      ctx.partial = true;\n      dataFieldValue = null;\n    } else if (\n      dataFieldValue === null &&\n      (directives.required || optionalRef === false)\n    ) {\n      if (\n        ctx.store.logger &&\n        process.env.NODE_ENV !== 'production' &&\n        InMemoryData.currentOperation === 'read'\n      ) {\n        ctx.store.logger(\n          'debug',\n          `Got value \"null\" for required field \"${fieldName}\"${\n            fieldArgs ? ` with args ${JSON.stringify(fieldArgs)}` : ''\n          } on entity \"${entityKey}\"`\n        );\n      }\n      dataFieldValue = undefined;\n    } else {\n      hasFields = hasFields || fieldName !== '__typename';\n    }\n\n    // After processing the field, remove the current alias from the path again\n    ctx.__internal.path.pop();\n    // Check for any referential changes in the field's value\n    hasChanged = hasChanged || dataFieldValue !== input[fieldAlias];\n    if (dataFieldValue !== undefined) {\n      output[fieldAlias] = dataFieldValue;\n    } else if (deferRef) {\n      hasNext = true;\n    } else {\n      if (\n        ctx.store.logger &&\n        process.env.NODE_ENV !== 'production' &&\n        InMemoryData.currentOperation === 'read'\n      ) {\n        ctx.store.logger(\n          'debug',\n          `No value for field \"${fieldName}\"${\n            fieldArgs ? ` with args ${JSON.stringify(fieldArgs)}` : ''\n          } on entity \"${entityKey}\"`\n        );\n      }\n      // If the field isn't deferred or partial then we have to abort and also reset\n      // the partial field\n      ctx.partial = hasPartials;\n      return undefined;\n    }\n  }\n\n  ctx.partial = ctx.partial || hasPartials;\n  ctx.hasNext = ctx.hasNext || hasNext;\n  return isQuery && ctx.partial && !hasFields\n    ? undefined\n    : hasChanged\n      ? output\n      : input;\n};\n\nconst resolveResolverResult = (\n  ctx: Context,\n  typename: string,\n  fieldName: string,\n  key: string,\n  select: FormattedNode<SelectionSet>,\n  prevData: void | null | Data | Data[],\n  result: void | DataField,\n  isOwnedData: boolean\n): DataField | void => {\n  if (Array.isArray(result)) {\n    const { store } = ctx;\n    // Check whether values of the list may be null; for resolvers we assume\n    // that they can be, since it's user-provided data\n    const _isListNullable = store.schema\n      ? isListNullable(store.schema, typename, fieldName, ctx.store.logger)\n      : false;\n    const hasPartials = ctx.partial;\n    const data = InMemoryData.makeData(prevData, true);\n    let hasChanged =\n      InMemoryData.currentForeignData ||\n      !Array.isArray(prevData) ||\n      result.length !== prevData.length;\n    for (let i = 0, l = result.length; i < l; i++) {\n      // Add the current index to the walked path before reading the field's value\n      ctx.__internal.path.push(i);\n      // Recursively read resolver result\n      const childResult = resolveResolverResult(\n        ctx,\n        typename,\n        fieldName,\n        joinKeys(key, `${i}`),\n        select,\n        prevData != null ? prevData[i] : undefined,\n        result[i],\n        isOwnedData\n      );\n      // After processing the field, remove the current index from the path\n      ctx.__internal.path.pop();\n      // Check the result for cache-missed values\n      if (childResult === undefined && !_isListNullable) {\n        ctx.partial = hasPartials;\n        return undefined;\n      } else {\n        ctx.partial =\n          ctx.partial || (childResult === undefined && _isListNullable);\n        data[i] = childResult != null ? childResult : null;\n        hasChanged = hasChanged || data[i] !== prevData![i];\n      }\n    }\n\n    return hasChanged ? data : prevData;\n  } else if (result === null || result === undefined) {\n    return result;\n  } else if (isOwnedData && prevData === null) {\n    return null;\n  } else if (isDataOrKey(result)) {\n    const data = (prevData || InMemoryData.makeData(prevData)) as Data;\n    return typeof result === 'string'\n      ? readSelection(ctx, result, select, data)\n      : readSelection(ctx, key, select, data, result);\n  } else {\n    warn(\n      'Invalid resolver value: The field at `' +\n        key +\n        '` is a scalar (number, boolean, etc)' +\n        ', but the GraphQL query expects a selection set for this field.',\n      9,\n      ctx.store.logger\n    );\n\n    return undefined;\n  }\n};\n\nconst resolveLink = (\n  ctx: Context,\n  link: Link | Link[],\n  typename: string,\n  fieldName: string,\n  select: FormattedNode<SelectionSet>,\n  prevData: void | null | Data | Data[],\n  isOwnedData: boolean\n): DataField | undefined => {\n  if (Array.isArray(link)) {\n    const { store } = ctx;\n    const _isListNullable = store.schema\n      ? isListNullable(store.schema, typename, fieldName, ctx.store.logger)\n      : false;\n    const newLink = InMemoryData.makeData(prevData, true);\n    const hasPartials = ctx.partial;\n    let hasChanged =\n      InMemoryData.currentForeignData ||\n      !Array.isArray(prevData) ||\n      link.length !== prevData.length;\n    for (let i = 0, l = link.length; i < l; i++) {\n      // Add the current index to the walked path before reading the field's value\n      ctx.__internal.path.push(i);\n      // Recursively read the link\n      const childLink = resolveLink(\n        ctx,\n        link[i],\n        typename,\n        fieldName,\n        select,\n        prevData != null ? prevData[i] : undefined,\n        isOwnedData\n      );\n      // After processing the field, remove the current index from the path\n      ctx.__internal.path.pop();\n      // Check the result for cache-missed values\n      if (childLink === undefined && !_isListNullable) {\n        ctx.partial = hasPartials;\n        return undefined;\n      } else {\n        ctx.partial =\n          ctx.partial || (childLink === undefined && _isListNullable);\n        newLink[i] = childLink || null;\n        hasChanged = hasChanged || newLink[i] !== prevData![i];\n      }\n    }\n\n    return hasChanged ? newLink : (prevData as Data[]);\n  } else if (link === null || (prevData === null && isOwnedData)) {\n    return null;\n  }\n\n  return readSelection(\n    ctx,\n    link,\n    select,\n    (prevData || InMemoryData.makeData(prevData)) as Data\n  );\n};\n\nconst isDataOrKey = (x: any): x is string | Data =>\n  typeof x === 'string' ||\n  (typeof x === 'object' && typeof (x as any).__typename === 'string');\n","import * as InMemoryData from '../store/data';\nimport { keyOfField } from '../store/keys';\nimport type { FieldArgs } from '../types';\n\ninterface PartialFieldInfo {\n  fieldKey: string;\n}\n\nexport const invalidateEntity = (\n  entityKey: string,\n  field?: string,\n  args?: FieldArgs\n) => {\n  const fields: PartialFieldInfo[] = field\n    ? [{ fieldKey: keyOfField(field, args) }]\n    : InMemoryData.inspectFields(entityKey);\n\n  for (let i = 0, l = fields.length; i < l; i++) {\n    const { fieldKey } = fields[i];\n    if (InMemoryData.readLink(entityKey, fieldKey) !== undefined) {\n      InMemoryData.writeLink(entityKey, fieldKey, undefined);\n    } else {\n      InMemoryData.writeRecord(entityKey, fieldKey, undefined);\n    }\n  }\n};\n\nexport const invalidateType = (\n  typename: string,\n  excludedEntities: string[]\n) => {\n  const types = InMemoryData.getEntitiesForType(typename);\n  for (const entity of types) {\n    if (excludedEntities.includes(entity)) continue;\n    invalidateEntity(entity);\n  }\n};\n","import type { FormattedNode, CombinedError } from '@urql/core';\nimport { formatDocument } from '@urql/core';\n\nimport type {\n  FieldNode,\n  DocumentNode,\n  FragmentDefinitionNode,\n} from '@0no-co/graphql.web';\n\nimport type { SelectionSet } from '../ast';\nimport {\n  getFragments,\n  getMainOperation,\n  normalizeVariables,\n  getFieldArguments,\n  isFieldAvailableOnType,\n  getSelectionSet,\n  getName,\n  getFragmentTypeName,\n  getFieldAlias,\n} from '../ast';\n\nimport { invariant, warn, pushDebugNode, popDebugNode } from '../helpers/help';\n\nimport type {\n  NullArray,\n  Variables,\n  Data,\n  Link,\n  OperationRequest,\n  Dependencies,\n  EntityField,\n  OptimisticMutationResolver,\n} from '../types';\n\nimport { joinKeys, keyOfField } from '../store/keys';\nimport type { Store } from '../store/store';\nimport * as InMemoryData from '../store/data';\n\nimport type { Context } from './shared';\nimport {\n  SelectionIterator,\n  ensureData,\n  makeContext,\n  updateContext,\n  getFieldError,\n  deferRef,\n} from './shared';\nimport { invalidateType } from './invalidate';\n\nexport interface WriteResult {\n  data: null | Data;\n  dependencies: Dependencies;\n}\n\n/** Writes a GraphQL response to the cache.\n * @internal\n */\nexport const __initAnd_write = (\n  store: Store,\n  request: OperationRequest,\n  data: Data,\n  error?: CombinedError | undefined,\n  key?: number\n): WriteResult => {\n  InMemoryData.initDataState('write', store.data, key || null);\n  const result = _write(store, request, data, error);\n  InMemoryData.clearDataState();\n  return result;\n};\n\nexport const __initAnd_writeOptimistic = (\n  store: Store,\n  request: OperationRequest,\n  key: number\n): WriteResult => {\n  if (process.env.NODE_ENV !== 'production') {\n    invariant(\n      getMainOperation(request.query).operation === 'mutation',\n      'writeOptimistic(...) was called with an operation that is not a mutation.\\n' +\n        'This case is unsupported and should never occur.',\n      10\n    );\n  }\n\n  InMemoryData.initDataState('write', store.data, key, true);\n  const result = _write(store, request, {} as Data, undefined);\n  InMemoryData.clearDataState();\n  return result;\n};\n\nexport const _write = (\n  store: Store,\n  request: OperationRequest,\n  data?: Data,\n  error?: CombinedError | undefined\n) => {\n  if (process.env.NODE_ENV !== 'production') {\n    InMemoryData.getCurrentDependencies();\n  }\n\n  const query = formatDocument(request.query);\n  const operation = getMainOperation(query);\n  const result: WriteResult = {\n    data: data || InMemoryData.makeData(),\n    dependencies: InMemoryData.currentDependencies!,\n  };\n  const kind = store.rootFields[operation.operation];\n\n  const ctx = makeContext(\n    store,\n    normalizeVariables(operation, request.variables),\n    getFragments(query),\n    kind,\n    kind,\n    error\n  );\n\n  if (process.env.NODE_ENV !== 'production') {\n    pushDebugNode(kind, operation);\n  }\n\n  writeSelection(ctx, kind, getSelectionSet(operation), result.data!);\n\n  if (process.env.NODE_ENV !== 'production') {\n    popDebugNode();\n  }\n\n  return result;\n};\n\nexport const _writeFragment = (\n  store: Store,\n  query: FormattedNode<DocumentNode>,\n  data: Partial<Data>,\n  variables?: Variables,\n  fragmentName?: string\n) => {\n  const fragments = getFragments(query);\n  let fragment: FormattedNode<FragmentDefinitionNode>;\n  if (fragmentName) {\n    fragment = fragments[fragmentName]!;\n    if (!fragment) {\n      warn(\n        'writeFragment(...) was called with a fragment name that does not exist.\\n' +\n          'You provided ' +\n          fragmentName +\n          ' but could only find ' +\n          Object.keys(fragments).join(', ') +\n          '.',\n        11,\n        store.logger\n      );\n\n      return null;\n    }\n  } else {\n    const names = Object.keys(fragments);\n    fragment = fragments[names[0]]!;\n    if (!fragment) {\n      warn(\n        'writeFragment(...) was called with an empty fragment.\\n' +\n          'You have to call it with at least one fragment in your GraphQL document.',\n        11,\n        store.logger\n      );\n\n      return null;\n    }\n  }\n\n  const typename = getFragmentTypeName(fragment);\n  const dataToWrite = { __typename: typename, ...data } as Data;\n  const entityKey = store.keyOfEntity(dataToWrite);\n  if (!entityKey) {\n    return warn(\n      \"Can't generate a key for writeFragment(...) data.\\n\" +\n        'You have to pass an `id` or `_id` field or create a custom `keys` config for `' +\n        typename +\n        '`.',\n      12,\n      store.logger\n    );\n  }\n\n  if (process.env.NODE_ENV !== 'production') {\n    pushDebugNode(typename, fragment);\n  }\n\n  const ctx = makeContext(\n    store,\n    variables || {},\n    fragments,\n    typename,\n    entityKey,\n    undefined\n  );\n\n  writeSelection(ctx, entityKey, getSelectionSet(fragment), dataToWrite);\n\n  if (process.env.NODE_ENV !== 'production') {\n    popDebugNode();\n  }\n};\n\nconst writeSelection = (\n  ctx: Context,\n  entityKey: undefined | string,\n  select: FormattedNode<SelectionSet>,\n  data: Data\n) => {\n  // These fields determine how we write. The `Query` root type is written\n  // like a normal entity, hence, we use `rootField` with a default to determine\n  // this. All other root names (Subscription & Mutation) are in a different\n  // write mode\n  const rootField = ctx.store.rootNames[entityKey!] || 'query';\n  const isRoot = !!ctx.store.rootNames[entityKey!];\n\n  let typename = isRoot ? entityKey : data.__typename;\n  if (!typename && entityKey && ctx.optimistic) {\n    typename = InMemoryData.readRecord(entityKey, '__typename') as\n      | string\n      | undefined;\n  }\n\n  if (!typename) {\n    warn(\n      \"Couldn't find __typename when writing.\\n\" +\n        \"If you're writing to the cache manually have to pass a `__typename` property on each entity in your data.\",\n      14,\n      ctx.store.logger\n    );\n    return;\n  } else if (!isRoot && entityKey) {\n    InMemoryData.writeRecord(entityKey, '__typename', typename);\n    InMemoryData.writeType(typename, entityKey);\n  }\n\n  const updates = ctx.store.updates[typename];\n  const selection = new SelectionIterator(\n    typename,\n    entityKey || typename,\n    false,\n    undefined,\n    select,\n    ctx\n  );\n\n  let node: FormattedNode<FieldNode> | void;\n  while ((node = selection.next())) {\n    const fieldName = getName(node);\n    const fieldArgs = getFieldArguments(node, ctx.variables);\n    const fieldKey = keyOfField(fieldName, fieldArgs);\n    const fieldAlias = getFieldAlias(node);\n    let fieldValue = data[ctx.optimistic ? fieldName : fieldAlias];\n\n    if (\n      // Skip typename fields and assume they've already been written above\n      fieldName === '__typename' ||\n      // Fields marked as deferred that aren't defined must be skipped\n      // Otherwise, we also ignore undefined values in optimistic updaters\n      (fieldValue === undefined &&\n        (deferRef || (ctx.optimistic && rootField === 'query')))\n    ) {\n      continue;\n    }\n\n    if (process.env.NODE_ENV !== 'production') {\n      if (ctx.store.schema && typename && fieldName !== '__typename') {\n        isFieldAvailableOnType(\n          ctx.store.schema,\n          typename,\n          fieldName,\n          ctx.store.logger\n        );\n      }\n    }\n\n    // Add the current alias to the walked path before processing the field's value\n    ctx.__internal.path.push(fieldAlias);\n\n    // Execute optimistic mutation functions on root fields, or execute recursive functions\n    // that have been returned on optimistic objects\n    let resolver: OptimisticMutationResolver | undefined;\n    if (ctx.optimistic && rootField === 'mutation') {\n      resolver = ctx.store.optimisticMutations[fieldName];\n      if (!resolver) continue;\n    } else if (ctx.optimistic && typeof fieldValue === 'function') {\n      resolver = fieldValue as any;\n    }\n\n    // Execute the field-level resolver to retrieve its data\n    if (resolver) {\n      // We have to update the context to reflect up-to-date ResolveInfo\n      updateContext(\n        ctx,\n        data,\n        typename,\n        entityKey || typename,\n        fieldKey,\n        fieldName\n      );\n      fieldValue = ensureData(resolver(fieldArgs || {}, ctx.store, ctx));\n    }\n\n    if (fieldValue === undefined) {\n      if (process.env.NODE_ENV !== 'production') {\n        if (\n          !entityKey ||\n          !InMemoryData.hasField(entityKey, fieldKey) ||\n          (ctx.optimistic && !InMemoryData.readRecord(entityKey, '__typename'))\n        ) {\n          const expected =\n            node.selectionSet === undefined\n              ? 'scalar (number, boolean, etc)'\n              : 'selection set';\n\n          warn(\n            'Invalid undefined: The field at `' +\n              fieldKey +\n              '` is `undefined`, but the GraphQL query expects a ' +\n              expected +\n              ' for this field.',\n            13,\n            ctx.store.logger\n          );\n        }\n      }\n\n      continue; // Skip this field\n    }\n\n    if (node.selectionSet) {\n      // Process the field and write links for the child entities that have been written\n      if (entityKey && rootField === 'query') {\n        const key = joinKeys(entityKey, fieldKey);\n        const link = writeField(\n          ctx,\n          getSelectionSet(node),\n          ensureData(fieldValue),\n          key,\n          ctx.optimistic\n            ? InMemoryData.readLink(entityKey || typename, fieldKey)\n            : undefined\n        );\n\n        InMemoryData.writeLink(entityKey || typename, fieldKey, link);\n      } else {\n        writeField(ctx, getSelectionSet(node), ensureData(fieldValue));\n      }\n    } else if (entityKey && rootField === 'query') {\n      // This is a leaf node, so we're setting the field's value directly\n      InMemoryData.writeRecord(\n        entityKey || typename,\n        fieldKey,\n        (fieldValue !== null || !getFieldError(ctx)\n          ? fieldValue\n          : undefined) as EntityField\n      );\n    }\n\n    // We run side-effect updates after the default, normalized updates\n    // so that the data is already available in-store if necessary\n    const updater = updates && updates[fieldName];\n    if (updater) {\n      // We have to update the context to reflect up-to-date ResolveInfo\n      updateContext(\n        ctx,\n        data,\n        typename,\n        entityKey || typename,\n        fieldKey,\n        fieldName\n      );\n\n      data[fieldName] = fieldValue;\n      updater(data, fieldArgs || {}, ctx.store, ctx);\n    } else if (\n      typename === ctx.store.rootFields['mutation'] &&\n      !ctx.optimistic\n    ) {\n      // If we're on a mutation that doesn't have an updater, we'll see\n      // whether we can find the entity returned by the mutation in the cache.\n      // if we don't we'll assume this is a create mutation and invalidate\n      // the found __typename.\n      if (fieldValue && Array.isArray(fieldValue)) {\n        const excludedEntities: string[] = fieldValue.map(\n          entity => ctx.store.keyOfEntity(entity) || ''\n        );\n        for (let i = 0, l = fieldValue.length; i < l; i++) {\n          const key = excludedEntities[i];\n          if (key && fieldValue[i].__typename) {\n            const resolved = InMemoryData.readRecord(key, '__typename');\n            const count = InMemoryData!.getRefCount(key);\n            if (resolved && !count) {\n              invalidateType(fieldValue[i].__typename, excludedEntities);\n            }\n          }\n        }\n      } else if (fieldValue && typeof fieldValue === 'object') {\n        const key = ctx.store.keyOfEntity(fieldValue as any);\n        if (key) {\n          const resolved = InMemoryData.readRecord(key, '__typename');\n          const count = InMemoryData.getRefCount(key);\n          if ((!resolved || !count) && fieldValue.__typename) {\n            invalidateType(fieldValue.__typename, [key]);\n          }\n        }\n      }\n    }\n\n    // After processing the field, remove the current alias from the path again\n    ctx.__internal.path.pop();\n  }\n};\n\n// A pattern to match typenames of types that are likely never keyable\nconst KEYLESS_TYPE_RE = /^__|PageInfo|(Connection|Edge)$/;\n\nconst writeField = (\n  ctx: Context,\n  select: FormattedNode<SelectionSet>,\n  data: null | Data | NullArray<Data>,\n  parentFieldKey?: string,\n  prevLink?: Link\n): Link | undefined => {\n  if (Array.isArray(data)) {\n    const newData = new Array(data.length);\n    for (let i = 0, l = data.length; i < l; i++) {\n      // Add the current index to the walked path before processing the link\n      ctx.__internal.path.push(i);\n      // Append the current index to the parentFieldKey fallback\n      const indexKey = parentFieldKey\n        ? joinKeys(parentFieldKey, `${i}`)\n        : undefined;\n      // Recursively write array data\n      const prevIndex = prevLink != null ? prevLink[i] : undefined;\n      const links = writeField(ctx, select, data[i], indexKey, prevIndex);\n      // Link cannot be expressed as a recursive type\n      newData[i] = links as string | null;\n      // After processing the field, remove the current index from the path\n      ctx.__internal.path.pop();\n    }\n\n    return newData;\n  } else if (data === null) {\n    return getFieldError(ctx) ? undefined : null;\n  }\n\n  const entityKey =\n    ctx.store.keyOfEntity(data) ||\n    (typeof prevLink === 'string' ? prevLink : null);\n  const typename = data.__typename;\n\n  if (\n    parentFieldKey &&\n    !ctx.store.keys[data.__typename] &&\n    entityKey === null &&\n    typeof typename === 'string' &&\n    !KEYLESS_TYPE_RE.test(typename)\n  ) {\n    warn(\n      'Invalid key: The GraphQL query at the field at `' +\n        parentFieldKey +\n        '` has a selection set, ' +\n        'but no key could be generated for the data at this field.\\n' +\n        'You have to request `id` or `_id` fields for all selection sets or create ' +\n        'a custom `keys` config for `' +\n        typename +\n        '`.\\n' +\n        'Entities without keys will be embedded directly on the parent entity. ' +\n        'If this is intentional, create a `keys` config for `' +\n        typename +\n        '` that always returns null.',\n      15,\n      ctx.store.logger\n    );\n  }\n\n  const childKey = entityKey || parentFieldKey;\n  writeSelection(ctx, childKey, select, data);\n  return childKey || null;\n};\n","import type { TypedDocumentNode } from '@urql/core';\nimport { formatDocument, createRequest } from '@urql/core';\n\nimport type {\n  Cache,\n  FieldInfo,\n  ResolverConfig,\n  DataField,\n  Variables,\n  FieldArgs,\n  Link,\n  Data,\n  QueryInput,\n  UpdatesConfig,\n  OptimisticMutationConfig,\n  KeyingConfig,\n  Entity,\n  CacheExchangeOpts,\n  DirectivesConfig,\n  Logger,\n} from '../types';\n\nimport { invariant } from '../helpers/help';\nimport { contextRef, ensureLink } from '../operations/shared';\nimport { _query, _queryFragment } from '../operations/query';\nimport { _write, _writeFragment } from '../operations/write';\nimport { invalidateEntity, invalidateType } from '../operations/invalidate';\nimport { keyOfField } from './keys';\nimport * as InMemoryData from './data';\n\nimport type { SchemaIntrospector } from '../ast';\nimport {\n  buildClientSchema,\n  expectValidKeyingConfig,\n  expectValidUpdatesConfig,\n  expectValidResolversConfig,\n  expectValidOptimisticMutationsConfig,\n} from '../ast';\n\ntype DocumentNode = TypedDocumentNode<any, any>;\ntype RootField = 'query' | 'mutation' | 'subscription';\n\n/** Implementation of the {@link Cache} interface as created internally by the {@link cacheExchange}.\n * @internal\n */\nexport class Store<\n  C extends Partial<CacheExchangeOpts> = Partial<CacheExchangeOpts>,\n> implements Cache\n{\n  data: InMemoryData.InMemoryData;\n\n  logger?: Logger;\n  directives: DirectivesConfig;\n  resolvers: ResolverConfig;\n  updates: UpdatesConfig;\n  optimisticMutations: OptimisticMutationConfig;\n  keys: KeyingConfig;\n  globalIDs: Set<string> | boolean;\n  schema?: SchemaIntrospector;\n\n  rootFields: { query: string; mutation: string; subscription: string };\n  rootNames: { [name: string]: RootField | void };\n\n  constructor(opts?: C) {\n    if (!opts) opts = {} as C;\n\n    this.logger = opts.logger;\n    this.resolvers = opts.resolvers || {};\n    this.directives = opts.directives || {};\n    this.optimisticMutations = opts.optimistic || {};\n    this.keys = opts.keys || {};\n\n    this.globalIDs = Array.isArray(opts.globalIDs)\n      ? new Set(opts.globalIDs)\n      : !!opts.globalIDs;\n\n    let queryName = 'Query';\n    let mutationName = 'Mutation';\n    let subscriptionName = 'Subscription';\n    if (opts.schema) {\n      const schema = buildClientSchema(opts.schema);\n      queryName = schema.query || queryName;\n      mutationName = schema.mutation || mutationName;\n      subscriptionName = schema.subscription || subscriptionName;\n      // Only add schema introspector if it has types info\n      if (schema.types) this.schema = schema;\n    }\n\n    this.updates = opts.updates || {};\n\n    this.rootFields = {\n      query: queryName,\n      mutation: mutationName,\n      subscription: subscriptionName,\n    };\n\n    this.rootNames = {\n      [queryName]: 'query',\n      [mutationName]: 'mutation',\n      [subscriptionName]: 'subscription',\n    };\n\n    this.data = InMemoryData.make(queryName);\n\n    if (this.schema && process.env.NODE_ENV !== 'production') {\n      expectValidKeyingConfig(this.schema, this.keys, this.logger);\n      expectValidUpdatesConfig(this.schema, this.updates, this.logger);\n      expectValidResolversConfig(this.schema, this.resolvers, this.logger);\n      expectValidOptimisticMutationsConfig(\n        this.schema,\n        this.optimisticMutations,\n        this.logger\n      );\n    }\n  }\n\n  keyOfField(fieldName: string, fieldArgs?: FieldArgs) {\n    return keyOfField(fieldName, fieldArgs);\n  }\n\n  keyOfEntity(data: Entity) {\n    // In resolvers and updaters we may have a specific parent\n    // object available that can be used to skip to a specific parent\n    // key directly without looking at its incomplete properties\n    if (contextRef && data === contextRef.parent) {\n      return contextRef.parentKey;\n    } else if (data == null || typeof data === 'string') {\n      return data || null;\n    } else if (!data.__typename) {\n      return null;\n    } else if (this.rootNames[data.__typename]) {\n      return data.__typename;\n    }\n\n    let key: string | null = null;\n    if (this.keys[data.__typename]) {\n      key = this.keys[data.__typename](data) || null;\n    } else if (data.id != null) {\n      key = `${data.id}`;\n    } else if (data._id != null) {\n      key = `${data._id}`;\n    }\n\n    const typename = data.__typename;\n    const globalID =\n      this.globalIDs === true ||\n      (this.globalIDs && this.globalIDs.has(typename));\n    return globalID || !key ? key : `${typename}:${key}`;\n  }\n\n  resolve(\n    entity: Entity,\n    field: string,\n    args?: FieldArgs\n  ): DataField | undefined {\n    const entityKey = this.keyOfEntity(entity);\n    if (entityKey) {\n      const fieldKey = keyOfField(field, args);\n      const fieldValue = InMemoryData.readRecord(entityKey, fieldKey);\n      if (fieldValue !== undefined) return fieldValue;\n      let fieldLink = InMemoryData.readLink(entityKey, fieldKey);\n      if (fieldLink !== undefined) fieldLink = ensureLink(this, fieldLink);\n      return fieldLink;\n    }\n  }\n\n  invalidate(entity: Entity, field?: string, args?: FieldArgs) {\n    const entityKey = this.keyOfEntity(entity);\n    const shouldInvalidateType =\n      entity &&\n      typeof entity === 'string' &&\n      !field &&\n      !args &&\n      !this.resolve(entity, '__typename');\n\n    if (shouldInvalidateType) {\n      invalidateType(entity, []);\n    } else {\n      invariant(\n        entityKey,\n        \"Can't generate a key for invalidate(...).\\n\" +\n          'You have to pass an id or _id field or create a custom `keys` field for `' +\n          (typeof entity === 'object'\n            ? (entity as Data).__typename\n            : entity + '`.'),\n        19\n      );\n\n      invalidateEntity(entityKey, field, args);\n    }\n  }\n\n  inspectFields(entity: Entity): FieldInfo[] {\n    const entityKey = this.keyOfEntity(entity);\n    return entityKey ? InMemoryData.inspectFields(entityKey) : [];\n  }\n\n  updateQuery<T = Data, V = Variables>(\n    input: QueryInput<T, V>,\n    updater: (data: T | null) => T | null\n  ): void {\n    const request = createRequest(input.query, input.variables!);\n    const output = updater(this.readQuery(request));\n    if (output !== null) {\n      _write(this, request, output as any, undefined);\n    }\n  }\n\n  readQuery<T = Data, V = Variables>(input: QueryInput<T, V>): T | null {\n    const request = createRequest(input.query, input.variables!);\n    return _query(this, request, undefined, undefined).data as T | null;\n  }\n\n  readFragment<T = Data, V = Variables>(\n    fragment: DocumentNode | TypedDocumentNode<T, V>,\n    entity: string | Data | T,\n    variables?: V,\n    fragmentName?: string\n  ): T | null {\n    return _queryFragment(\n      this,\n      formatDocument(fragment),\n      entity as Data,\n      variables as any,\n      fragmentName\n    ) as T | null;\n  }\n\n  writeFragment<T = Data, V = Variables>(\n    fragment: DocumentNode | TypedDocumentNode<T, V>,\n    data: T,\n    variables?: V,\n    fragmentName?: string\n  ): void {\n    _writeFragment(\n      this,\n      formatDocument(fragment),\n      data as Data,\n      variables as any,\n      fragmentName\n    );\n  }\n\n  link(\n    entity: Entity,\n    field: string,\n    args: FieldArgs,\n    link: Link<Entity>\n  ): void;\n\n  link(entity: Entity, field: string, link: Link<Entity>): void;\n\n  link(\n    entity: Entity,\n    field: string,\n    ...rest: [FieldArgs, Link<Entity>] | [Link<Entity>]\n  ): void {\n    const args = rest.length === 2 ? rest[0] : null;\n    const link = rest.length === 2 ? rest[1] : rest[0];\n    const entityKey = this.keyOfEntity(entity);\n    if (entityKey) {\n      InMemoryData.writeLink(\n        entityKey,\n        keyOfField(field, args),\n        ensureLink(this, link)\n      );\n    }\n  }\n}\n","import type {\n  IntrospectionQuery,\n  IntrospectionTypeRef,\n  IntrospectionInputValue,\n  IntrospectionType,\n} from './graphql';\n\nexport interface SchemaField {\n  name: string;\n  type: IntrospectionTypeRef;\n  args(): Record<string, IntrospectionInputValue | void>;\n}\n\nexport interface SchemaObject {\n  name: string;\n  kind: 'INTERFACE' | 'OBJECT';\n  interfaces(): Record<string, unknown>;\n  fields(): Record<string, SchemaField | void>;\n}\n\nexport interface SchemaUnion {\n  name: string;\n  kind: 'UNION';\n  types(): Record<string, unknown>;\n}\n\nexport interface SchemaIntrospector {\n  query: string | null;\n  mutation: string | null;\n  subscription: string | null;\n  types?: Map<string, SchemaObject | SchemaUnion>;\n  isSubType(abstract: string, possible: string): boolean;\n}\n\nexport interface PartialIntrospectionSchema {\n  queryType: { name: string; kind?: any };\n  mutationType?: { name: string; kind?: any } | null;\n  subscriptionType?: { name: string; kind?: any } | null;\n  types?: readonly any[];\n}\n\nexport type IntrospectionData =\n  | IntrospectionQuery\n  | { __schema: PartialIntrospectionSchema };\n\nexport const buildClientSchema = ({\n  __schema,\n}: IntrospectionData): SchemaIntrospector => {\n  const typemap: Map<string, SchemaObject | SchemaUnion> = new Map();\n\n  const buildNameMap = <T extends { name: string }>(\n    arr: ReadonlyArray<T>\n  ): (() => { [name: string]: T }) => {\n    let map: Record<string, T> | void;\n    return () => {\n      if (!map) {\n        map = {};\n        for (let i = 0; i < arr.length; i++) map[arr[i].name] = arr[i];\n      }\n      return map;\n    };\n  };\n\n  const buildType = (\n    type: IntrospectionType\n  ): SchemaObject | SchemaUnion | void => {\n    switch (type.kind) {\n      case 'OBJECT':\n      case 'INTERFACE':\n        return {\n          name: type.name,\n          kind: type.kind as 'OBJECT' | 'INTERFACE',\n          interfaces: buildNameMap(type.interfaces || []),\n          fields: buildNameMap(\n            type.fields!.map((field: any) => ({\n              name: field.name,\n              type: field.type,\n              args: buildNameMap(field.args),\n            }))\n          ),\n        } as SchemaObject;\n      case 'UNION':\n        return {\n          name: type.name,\n          kind: type.kind as 'UNION',\n          types: buildNameMap(type.possibleTypes || []),\n        } as SchemaUnion;\n    }\n  };\n\n  const schema: SchemaIntrospector = {\n    query: __schema.queryType ? __schema.queryType.name : null,\n    mutation: __schema.mutationType ? __schema.mutationType.name : null,\n    subscription: __schema.subscriptionType\n      ? __schema.subscriptionType.name\n      : null,\n    types: undefined,\n    isSubType(abstract: string, possible: string) {\n      const abstractType = typemap.get(abstract);\n      const possibleType = typemap.get(possible);\n      if (!abstractType || !possibleType) {\n        return false;\n      } else if (abstractType.kind === 'UNION') {\n        return !!abstractType.types()[possible];\n      } else if (\n        abstractType.kind !== 'OBJECT' &&\n        possibleType.kind === 'OBJECT'\n      ) {\n        return !!possibleType.interfaces()[abstract];\n      } else {\n        return abstract === possible;\n      }\n    },\n  };\n\n  if (__schema.types) {\n    schema.types = typemap;\n    for (let i = 0; i < __schema.types.length; i++) {\n      const type = __schema.types[i];\n      if (type && type.name) {\n        const out = buildType(type);\n        if (out) typemap.set(type.name, out);\n      }\n    }\n  }\n\n  return schema;\n};\n","import type { Operation, RequestPolicy, OperationDebugMeta } from '@urql/core';\nimport { makeOperation } from '@urql/core';\n\n// Returns the given operation result with added cacheOutcome meta field\nexport const addMetadata = (\n  operation: Operation,\n  meta: OperationDebugMeta\n): Operation =>\n  makeOperation(operation.kind, operation, {\n    ...operation.context,\n    meta: {\n      ...operation.context.meta,\n      ...meta,\n    },\n  });\n\n// Copy an operation and change the requestPolicy to skip the cache\nexport const toRequestPolicy = (\n  operation: Operation,\n  requestPolicy: RequestPolicy\n): Operation => {\n  return makeOperation(operation.kind, operation, {\n    ...operation.context,\n    requestPolicy,\n  });\n};\n","import type {\n  Exchange,\n  Operation,\n  OperationResult,\n  RequestPolicy,\n  CacheOutcome,\n} from '@urql/core';\nimport { formatDocument, makeOperation } from '@urql/core';\n\nimport type { Source } from 'wonka';\nimport {\n  filter,\n  map,\n  merge,\n  pipe,\n  share,\n  fromArray,\n  mergeMap,\n  empty,\n} from 'wonka';\n\nimport { _query } from './operations/query';\nimport { _write } from './operations/write';\nimport { addMetadata, toRequestPolicy } from './helpers/operation';\nimport { filterVariables, getMainOperation } from './ast';\nimport { Store } from './store/store';\nimport type { Data, Dependencies, CacheExchangeOpts } from './types';\n\nimport {\n  initDataState,\n  clearDataState,\n  noopDataState,\n  hydrateData,\n  reserveLayer,\n  hasLayer,\n} from './store/data';\n\ninterface OperationResultWithMeta extends Partial<OperationResult> {\n  operation: Operation;\n  outcome: CacheOutcome;\n  dependencies: Dependencies;\n  hasNext: boolean;\n}\n\ntype Operations = Set<number>;\ntype OperationMap = Map<number, Operation>;\ntype ResultMap = Map<number, Data | null>;\ntype OptimisticDependencies = Map<number, Dependencies>;\ntype DependentOperations = Map<string, Operations>;\n\n/** Exchange factory that creates a normalized cache exchange.\n *\n * @param opts - A {@link CacheExchangeOpts} configuration object.\n * @returns the created normalized cache {@link Exchange}.\n *\n * @remarks\n * Graphcache is a normalized cache, enabled by using the `cacheExchange`\n * in place of `@urql/core`’s. A normalized GraphQL cache uses typenames\n * and key fields in the result to share a single copy for each unique\n * entity across all queries.\n *\n * The `cacheExchange` may be passed a {@link CacheExchangeOpts} object\n * to define custom resolvers, custom updates for mutations,\n * optimistic updates, or to add custom key fields per type.\n *\n * @see {@link https://urql.dev/goto/docs/graphcache} for the full Graphcache docs.\n */\nexport const cacheExchange =\n  <C extends Partial<CacheExchangeOpts>>(opts?: C): Exchange =>\n  ({ forward, client, dispatchDebug }) => {\n    const store = new Store<C>(opts);\n\n    if (opts && opts.storage) {\n      store.data.hydrating = true;\n      opts.storage.readData().then(entries => {\n        hydrateData(store.data, opts!.storage!, entries);\n        if (opts.storage!.onCacheHydrated) opts.storage!.onCacheHydrated();\n      });\n    }\n\n    const optimisticKeysToDependencies: OptimisticDependencies = new Map();\n    const mutationResultBuffer: OperationResult[] = [];\n    const operations: OperationMap = new Map();\n    const results: ResultMap = new Map();\n    const blockedDependencies: Dependencies = new Set();\n    const requestedRefetch: Operations = new Set();\n    const deps: DependentOperations = new Map();\n\n    let reexecutingOperations: Operations = new Set();\n    let dependentOperations: Operations = new Set();\n\n    const isBlockedByOptimisticUpdate = (\n      dependencies: Dependencies\n    ): boolean => {\n      for (const dep of dependencies.values())\n        if (blockedDependencies.has(dep)) return true;\n      return false;\n    };\n\n    const collectPendingOperations = (\n      pendingOperations: Operations,\n      dependencies: undefined | Dependencies\n    ) => {\n      if (dependencies) {\n        // Collect operations that will be updated due to cache changes\n        for (const dep of dependencies.values()) {\n          const keys = deps.get(dep);\n          if (keys) for (const key of keys.values()) pendingOperations.add(key);\n        }\n      }\n    };\n\n    const executePendingOperations = (\n      operation: Operation,\n      pendingOperations: Operations,\n      isOptimistic: boolean\n    ) => {\n      // Reexecute collected operations and delete them from the mapping\n      for (const key of pendingOperations.values()) {\n        if (key !== operation.key) {\n          const op = operations.get(key);\n          if (op) {\n            // Collect all dependent operations if the reexecuting operation is a query\n            if (operation.kind === 'query') dependentOperations.add(key);\n            let policy: RequestPolicy = 'cache-first';\n            if (requestedRefetch.has(key)) {\n              requestedRefetch.delete(key);\n              policy = 'cache-and-network';\n            }\n            client.reexecuteOperation(toRequestPolicy(op, policy));\n          }\n        }\n      }\n\n      if (!isOptimistic) {\n        // Upon completion, all dependent operations become reexecuting operations, preventing\n        // them from reexecuting prior operations again, causing infinite loops\n        const _reexecutingOperations = reexecutingOperations;\n        reexecutingOperations = dependentOperations;\n        if (operation.kind === 'query') {\n          reexecutingOperations.add(operation.key);\n        }\n        (dependentOperations = _reexecutingOperations).clear();\n      }\n    };\n\n    // This registers queries with the data layer to ensure commutativity\n    const prepareForwardedOperation = (operation: Operation) => {\n      let optimistic = false;\n      if (operation.kind === 'query') {\n        // Pre-reserve the position of the result layer\n        reserveLayer(store.data, operation.key);\n        operations.set(operation.key, operation);\n      } else if (operation.kind === 'teardown') {\n        // Delete reference to operation if any exists to release it\n        operations.delete(operation.key);\n        results.delete(operation.key);\n        reexecutingOperations.delete(operation.key);\n        // Mark operation layer as done\n        noopDataState(store.data, operation.key);\n        return operation;\n      } else if (\n        operation.kind === 'mutation' &&\n        operation.context.requestPolicy !== 'network-only'\n      ) {\n        operations.set(operation.key, operation);\n        // This executes an optimistic update for mutations and registers it if necessary\n        initDataState('write', store.data, operation.key, true, false);\n        const { dependencies } = _write(\n          store,\n          operation as any,\n          undefined,\n          undefined\n        );\n        clearDataState();\n        if (dependencies.size) {\n          // Update blocked optimistic dependencies\n          for (const dep of dependencies.values()) blockedDependencies.add(dep);\n          // Store optimistic dependencies for update\n          optimisticKeysToDependencies.set(operation.key, dependencies);\n          // Update related queries\n          const pendingOperations: Operations = new Set();\n          collectPendingOperations(pendingOperations, dependencies);\n          executePendingOperations(operation, pendingOperations, true);\n          // Mark operation as optimistic\n          optimistic = true;\n        }\n      }\n\n      return makeOperation(\n        operation.kind,\n        {\n          key: operation.key,\n          query: formatDocument(operation.query),\n          variables: operation.variables\n            ? filterVariables(\n                getMainOperation(operation.query),\n                operation.variables\n              )\n            : operation.variables,\n        },\n        { ...operation.context, optimistic }\n      );\n    };\n\n    // This updates the known dependencies for the passed operation\n    const updateDependencies = (op: Operation, dependencies: Dependencies) => {\n      for (const dep of dependencies.values()) {\n        let depOps = deps.get(dep);\n        if (!depOps) deps.set(dep, (depOps = new Set()));\n        depOps.add(op.key);\n      }\n    };\n\n    // Retrieves a query result from cache and adds an `isComplete` hint\n    // This hint indicates whether the result is \"complete\" or not\n    const operationResultFromCache = (\n      operation: Operation\n    ): OperationResultWithMeta => {\n      initDataState('read', store.data, undefined, false, false);\n      const result = _query(\n        store,\n        operation,\n        results.get(operation.key),\n        undefined\n      );\n      clearDataState();\n      const cacheOutcome: CacheOutcome = result.data\n        ? !result.partial && !result.hasNext\n          ? 'hit'\n          : 'partial'\n        : 'miss';\n\n      results.set(operation.key, result.data);\n      operations.set(operation.key, operation);\n      updateDependencies(operation, result.dependencies);\n\n      return {\n        outcome: cacheOutcome,\n        operation,\n        data: result.data,\n        dependencies: result.dependencies,\n        hasNext: result.hasNext,\n      };\n    };\n\n    // Take any OperationResult and update the cache with it\n    const updateCacheWithResult = (\n      result: OperationResult,\n      pendingOperations: Operations\n    ): OperationResult => {\n      // Retrieve the original operation to get unfiltered variables\n      const operation =\n        operations.get(result.operation.key) || result.operation;\n      if (operation.kind === 'mutation') {\n        // Collect previous dependencies that have been written for optimistic updates\n        const dependencies = optimisticKeysToDependencies.get(operation.key);\n        collectPendingOperations(pendingOperations, dependencies);\n        optimisticKeysToDependencies.delete(operation.key);\n      }\n\n      if (operation.kind === 'subscription' || result.hasNext)\n        reserveLayer(store.data, operation.key, true);\n\n      let queryDependencies: undefined | Dependencies;\n      let data: Data | null = result.data;\n      if (data) {\n        // Write the result to cache and collect all dependencies that need to be\n        // updated\n        initDataState('write', store.data, operation.key, false, false);\n        const writeDependencies = _write(\n          store,\n          operation,\n          data,\n          result.error\n        ).dependencies;\n        clearDataState();\n        collectPendingOperations(pendingOperations, writeDependencies);\n        const prevData =\n          operation.kind === 'query' ? results.get(operation.key) : null;\n        initDataState(\n          'read',\n          store.data,\n          operation.key,\n          false,\n          prevData !== data\n        );\n        const queryResult = _query(\n          store,\n          operation,\n          prevData || data,\n          result.error\n        );\n        clearDataState();\n        data = queryResult.data;\n        if (operation.kind === 'query') {\n          // Collect the query's dependencies for future pending operation updates\n          queryDependencies = queryResult.dependencies;\n          collectPendingOperations(pendingOperations, queryDependencies);\n          results.set(operation.key, data);\n        }\n      } else {\n        noopDataState(store.data, operation.key);\n      }\n\n      // Update this operation's dependencies if it's a query\n      if (queryDependencies) {\n        updateDependencies(result.operation, queryDependencies);\n      }\n\n      return {\n        operation,\n        data,\n        error: result.error,\n        extensions: result.extensions,\n        hasNext: result.hasNext,\n        stale: result.stale,\n      };\n    };\n\n    return operations$ => {\n      // Filter by operations that are cacheable and attempt to query them from the cache\n      const cacheOps$ = pipe(\n        operations$,\n        filter(\n          op =>\n            op.kind === 'query' && op.context.requestPolicy !== 'network-only'\n        ),\n        map(operationResultFromCache),\n        share\n      );\n\n      const nonCacheOps$ = pipe(\n        operations$,\n        filter(\n          op =>\n            op.kind !== 'query' || op.context.requestPolicy === 'network-only'\n        )\n      );\n\n      // Rebound operations that are incomplete, i.e. couldn't be queried just from the cache\n      const cacheMissOps$ = pipe(\n        cacheOps$,\n        filter(\n          res =>\n            res.outcome === 'miss' &&\n            res.operation.context.requestPolicy !== 'cache-only' &&\n            !isBlockedByOptimisticUpdate(res.dependencies) &&\n            !reexecutingOperations.has(res.operation.key)\n        ),\n        map(res => {\n          dispatchDebug({\n            type: 'cacheMiss',\n            message: 'The result could not be retrieved from the cache',\n            operation: res.operation,\n          });\n          return addMetadata(res.operation, { cacheOutcome: 'miss' });\n        })\n      );\n\n      // Resolve OperationResults that the cache was able to assemble completely and trigger\n      // a network request if the current operation's policy is cache-and-network\n      const cacheResult$ = pipe(\n        cacheOps$,\n        filter(\n          res =>\n            res.outcome !== 'miss' ||\n            res.operation.context.requestPolicy === 'cache-only'\n        ),\n        map((res: OperationResultWithMeta): OperationResult => {\n          const { requestPolicy } = res.operation.context;\n\n          // We reexecute requests marked as `cache-and-network`, and partial responses,\n          // if we wouldn't cause a request loop\n          const shouldReexecute =\n            requestPolicy !== 'cache-only' &&\n            (res.hasNext ||\n              requestPolicy === 'cache-and-network' ||\n              (requestPolicy === 'cache-first' &&\n                res.outcome === 'partial' &&\n                !reexecutingOperations.has(res.operation.key)));\n          // Set stale to true anyway, even if the reexecute will be blocked, if the operation\n          // is in progress. We can be reasonably sure of that if a layer has been reserved for it.\n          const stale =\n            requestPolicy !== 'cache-only' &&\n            (shouldReexecute ||\n              (res.outcome === 'partial' &&\n                reexecutingOperations.has(res.operation.key) &&\n                hasLayer(store.data, res.operation.key)));\n\n          const result: OperationResult = {\n            operation: addMetadata(res.operation, {\n              cacheOutcome: res.outcome,\n            }),\n            data: res.data,\n            error: res.error,\n            extensions: res.extensions,\n            stale: stale && !res.hasNext,\n            hasNext: shouldReexecute && res.hasNext,\n          };\n\n          if (!shouldReexecute) {\n            /*noop*/\n          } else if (!isBlockedByOptimisticUpdate(res.dependencies)) {\n            client.reexecuteOperation(\n              toRequestPolicy(\n                operations.get(res.operation.key) || res.operation,\n                'network-only'\n              )\n            );\n          } else if (requestPolicy === 'cache-and-network') {\n            requestedRefetch.add(res.operation.key);\n          }\n\n          dispatchDebug({\n            type: 'cacheHit',\n            message: `A requested operation was found and returned from the cache.`,\n            operation: res.operation,\n            data: {\n              value: result,\n            },\n          });\n\n          return result;\n        })\n      );\n\n      // Forward operations that aren't cacheable and rebound operations\n      // Also update the cache with any network results\n      const result$ = pipe(\n        merge([nonCacheOps$, cacheMissOps$]),\n        map(prepareForwardedOperation),\n        forward\n      );\n\n      // Results that can immediately be resolved\n      const nonOptimisticResults$ = pipe(\n        result$,\n        filter(\n          result => !optimisticKeysToDependencies.has(result.operation.key)\n        ),\n        map(result => {\n          const pendingOperations: Operations = new Set();\n          // Update the cache with the incoming API result\n          const cacheResult = updateCacheWithResult(result, pendingOperations);\n          // Execute all dependent queries\n          executePendingOperations(result.operation, pendingOperations, false);\n          return cacheResult;\n        })\n      );\n\n      // Prevent mutations that were previously optimistic from being flushed\n      // immediately and instead clear them out slowly\n      const optimisticMutationCompletion$ = pipe(\n        result$,\n        filter(result =>\n          optimisticKeysToDependencies.has(result.operation.key)\n        ),\n        mergeMap((result: OperationResult): Source<OperationResult> => {\n          const length = mutationResultBuffer.push(result);\n          if (length < optimisticKeysToDependencies.size) {\n            return empty;\n          }\n\n          for (let i = 0; i < mutationResultBuffer.length; i++) {\n            reserveLayer(store.data, mutationResultBuffer[i].operation.key);\n          }\n\n          blockedDependencies.clear();\n\n          const results: OperationResult[] = [];\n          const pendingOperations: Operations = new Set();\n\n          let bufferedResult: OperationResult | void;\n          while ((bufferedResult = mutationResultBuffer.shift()))\n            results.push(\n              updateCacheWithResult(bufferedResult, pendingOperations)\n            );\n\n          // Execute all dependent queries as a single batch\n          executePendingOperations(result.operation, pendingOperations, false);\n\n          return fromArray(results);\n        })\n      );\n\n      return merge([\n        nonOptimisticResults$,\n        optimisticMutationCompletion$,\n        cacheResult$,\n      ]);\n    };\n  };\n","import { pipe, share, merge, makeSubject, filter, onPush } from 'wonka';\n\nimport type {\n  Operation,\n  OperationResult,\n  Exchange,\n  ExchangeIO,\n  CombinedError,\n  RequestPolicy,\n} from '@urql/core';\nimport { stringifyDocument, createRequest, makeOperation } from '@urql/core';\n\nimport type {\n  SerializedRequest,\n  CacheExchangeOpts,\n  StorageAdapter,\n} from './types';\nimport { cacheExchange } from './cacheExchange';\nimport { toRequestPolicy } from './helpers/operation';\n\nconst policyLevel = {\n  'cache-only': 0,\n  'cache-first': 1,\n  'network-only': 2,\n  'cache-and-network': 3,\n} as const;\n\n/** Input parameters for the {@link offlineExchange}.\n * @remarks\n * This configuration object extends the {@link CacheExchangeOpts}\n * as the `offlineExchange` extends the regular {@link cacheExchange}.\n */\nexport interface OfflineExchangeOpts extends CacheExchangeOpts {\n  /** Configures an offline storage adapter for Graphcache.\n   *\n   * @remarks\n   * A {@link StorageAdapter} allows Graphcache to write data to an external,\n   * asynchronous storage, and hydrate data from it when it first loads.\n   * This allows you to preserve normalized data between restarts/reloads.\n   *\n   * @see {@link https://urql.dev/goto/docs/graphcache/offline} for the full Offline Support docs.\n   */\n  storage: StorageAdapter;\n  /** Predicate function to determine whether a {@link CombinedError} hints at a network error.\n   *\n   * @remarks\n   * Not ever {@link CombinedError} means that the device is offline and by default\n   * the `offlineExchange` will check for common network error messages and check\n   * `navigator.onLine`. However, when `isOfflineError` is passed it can replace\n   * the default offline detection.\n   */\n  isOfflineError?(\n    error: undefined | CombinedError,\n    result: OperationResult\n  ): boolean;\n}\n\n/** Exchange factory that creates a normalized cache exchange in Offline Support mode.\n *\n * @param opts - A {@link OfflineExchangeOpts} configuration object.\n * @returns the created normalized, offline cache {@link Exchange}.\n *\n * @remarks\n * The `offlineExchange` is a wrapper around the regular {@link cacheExchange}\n * which adds logic via the {@link OfflineExchangeOpts.storage} adapter to\n * recognize when it’s offline, when to retry failed mutations, and how\n * to handle longer periods of being offline.\n *\n * @see {@link https://urql.dev/goto/docs/graphcache/offline} for the full Offline Support docs.\n */\nexport const offlineExchange =\n  <C extends OfflineExchangeOpts>(opts: C): Exchange =>\n  input => {\n    const { storage } = opts;\n\n    const isOfflineError =\n      opts.isOfflineError ||\n      ((error: undefined | CombinedError) =>\n        error &&\n        error.networkError &&\n        !error.response &&\n        ((typeof navigator !== 'undefined' && navigator.onLine === false) ||\n          /request failed|failed to fetch|network\\s?error/i.test(\n            error.networkError.message\n          )));\n\n    if (\n      storage &&\n      storage.onOnline &&\n      storage.readMetadata &&\n      storage.writeMetadata\n    ) {\n      const { forward: outerForward, client, dispatchDebug } = input;\n      const { source: reboundOps$, next } = makeSubject<Operation>();\n      const failedQueue: Operation[] = [];\n      let hasRehydrated = false;\n      let isFlushingQueue = false;\n\n      const updateMetadata = () => {\n        if (hasRehydrated) {\n          const requests: SerializedRequest[] = [];\n          for (let i = 0; i < failedQueue.length; i++) {\n            const operation = failedQueue[i];\n            if (operation.kind === 'mutation') {\n              requests.push({\n                query: stringifyDocument(operation.query),\n                variables: operation.variables,\n                extensions: operation.extensions,\n              });\n            }\n          }\n          storage.writeMetadata!(requests);\n        }\n      };\n\n      const filterQueue = (key: number) => {\n        for (let i = failedQueue.length - 1; i >= 0; i--)\n          if (failedQueue[i].key === key) failedQueue.splice(i, 1);\n      };\n\n      const flushQueue = () => {\n        if (!isFlushingQueue) {\n          const sent = new Set<number>();\n          isFlushingQueue = true;\n          for (let i = 0; i < failedQueue.length; i++) {\n            const operation = failedQueue[i];\n            if (operation.kind === 'mutation' || !sent.has(operation.key)) {\n              sent.add(operation.key);\n              if (operation.kind !== 'subscription') {\n                next(makeOperation('teardown', operation));\n                let overridePolicy: RequestPolicy = 'cache-first';\n                for (let i = 0; i < failedQueue.length; i++) {\n                  const { requestPolicy } = failedQueue[i].context;\n                  if (policyLevel[requestPolicy] > policyLevel[overridePolicy])\n                    overridePolicy = requestPolicy;\n                }\n                next(toRequestPolicy(operation, overridePolicy));\n              } else {\n                next(toRequestPolicy(operation, 'cache-first'));\n              }\n            }\n          }\n          isFlushingQueue = false;\n          failedQueue.length = 0;\n          updateMetadata();\n        }\n      };\n\n      const forward: ExchangeIO = ops$ => {\n        return pipe(\n          outerForward(ops$),\n          filter(res => {\n            if (\n              hasRehydrated &&\n              res.operation.kind === 'mutation' &&\n              res.operation.context.optimistic &&\n              isOfflineError(res.error, res)\n            ) {\n              failedQueue.push(res.operation);\n              updateMetadata();\n              return false;\n            }\n\n            return true;\n          }),\n          share\n        );\n      };\n\n      const cacheResults$ = cacheExchange({\n        ...opts,\n        storage: {\n          ...storage,\n          readData() {\n            const hydrate = storage.readData();\n            return {\n              async then(onEntries) {\n                const mutations = await storage.readMetadata!();\n                for (let i = 0; mutations && i < mutations.length; i++) {\n                  failedQueue.push(\n                    client.createRequestOperation(\n                      'mutation',\n                      createRequest(mutations[i].query, mutations[i].variables),\n                      mutations[i].extensions\n                    )\n                  );\n                }\n                onEntries!(await hydrate);\n                storage.onOnline!(flushQueue);\n                hasRehydrated = true;\n                flushQueue();\n              },\n            };\n          },\n        },\n      })({\n        client,\n        dispatchDebug,\n        forward,\n      });\n\n      return operations$ => {\n        const opsAndRebound$ = merge([\n          reboundOps$,\n          pipe(\n            operations$,\n            onPush(operation => {\n              if (operation.kind === 'query' && !hasRehydrated) {\n                failedQueue.push(operation);\n              } else if (operation.kind === 'teardown') {\n                filterQueue(operation.key);\n              }\n            })\n          ),\n        ]);\n\n        return pipe(\n          cacheResults$(opsAndRebound$),\n          filter(res => {\n            if (res.operation.kind === 'query') {\n              if (isOfflineError(res.error, res)) {\n                next(toRequestPolicy(res.operation, 'cache-only'));\n                failedQueue.push(res.operation);\n                return false;\n              } else if (!hasRehydrated) {\n                filterQueue(res.operation.key);\n              }\n            }\n            return true;\n          })\n        );\n      };\n    }\n\n    return cacheExchange(opts)(input);\n  };\n"],"names":["helpUrl","cache","Set","currentDebugStack","popDebugNode","pop","pushDebugNode","typename","node","identifier","kind","Kind","INLINE_FRAGMENT","OPERATION_DEFINITION","name","value","operation","FRAGMENT_DEFINITION","push","getDebugOutput","length","join","invariant","condition","message","code","errorMessage","process","env","NODE_ENV","error","Error","warn","logger","has","console","add","EMPTY_DIRECTIVES","getDirectives","_directives","getName","getFragmentTypeName","typeCondition","getFieldAlias","alias","emptySelectionSet","getSelectionSet","selectionSet","selections","getTypeCondition","getFieldArguments","vars","args","arguments","i","l","arg","valueFromASTUntyped","filterVariables","input","variableDefinitions","variable","normalizeVariables","def","undefined","defaultValue","key","getMainOperation","doc","definitions","getFragments","fragments","shouldInclude","directives","include","skip","directive","isDeferred","defer","argument","isOptional","optional","required","BUILTIN_NAME","isFieldNullable","schema","fieldName","field","getField","type","isListNullable","ofType","isFieldAvailableOnType","indexOf","isInterfaceOfType","types","get","expectAbstractType","expectObjectType","isSubType","fields","warnAboutResolver","warnAboutAbstractResolver","keyOfField","stringifyVariables","joinKeys","parentKey","fieldInfoOfKey","fieldKey","parenIndex","slice","JSON","parse","deserializeKeyInfo","dotIndex","entityKey","replace","currentOwnership","currentDataMapping","currentData","currentOptimisticKey","currentOperation","currentDependencies","currentForeignData","currentOptimistic","makeData","data","isArray","newData","set","ownsData","initDataState","operationType","layerKey","isOptimistic","isForeignData","WeakSet","WeakMap","hydrating","optimisticOrder","commutativeKeys","reserveLayer","splice","delete","createLayer","deleteLayer","clearDataState","getCurrentDependencies","dirtyKeys","squashLayer","storage","setTimeout","gc","persistData","noopDataState","deferredKeys","DEFAULT_EMPTY_SET","setNode","map","keymap","optimistic","base","entity","Object","create","getNode","getRefCount","refCount","updateRCForLink","link","by","Array","updateRCForEntity","count","newCount","extractNodeFields","fieldInfos","seenFieldKeys","extractNodeMapFields","keys","record","records","__typename","linkNode","links","updateDependencies","queryRootKey","updatePersist","persist","serializeKeys","readRecord","readLink","writeConcreteType","abstractType","concreteType","existingTypes","abstractToConcreteMap","typeSet","writeRecord","isEqualLinkOrScalar","hasField","writeLink","entityLinks","hasNext","index","clearLayer","unshift","Map","previousDependencies","entry","entries","keyMap","inspectFields","x","writeData","clear","a","b","some","el","contextRef","deferRef","optionalRef","getFieldError","ctx","__internal","path","errorMap","makeContext","store","variables","parent","parentTypeName","parentFieldKey","partial","graphQLErrors","graphQLError","updateContext","isFragmentHeuristicallyMatching","FIELD","SelectionIterator","constructor","_defer","_optional","this","stack","next","state","select","fragment","isMatching","isFragmentMatching","isFragmentOptional","_generated","isProbableAbstractType","isSeenConcreteType","getConcreteTypes","size","ensureData","ensureLink","ref","keyOfEntity","_query","request","query","formatDocument","rootKey","rootFields","rootSelect","readRoot","InMemoryData","readSelection","dependencies","rootNames","selection","hasChanged","output","fieldAlias","fieldValue","dataFieldValue","readRootField","originalData","getFieldResolver","resolvers","fieldResolver","directiveResolver","directiveNode","result","isQuery","mutation","subscription","hasFields","hasPartials","fieldArgs","resolver","resultValue","resolveResolverResult","resolveLink","stringify","prevData","isOwnedData","_isListNullable","childResult","isDataOrKey","newLink","childLink","invalidateEntity","invalidateType","excludedEntities","includes","_write","writeSelection","rootField","isRoot","writeType","updates","optimisticMutations","writeField","updater","resolved","KEYLESS_TYPE_RE","prevLink","indexKey","test","childKey","Store","opts","globalIDs","queryName","mutationName","subscriptionName","buildClientSchema","__schema","typemap","buildNameMap","arr","buildType","interfaces","possibleTypes","queryType","mutationType","subscriptionType","abstract","possible","possibleType","out","expectValidKeyingConfig","expectValidUpdatesConfig","addition","expectValidResolversConfig","validQueries","resolverQuery","Query","validTypeProperties","resolverProperty","expectValidOptimisticMutationsConfig","validMutations","id","_id","resolve","fieldLink","invalidate","updateQuery","createRequest","readQuery","readFragment","fragmentName","_queryFragment","writeFragment","_writeFragment","dataToWrite","rest","addMetadata","meta","makeOperation","context","toRequestPolicy","requestPolicy","cacheExchange","forward","client","dispatchDebug","readData","then","hydrateData","onCacheHydrated","optimisticKeysToDependencies","mutationResultBuffer","operations","results","blockedDependencies","requestedRefetch","deps","reexecutingOperations","dependentOperations","isBlockedByOptimisticUpdate","dep","values","collectPendingOperations","pendingOperations","executePendingOperations","op","policy","reexecuteOperation","_reexecutingOperations","prepareForwardedOperation","depOps","operationResultFromCache","cacheOutcome","outcome","updateCacheWithResult","queryDependencies","writeDependencies","queryResult","extensions","stale","operations$","cacheOps$","share","filter","nonCacheOps$","cacheMissOps$","res","source","cacheResult$","shouldReexecute","hasLayer","result$","merge","nonOptimisticResults$","cacheResult","optimisticMutationCompletion$","mergeMap","empty","bufferedResult","shift","fromArray","policyLevel","offlineExchange","isOfflineError","networkError","response","navigator","onLine","onOnline","readMetadata","writeMetadata","outerForward","reboundOps$","makeSubject","failedQueue","hasRehydrated","isFlushingQueue","updateMetadata","requests","stringifyDocument","filterQueue","flushQueue","sent","overridePolicy","cacheResults$","hydrate","onEntries","mutations","createRequestOperation","ops$","opsAndRebound$","onPush"],"mappings":";;;;;;AA6CA,IAAMA,IAAU;;AAChB,IAAMC,IAAQ,IAAIC;;AAEX,IAAMC,IAA8B;;AAEpC,IAAMC,eAAeA,MAAMD,EAAkBE;;AAE7C,IAAMC,gBAAgBA,CAACC,GAAyBC;EACrD,IAAIC,IAAa;EACjB,IAAID,EAAKE,SAASC,EAAKC;IACrBH,IAAaF,IACT,uBAAuBA,OACvB;SACC,IAAIC,EAAKE,SAASC,EAAKE,sBAAsB;IAElDJ,IAAa,GADAD,EAAKM,OAAO,IAAIN,EAAKM,KAAKC,WAAW,aAC1BP,EAAKQ;AAC9B,SAAM,IAAIR,EAAKE,SAASC,EAAKM;IAC5BR,IAAa,IAAID,EAAKM,KAAKC;;EAG7B,IAAIN;IACFN,EAAkBe,KAAKT;;AACzB;;AAGF,IAAMU,iBAAiBA,MACrBhB,EAAkBiB,SACd,mBAAmBjB,EAAkBkB,KAAK,QAAQ,MAClD;;AAEC,SAASC,UACdC,GACAC,GACAC;EAEA,KAAKF,GAAW;IACd,IAAIG,IAAeF,KAAW,oBAAoBC,IAAO;IACzD,IAA6B,iBAAzBE,QAAQC,IAAIC;MACdH,KAAgBP;;IAGlB,IAAMW,IAAQ,IAAIC,MAAML,IAAe1B,IAAUyB;IACjDK,EAAMhB,OAAO;IACb,MAAMgB;AACR;AACF;;AAEO,SAASE,KACdR,GACAC,GACAQ;EAEA,KAAKhC,EAAMiC,IAAIV,IAAU;IACvB,IAAIS;MACFA,EAAO,QAAQT,IAAUL,mBAAmBnB,IAAUyB;;MAEtDU,QAAQH,KAAKR,IAAUL,mBAAmBnB,IAAUyB;;IAEtDxB,EAAMmC,IAAIZ;AACZ;AACF;;AC3FA,IAAMa,IAA8D,CAAA;;AAG7D,IAAMC,gBAAiB9B,KAExBA,EAAK+B,eAAeF;;AAGnB,IAAMG,UAAWhC,KAAqCA,EAAKM,KAAKC;;AAEhE,IAAM0B,sBAAuBjC,KAClCA,EAAKkC,cAAc5B,KAAKC;;AAGnB,IAAM4B,gBAAiBnC,KAC5BA,EAAKoC,QAAQpC,EAAKoC,MAAM7B,QAAQP,EAAKM,KAAKC;;AAE5C,IAAM8B,IAAkC;;AAGjC,IAAMC,kBAAmBtC,KAG7BA,EAAKuC,eACFvC,EAAKuC,aAAaC,aAClBH;;AAEC,IAAMI,mBAAoBzC,KAG/BA,EAAKkC,gBAAgBlC,EAAKkC,cAAc5B,KAAKC,QAAQ;;AChChD,IAAMmC,oBAAoBA,CAC/B1C,GACA2C;EAEA,IAAIC,IAAyB;EAC7B,IAAI5C,EAAK6C;IACP,KAAK,IAAIC,IAAI,GAAGC,IAAI/C,EAAK6C,UAAUjC,QAAQkC,IAAIC,GAAGD,KAAK;MACrD,IAAME,IAAMhD,EAAK6C,UAAUC;MAC3B,IAAMvC,IAAQ0C,EAAoBD,EAAIzC,OAAOoC;MAC7C,IAAIpC,WAAuC;QACzC,KAAKqC;UAAMA,IAAO;;QAClBA,EAAKZ,QAAQgB,MAAQzC;AACvB;AACF;;EAEF,OAAOqC;AAAI;;AAIN,IAAMM,kBAAkBA,CAC7BlD,GACAmD;EAEA,KAAKA,MAAUnD,EAAKoD;IAClB;;EAGF,IAAMT,IAAO,CAAA;EACb,KAAK,IAAIG,IAAI,GAAGC,IAAI/C,EAAKoD,oBAAoBxC,QAAQkC,IAAIC,GAAGD,KAAK;IAC/D,IAAMxC,IAAO0B,QAAQhC,EAAKoD,oBAAoBN,GAAGO;IACjDV,EAAKrC,KAAQ6C,EAAM7C;AACrB;EAEA,OAAOqC;AAAI;;AAIN,IAAMW,qBAAqBA,CAChCtD,GACAmD;EAEA,IAAMR,IAAO,CAAA;EACb,KAAKQ;IAAO,OAAOR;;EAEnB,IAAI3C,EAAKoD;IACP,KAAK,IAAIN,IAAI,GAAGC,IAAI/C,EAAKoD,oBAAoBxC,QAAQkC,IAAIC,GAAGD,KAAK;MAC/D,IAAMS,IAAMvD,EAAKoD,oBAAoBN;MACrC,IAAMxC,IAAO0B,QAAQuB,EAAIF;MACzBV,EAAKrC,UACakD,MAAhBL,EAAM7C,MAAuBiD,EAAIE,eAC7BR,EAAoBM,EAAIE,cAAcN,KACtCA,EAAM7C;AACd;;EAGF,KAAK,IAAMoD,KAAOP;IAChB,MAAMO,KAAOf;MAAOA,EAAKe,KAAOP,EAAMO;;;EAGxC,OAAOf;AAAI;;ACnDb,SAASgB,iBAAiBC;EACxB,KAAK,IAAId,IAAI,GAAGA,IAAIc,EAAIC,YAAYjD,QAAQkC;IAC1C,IAAIc,EAAIC,YAAYf,GAAG5C,SAASC,EAAKE;MACnC,OAAOuD,EAAIC,YAAYf;;;EAI3BhC,WACE,GAAK,iBAAAK,QAAAC,IAAAC,WACL,oIACgD,IAChD;AAEJ;;AAKO,IAAMyC,eAAgBF;EAC3B,IAAMG,IAAuB,CAAA;EAC7B,KAAK,IAAIjB,IAAI,GAAGA,IAAIc,EAAIC,YAAYjD,QAAQkC,KAAK;IAC/C,IAAM9C,IAAO4D,EAAIC,YAAYf;IAC7B,IAAI9C,EAAKE,SAASC,EAAKM;MACrBsD,EAAU/B,QAAQhC,MAASA;;AAE/B;EAEA,OAAO+D;AAAS;;AAIX,IAAMC,gBAAgBA,CAC3BhE,GACA2C;EAEA,IAAMsB,IAAanC,cAAc9B;EACjC,IAAIiE,EAAWC,WAAWD,EAAWE;IAEnC,KAAK,IAAM7D,KAAQ2D,GAAY;MAC7B,IAAMG,IAAYH,EAAW3D;MAC7B,IACE8D,MACU,cAAT9D,KAA+B,WAATA,MACvB8D,EAAUvB,aACVuB,EAAUvB,UAAU,MACgB,SAApCb,QAAQoC,EAAUvB,UAAU,KAC5B;QAGA,IAAMtC,IAAQ0C,EAAoBmB,EAAUvB,UAAU,GAAGtC,OAAOoC;QAChE,OAAgB,cAATrC,MAAuBC,KAASA;AACzC;AACF;;EAEF,QAAO;AAAI;;AAIN,IAAM8D,aAAaA,CACxBrE,GACA2C;EAEA,KAAM2B,OAAEA,KAAUxC,cAAc9B;EAChC,IAAIsE,GAAO;IACT,KAAK,IAAMC,KAAYD,EAAMzB,aAAa;MACxC,IAA0B,SAAtBb,QAAQuC;QAEV,SAAStB,EAAoBsB,EAAShE,OAAOoC;;;IAGjD,QAAO;AACT;EAEA,QAAO;AAAK;;AAIP,IAAM6B,aACXxE;EAEA,KAAMyE,UAAEA,GAAQC,UAAEA,KAAa5C,cAAc9B;EAC7C,IAAI0E;IACF,QAAO;;EAGT,IAAID;IACF,QAAO;;EAGT;AAAgB;;AC5FlB,IAAME,IAAe;;AAEd,IAAMC,kBAAkBA,CAC7BC,GACA9E,GACA+E,GACArD;EAEA,IAAMsD,IAAQC,SAASH,GAAQ9E,GAAU+E,GAAWrD;EACpD,SAASsD,KAA6B,eAApBA,EAAME,KAAK/E;AAAmB;;AAG3C,IAAMgF,iBAAiBA,CAC5BL,GACA9E,GACA+E,GACArD;EAEA,IAAMsD,IAAQC,SAASH,GAAQ9E,GAAU+E,GAAWrD;EACpD,KAAKsD;IAAO,QAAO;;EACnB,IAAMI,IACgB,eAApBJ,EAAME,KAAK/E,OAAsB6E,EAAME,KAAKE,SAASJ,EAAME;EAC7D,OAAuB,WAAhBE,EAAOjF,QAA0C,eAAvBiF,EAAOA,OAAOjF;AAAmB;;AAG7D,IAAMkF,yBAAyBA,CACpCP,GACA9E,GACA+E,GACArD,MAEoC,MAApCqD,EAAUO,QAAQV,MACiB,MAAnC5E,EAASsF,QAAQV,QACfK,SAASH,GAAQ9E,GAAU+E,GAAWrD;;AAEnC,IAAM6D,oBAAoBA,CAC/BT,GACA7E,GACAD;EAEA,KAAKA;IAAU,QAAO;;EACtB,IAAMmC,IAAgBO,iBAAiBzC;EACvC,KAAKkC,KAAiBnC,MAAamC;IACjC,QAAO;SACF,IACL2C,EAAOU,MAAO7D,IAAIQ,MACyB,aAA3C2C,EAAOU,MAAOC,IAAItD,GAAgBhC;IAElC,OAAOgC,MAAkBnC;;GAoD7B,SAAS0F,mBAAmBZ,GAA4B9E;IACtDe,UACE+D,EAAOU,MAAO7D,IAAI3B,OACuB,gBAAtC8E,EAAOU,MAAOC,IAAIzF,GAAWG,QACU,YAAtC2E,EAAOU,MAAOC,IAAIzF,GAAWG,OAAiB,iBAAAiB,QAAAC,IAAAC,WAClD,sCACEtB,IADF,uIAIA,IAAA;AAEJ,GA5DE0F,CAAmBZ,GAAQ3C;EAC3BwD,iBAAiBb,GAAQ9E;EACzB,OAAO8E,EAAOc,UAAUzD,GAAenC;AAAS;;AAGlD,IAAMiF,WAAWA,CACfH,GACA9E,GACA+E,GACArD;EAEA,IACsC,MAApCqD,EAAUO,QAAQV,MACiB,MAAnC5E,EAASsF,QAAQV;IAEjB;;EAEFe,iBAAiBb,GAAQ9E;EAEzB,IAAMgF,IADSF,EAAOU,MAAOC,IAAIzF,GACZ6F,SAASd;EAAW,IAAA,iBAAA3D,QAAAC,IAAAC;IACzC,KAAK0D;MACHvD,KACE,+BACEsD,IACA,0BACA/E,IAHF,2HAOA,GACA0B;;;EAIJ,OAAOsD;AAAK;;AAGd,SAASW,iBAAiBb,GAA4B9E;EACpDe,UACE+D,EAAOU,MAAO7D,IAAI3B,MACsB,aAAtC8E,EAAOU,MAAOC,IAAIzF,GAAWG,MAAiB,iBAAAiB,QAAAC,IAAAC,WAChD,oCACEtB,IADF,yFAG8C,IAC9C;AAEJ;;AA6FA,SAAS8F,kBAAkBvF,GAAcmB;mBACvCN,QAAAC,IAAAC,YAAAG,KACE,uBAAuBlB,qFACvB,IACAmB;AAEJ;;AAEA,SAASqE,0BACPxF,GACAJ,GACAuB;mBAEAN,QAAAC,IAAAC,YAAAG,KACE,uBAAuBlB,kJACZ,YAATJ,IAAmB,sBAAsB,sCAE3C,IACAuB;AAEJ;;ACjOO,IAAMsE,aAAaA,CAACjB,GAAmBlC,MAC5CA,IAAO,GAAGkC,KAAakB,EAAmBpD,QAAWkC;;AAEhD,IAAMmB,WAAWA,CAACC,GAAmBxC,MAC1C,GAAGwC,KAAaxC;;AAEX,IAAMyC,iBAAkBC;EAC7B,IAAMC,IAAaD,EAASf,QAAQ;EACpC,IAAIgB,KAAc;IAChB,OAAO;MACLD;MACAtB,WAAWsB,EAASE,MAAM,GAAGD;MAC7BxD,WAAW0D,KAAKC,MAAMJ,EAASE,MAAMD,IAAa,IAAI;;;IAGxD,OAAO;MACLD;MACAtB,WAAWsB;MACXvD,WAAW;;;AAEf;;AAMK,IAAM4D,qBAAsB/C;EACjC,IAAMgD,IAAWhD,EAAI2B,QAAQ;EAG7B,OAAO;IAAEsB,WAFSjD,EAAI4C,MAAM,GAAGI,GAAUE,QAAQ,QAAQ;IAErCR,UADH1C,EAAI4C,MAAMI,IAAW;;AACR;;ACgChC,IAAIG,IAAwC;;AAC5C,IAAIC,IAA+C;;AACnD,IAAIC,IAAmC;;AACvC,IAAIC,IAAsC;;AACnC,IAAIC,IAAyC;;AAC7C,IAAIC,IAA2C;;AAC/C,IAAIC,KAAqB;;AACzB,IAAIC,KAAoB;;AAMxB,SAASC,SAASC,GAAyBC;EAChD,IAAIC;EACJ,IAAIF,GAAM;IACR,IAAIT,EAAkBnF,IAAI4F;MAAO,OAAOA;;IACxCE,IAAUV,EAAoBtB,IAAI8B;AACpC;EAEA,IAAe,QAAXE;IACFA,IAAWD,IAAU,KAAK;;EAG5B,IAAID;IACFR,EAAoBW,IAAIH,GAAME;;EAGhCX,EAAkBjF,IAAI4F;EACtB,OAAOA;AACT;;AAEO,IAAME,WAAYJ,OACrBA,KAAQT,EAAkBnF,IAAI4F;;AAG3B,IAAMK,gBAAgBA,CAC3BC,GACAN,GACAO,GACAC,GACAC;EAEAlB,IAAmB,IAAImB;EACvBlB,IAAqB,IAAImB;EACzBhB,IAAmBW;EACnBb,IAAcO;EACdJ,IAAsB,IAAIxH;EAC1B0H,MAAsBU;EACtBX,MAAuBY;EACvB,IAA6B,iBAAzB5G,QAAQC,IAAIC;IACd1B,EAAkBiB,SAAS;;EAG7B,KAAKiH;IACHb,IAAuB;SAClB,IAAyB,WAArBC;IAGTD,IAAuBa;SAClB,IACLC,KACAR,EAAKY,aACLZ,EAAKa,gBAAgBvH,SAAS,GAC9B;IAIA,KAAKkH,MAAiBR,EAAKc,gBAAgB1G,IAAImG;MAC7CQ,aAAaf,GAAMO;WACd,IAAIC,GAAc;MACvB,KAC8C,MAA5CR,EAAKa,gBAAgB9C,QAAQwC,OAC5BP,EAAKc,gBAAgB1G,IAAImG;QAE1BP,EAAKa,gBAAgBG,OAAOhB,EAAKa,gBAAgB9C,QAAQwC,IAAW;;MAItEP,EAAKc,gBAAgBG,OAAOV;AAC9B;IAKAb,IAAuBa;IACvBW,YAAYlB,GAAMO;AACpB,SAAO;IAKLb,IAAuB;IACvByB,YAAYnB,GAAMO;AACpB;AAAA;;AAIK,IAAMa,iBAAiBA;EAE5B,IAA6B,iBAAzBvH,QAAQC,IAAIC;IACdsH;;EAGF,IAAMrB,IAAOP;EACb,IAAMc,IAAWb;EACjBI,KAAoB;EACpBJ,IAAuB;EAGvB,KACGM,EAAKY,aACNL,KACAP,EAAKa,gBAAgB9C,QAAQwC,MAAa,GAC1C;IAGA,IAAI/E,IAAIwE,EAAKa,gBAAgBvH;IAC7B,SACIkC,KAAK,KACPwE,EAAKsB,UAAUlH,IAAI4F,EAAKa,gBAAgBrF,OACxCwE,EAAKc,gBAAgB1G,IAAI4F,EAAKa,gBAAgBrF;MAE9C+F,YAAYvB,EAAKa,gBAAgBrF;;AACrC;EAEA+D,IAAmB;EACnBC,IAAqB;EACrBG,IAAmB;EACnBF,IAAc;EACdG,IAAsB;EACtB,IAA6B,iBAAzB/F,QAAQC,IAAIC;IACd1B,EAAkBiB,SAAS;;EAG7B,IAA6B,WAAzBO,QAAQC,IAAIC;IAGd,KAAKiG,EAAKhD,UAAUgD,EAAKwB,YAAYxB,EAAKa,gBAAgBvH,SAAS;MACjE0G,EAAKhD,SAAQ;MACbyE,YAAW;QACTpB,cAAc,QAAQL,GAAM;QAC5B0B;QACAC;QACAP;QACApB,EAAKhD,SAAQ;AAAK;AAEtB;;AACF;;AAIK,IAAM4E,gBAAgBA,CAC3B5B,GACAO,GACAC;EAEA,IAAID,MAAaC;IAAcR,EAAK6B,aAAaZ,OAAOV;;EACxDF,cAAc,SAASL,GAAMO,GAAUC;EACvCY;AAAgB;;AAIX,IAAMC,yBAAyBA;EACpC7H,UAC0B,SAAxBoG,GAA4B,iBAAA/F,QAAAC,IAAAC,WAC5B,sKAE0B,IAC1B;EAGF,OAAO6F;AAAmB;;AAG5B,IAAMkC,IAAoB,IAAI1J;;AA0B9B,IAAM2J,UAAUA,CACdC,GACA3C,GACAP,GACA7F;EAEA,IAA6B,iBAAzBY,QAAQC,IAAIC;IACdP,UACuB,WAArBmG,GAA2B,iBAAA9F,QAAAC,IAAAC,WAC3B,wMAEiD,IACjD;;EAMJ,IAAMkI,IAAsCvC,IACxCsC,EAAIE,WAAWhE,IAAIwB,KACnBsC,EAAIG;EAGR,IAAIC,IAASH,EAAO/D,IAAImB;EACxB,SAAenD,MAAXkG;IACFH,EAAO9B,IAAId,GAAY+C,IAASC,OAAOC,OAAO;;EAMhD,SAAcpG,MAAVjD,MAAwByG;WACnB0C,EAAOtD;;IAEdsD,EAAOtD,KAAY7F;;AACrB;;AAIF,IAAMsJ,UAAUA,CACdP,GACA3C,GACAP;EAEA,IAAIpG;EAGJ,IAAImE,KACDiD,KACoB,WAArBH,KACAD,KACAD,EAAaqB,gBAAgB1G,IAAIsF;EAEnC,KAAK,IAAIlE,IAAI,GAAGC,IAAIgE,EAAaoB,gBAAgBvH,QAAQkC,IAAIC,GAAGD,KAAK;IACnE,IAAM+E,IAAWd,EAAaoB,gBAAgBrF;IAC9C,IAAM0G,IAAaF,EAAIE,WAAWhE,IAAIqC;IAEtC1D,IAAOA,KAAQ0D,MAAab;IAE5B,IACEwC,OACErF,MAAS4C,EAAaqB,gBAAgB1G,IAAImG,SAC1CT,KACqB,YAArBH,KACAF,EAAaqB,gBAAgB1G,IAAImG,YACIrE,OAAtCxD,IAAOwJ,EAAWhE,IAAImB,OACvBP,KAAYpG;MAEZ,OAAOA,EAAKoG;;AAEhB;EAIA,YAAgB5C,OADhBxD,IAAOsJ,EAAIG,KAAKjE,IAAImB,MACQ3G,EAAKoG,UAAY5C;AAAS;;AAGjD,SAASsG,YAAYnD;EAC1B,OAAOI,EAAagD,SAASvE,IAAImB,MAAc;AACjD;;AAeA,IAAMqD,kBAAkBA,CAACC,GAAwBC;EAC/C,IAAIC,MAAM5C,QAAQ0C;IAChB,KAAK,IAAInH,IAAI,GAAGC,IAAIkH,EAAKrJ,QAAQkC,IAAIC,GAAGD;MAAKkH,gBAAgBC,EAAKnH,IAAIoH;;SACjE,IAAoB,mBAATD;IAfMG,EAACzD,GAAmBuD;MAE5C,IAAMG,IAAQP,YAAYnD;MAC1B,IAAM2D,IAAWD,IAAQH,IAAK,IAAIG,IAAQH,IAAK;MAC/CnD,EAAagD,SAAStC,IAAId,GAAW2D;MAGrC,KAAKA;QAAUvD,EAAaiC,GAAGpH,IAAI+E;aAC9B,KAAK0D,KAASC;QAAUvD,EAAaiC,GAAGT,OAAO5B;;AAAU,MAQ5DyD,CAAkBH,GAAMC;;AAC1B;;AAIF,IAAMK,oBAAoBA,CACxBC,GACAC,GACAzK;EAEA,SAAawD,MAATxD;IACF,KAAK,IAAMoG,KAAYpG;MACrB,KAAKyK,EAAc/I,IAAI0E,IAAW;QAGhCoE,EAAW9J,KAAKyF,eAAeC;QAC/BqE,EAAc7I,IAAIwE;AACpB;;;AAEJ;;AAIF,IAAMsE,uBAAuBA,CAC3BF,GACAC,GACA9D,GACA2C;EAGAiB,kBAAkBC,GAAYC,GAAenB,EAAIG,KAAKjE,IAAImB;EAG1D,KAAK,IAAI7D,IAAI,GAAGC,IAAIgE,EAAaoB,gBAAgBvH,QAAQkC,IAAIC,GAAGD,KAAK;IACnE,IAAM0G,IAAaF,EAAIE,WAAWhE,IAAIuB,EAAaoB,gBAAgBrF;IACnE,SAAmBU,MAAfgG;MACFe,kBAAkBC,GAAYC,GAAejB,EAAWhE,IAAImB;;AAEhE;AAAA;;AAIK,IAAMqC,KAAKA;EAEhB,IAAIjC,EAAaoB,gBAAgBvH;IAAQ;;EAKzC,KAAK,IAAM+F,KAAaI,EAAaiC,GAAG2B,QAAQ;IAE9C5D,EAAaiC,GAAGT,OAAO5B;IAKvB,IADWmD,YAAYnD,KACd;MAAG;;IAEZ,IAAMiE,IAAS7D,EAAa8D,QAAQpB,KAAKjE,IAAImB;IAE7CI,EAAagD,SAASxB,OAAO5B;IAC7BI,EAAa8D,QAAQpB,KAAKlB,OAAO5B;IAEjC,IAAM5G,IAAY6K,KAAUA,EAAOE;IACnC,IAAI/K,GAAU;MACZ,IAAMkF,IAAO8B,EAAaxB,MAAMC,IAAIzF;MACpC,IAAIkF;QAAMA,EAAKsD,OAAO5B;;AACxB;IAEA,IAAMoE,IAAWhE,EAAaiE,MAAMvB,KAAKjE,IAAImB;IAC7C,IAAIoE,GAAU;MACZhE,EAAaiE,MAAMvB,KAAKlB,OAAO5B;MAC/B,KAAK,IAAMP,KAAY2E;QAAUf,gBAAgBe,EAAS3E,KAAY;;AACxE;AACF;AAAA;;AAGF,IAAM6E,qBAAqBA,CAACtE,GAAmBP;EAC7C,IAAIO,MAAcI,EAAamE;IAC7BhE,EAAqBtF,IAAI+E;SACpB,SAAiBnD,MAAb4C,KAAuC,iBAAbA;IACnCc,EAAqBtF,IAAIqE,SAASU,GAAWP;;AAC/C;;AAGF,IAAM+E,gBAAgBA,CAACxE,GAAmBP;EACxC,KAAKgB,KAAqBL,EAAa+B;IACrC/B,EAAaqE,QAAQxJ,IDzaIyJ,EAAC1E,GAAmBP,MAC/C,GAAGO,EAAUC,QAAQ,OAAO,UAAUR,ICwaXiF,CAAc1E,GAAWP;;AACpD;;AAIK,IAAMkF,aAAaA,CACxB3E,GACAP;EAEA,IAAyB,WAArBa;IACFgE,mBAAmBtE,GAAWP;;EAEhC,OAAOyD,QAAQ9C,EAAa8D,SAASlE,GAAWP;AAAS;;AAIpD,IAAMmF,WAAWA,CACtB5E,GACAP;EAEA,IAAyB,WAArBa;IACFgE,mBAAmBtE,GAAWP;;EAEhC,OAAOyD,QAAQ9C,EAAaiE,OAAOrE,GAAWP;AAAS;;AAuBlD,IAAMoF,oBAAoBA,CAC/BC,GACAC;EAEA,IAAMC,IAAgB5E,EAAa6E,sBAAsBpG,IAAIiG;EAC7D,KAAKE,GAAe;IAClB,IAAME,IAAU,IAAInM;IACpBmM,EAAQjK,IAAI8J;IACZ3E,EAAa6E,sBAAsBnE,IAAIgE,GAAcI;AACvD;IACEF,EAAc/J,IAAI8J;;AACpB;;AAIK,IAAMI,cAAcA,CACzBnF,GACAP,GACA7F;EAGA,KAAKwL,oBADYlC,QAAQ9C,EAAa8D,SAASlE,GAAWP,IACvB7F,IAAQ;IACzC0K,mBAAmBtE,GAAWP;IAC9B+E,cAAcxE,GAAWP;AAC3B;EAEAiD,QAAQtC,EAAa8D,SAASlE,GAAWP,GAAU7F;AAAM;;AAGpD,IAAMyL,WAAWA,CAACrF,GAAmBP,WACN5C,MAApC8H,WAAW3E,GAAWP,WACY5C,MAAlC+H,SAAS5E,GAAWP;;AAGf,IAAM6F,YAAYA,CACvBtF,GACAP,GACA6D;EAGA,IAAMe,IAAQhE,IACVD,EAAaiE,MAAMxB,WAAWhE,IAAIwB,KAClCD,EAAaiE,MAAMvB;EAEvB,KAAKzC,GAAsB;IACzB,IAAMkF,IAAclB,KAASA,EAAMxF,IAAImB;IACvCqD,gBAAgBkC,KAAeA,EAAY9F,KAAY;IACvD4D,gBAAgBC,GAAM;AACxB;EAEA,KAAK8B,oBADYlC,QAAQ9C,EAAaiE,OAAOrE,GAAWP,IACrB6D,IAAO;IACxCgB,mBAAmBtE,GAAWP;IAC9B+E,cAAcxE,GAAWP;AAC3B;EAGAiD,QAAQtC,EAAaiE,OAAOrE,GAAWP,GAAU6D;AAAK;;AAIjD,IAAM5B,eAAeA,CAC1Bf,GACAO,GACAsE;EAIA,IAAIC,IAAQ9E,EAAKa,gBAAgB9C,QAAQwC;EACzC,IAAIuE,KAAS;IAAG9E,EAAKa,gBAAgBG,OAAO8D,GAAO;;EAEnD,IAAID,GAAS;IACX7E,EAAK6B,aAAavH,IAAIiG;IAGtB,KACEuE,IAAQA,KAAS,IAAIA,IAAQ,GAC7BA,IAAQ9E,EAAKa,gBAAgBvH,WAC5B0G,EAAK6B,aAAazH,IAAI4F,EAAKa,gBAAgBiE,SAC1C9E,EAAKsB,UAAUlH,IAAI4F,EAAKa,gBAAgBiE,QACvC9E,EAAKc,gBAAgB1G,IAAI4F,EAAKa,gBAAgBiE,MACjDA;AAEJ,SAAO;IACL9E,EAAK6B,aAAaZ,OAAOV;IAGzB,IAAIuE,KAAS,MAAM9E,EAAKc,gBAAgB1G,IAAImG;MAC1CwE,WAAW/E,GAAMO;;IACnBuE,IAAQ;AACV;EAIA9E,EAAKa,gBAAgBG,OAAO8D,GAAO,GAAGvE;EACtCP,EAAKc,gBAAgBxG,IAAIiG;AAAS;;AASpC,IAAMW,cAAcA,CAAClB,GAAoBO;EACvC,KAAgD,MAA5CP,EAAKa,gBAAgB9C,QAAQwC;IAC/BP,EAAKa,gBAAgBmE,QAAQzE;;EAG/B,KAAKP,EAAKsB,UAAUlH,IAAImG,IAAW;IACjCP,EAAKsB,UAAUhH,IAAIiG;IACnBP,EAAK0D,MAAMxB,WAAW/B,IAAII,GAAU,IAAI0E;IACxCjF,EAAKuD,QAAQrB,WAAW/B,IAAII,GAAU,IAAI0E;AAC5C;AAAA;;AAIF,IAAMF,aAAaA,CAAC/E,GAAoBO;EACtC,IAAIP,EAAKsB,UAAUlH,IAAImG,IAAW;IAChCP,EAAKsB,UAAUL,OAAOV;IACtBP,EAAKuD,QAAQrB,WAAWjB,OAAOV;IAC/BP,EAAK0D,MAAMxB,WAAWjB,OAAOV;IAC7BP,EAAK6B,aAAaZ,OAAOV;AAC3B;AAAA;;AAIF,IAAMY,cAAcA,CAACnB,GAAoBO;EACvC,IAAMuE,IAAQ9E,EAAKa,gBAAgB9C,QAAQwC;EAC3C,IAAIuE,KAAS,GAAG;IACd9E,EAAKa,gBAAgBG,OAAO8D,GAAO;IACnC9E,EAAKc,gBAAgBG,OAAOV;AAC9B;EAEAwE,WAAW/E,GAAMO;AAAS;;AAI5B,IAAMgB,cAAehB;EAEnB,IAAM2E,IAAuBtF;EAC7BA,IAAsB,IAAIxH;EAC1BuH,IAAmB;EAEnB,IAAM+D,IAAQjE,EAAaiE,MAAMxB,WAAWhE,IAAIqC;EAChD,IAAImD;IACF,KAAK,IAAMyB,KAASzB,EAAM0B,WAAW;MACnC,IAAM/F,IAAY8F,EAAM;MACxB,IAAME,IAASF,EAAM;MACrB,KAAK,IAAMrG,KAAYuG;QACrBV,UAAUtF,GAAWP,GAAUuG,EAAOvG;;AAE1C;;EAGF,IAAMyE,IAAU9D,EAAa8D,QAAQrB,WAAWhE,IAAIqC;EACpD,IAAIgD;IACF,KAAK,IAAM4B,KAAS5B,EAAQ6B,WAAW;MACrC,IAAM/F,IAAY8F,EAAM;MACxB,IAAME,IAASF,EAAM;MACrB,KAAK,IAAMrG,KAAYuG;QACrBb,YAAYnF,GAAWP,GAAUuG,EAAOvG;;AAE5C;;EAGFc,IAAsBsF;EACtB/D,YAAY1B,GAAcc;AAAS;;AAI9B,IAAM+E,gBAAiBjG;EAC5B,KAAMqE,OAAEA,GAAKH,SAAEA,KAAY9D;EAC3B,IAAMyD,IAA0B;EAChC,IAAMC,IAA6B,IAAI/K;EAEvCuL,mBAAmBtE;EAGnB+D,qBAAqBF,GAAYC,GAAe9D,GAAWqE;EAC3DN,qBAAqBF,GAAYC,GAAe9D,GAAWkE;EAC3D,OAAOL;AAAU;;AAGZ,IAAMvB,cAAcA;EACzB,IAAIlC,EAAa+B,SAAS;IACxB1B,KAAoB;IACpBH,IAAmB;IACnB,IAAMyF,IAA6B,CAAA;IACnC,KAAK,IAAMhJ,KAAOqD,EAAaqE,QAAQT,QAAQ;MAC7C,KAAMhE,WAAEA,GAASP,UAAEA,KAAaK,mBAAmB/C;MACnD,IAAImJ,SAA4B;MAChC,SAA4CrJ,OAAvCqJ,IAAItB,SAAS5E,GAAWP;QAC3BsG,EAAQhJ,KAAO,IAAIsC,EAAmB6G;aACjC,SAA8CrJ,OAAzCqJ,IAAIvB,WAAW3E,GAAWP;QACpCsG,EAAQhJ,KAAOsC,EAAmB6G;;QAElCH,EAAQhJ,UAAOF;;AAEnB;IAEA4D,KAAoB;IACpBL,EAAa+B,QAAQgE,UAAUJ;IAC/B3F,EAAaqE,QAAQ2B;AACvB;AAAA;;AA6BF,SAAShB,oBACPiB,GACAC;EAEA,WAAWD,YAAaC;IAAG,QAAO;;EAClC,IAAID,MAAMC;IAAG,QAAO;;EACpB,IAAI9C,MAAM5C,QAAQyF,MAAM7C,MAAM5C,QAAQ0F,IAAI;IACxC,IAAID,EAAEpM,WAAWqM,EAAErM;MAAQ,QAAO;;IAClC,QAAQoM,EAAEE,MAAK,CAACC,GAAIf,MAAUe,MAAOF,EAAEb;AACzC;EAEA,QAAO;AACT;;ACxqBO,IAAIgB,IAA6B;;AACjC,IAAIC,KAAW;;AACf,IAAIC,SAAmC9J;;AAGvC,IAAM+J,gBAAiBC,KAC5BA,EAAIC,WAAWC,KAAK9M,SAAS,KAAK4M,EAAIC,WAAWE,WAC7CH,EAAIC,WAAWE,SAASH,EAAIC,WAAWC,KAAK7M,KAAK,aACjD2C;;AAEC,IAAMoK,cAAcA,CACzBC,GACAC,GACA/J,GACAhE,GACA4G,GACArF;EAEA,IAAMkM,IAAe;IACnBK;IACAC;IACA/J;IACAgK,QAAQ;MAAEjD,YAAY/K;;IACtBiO,gBAAgBjO;IAChBmG,WAAWS;IACXsH,gBAAgB;IAChBnJ,WAAW;IACXxD,YAAOkC;IACP0K,UAAS;IACT/B,UAAS;IACT3C,YAAYpC;IACZqG,YAAY;MACVC,MAAM;MACNC,eAAUnK;;;EAId,IAAIlC,KAASA,EAAM6M;IACjB,KAAK,IAAIrL,IAAI,GAAGA,IAAIxB,EAAM6M,cAAcvN,QAAQkC,KAAK;MACnD,IAAMsL,IAAe9M,EAAM6M,cAAcrL;MACzC,IAAIsL,EAAaV,QAAQU,EAAaV,KAAK9M,QAAQ;QACjD,KAAK4M,EAAIC,WAAWE;UAClBH,EAAIC,WAAWE,WAAWhE,OAAOC,OAAO;;QAC1C4D,EAAIC,WAAWE,SAAUS,EAAaV,KAAK7M,KAAK,QAAQuN;AAC1D;AACF;;EAGF,OAAOZ;AAAG;;AAGL,IAAMa,gBAAgBA,CAC3Bb,GACAlG,GACAvH,GACA4G,GACAP,GACAtB;EAEAsI,IAAaI;EACbA,EAAIO,SAASzG;EACbkG,EAAIQ,iBAAiBjO;EACrByN,EAAItH,YAAYS;EAChB6G,EAAIS,iBAAiB7H;EACrBoH,EAAI1I,YAAYA;EAChB0I,EAAIlM,QAAQiM,cAAcC;AAAI;;AAGhC,IAAMc,kCAAkCA,CACtCtO,GACAD,GACA4G,GACAhE,GACAlB;EAEA,KAAK1B;IAAU,QAAO;;EACtB,IAAMmC,IAAgBO,iBAAiBzC;EACvC,KAAKkC,KAAiBnC,MAAamC;IAAe,QAAO;;EAEzDV,iBAAAL,QAAAC,IAAAC,YAAAG,KACE,6EACEzB,IADF,wCAIEmC,IACA,6CACAA,IANF,kJAUA,IACAT;EAGF,QAAQa,gBAAgBtC,GAAMkN,MAAKlN;IACjC,IAAIA,EAAKE,SAASC,EAAKoO;MAAO,QAAO;;IACrC,IAAMnI,IAAWL,WAAW/D,QAAQhC,IAAO0C,kBAAkB1C,GAAM2C;IACnE,QAAQqJ,SAASrF,GAAWP;AAAS;AACrC;;AAGG,MAAMoI;EA8BXC,WAAAA,CACE1O,GACA4G,GACA+H,GACAC,GACApM,GACAiL;IAEAoB,KAAK7O,WAAWA;IAChB6O,KAAKjI,YAAYA;IACjBiI,KAAKpB,MAAMA;IACXoB,KAAKC,QAAQ,EACX;MACEtM;MACA6J,OAAO;MACP9H,OAAOoK;MACPjK,UAAUkK;;AAGhB;EAEAG,IAAAA;IACE,OAAOF,KAAKC,MAAMjO,SAAS,GAAG;MAC5B,IAAImO,IAAQH,KAAKC,MAAMD,KAAKC,MAAMjO,SAAS;MAC3C,OAAOmO,EAAM3C,QAAQ2C,EAAMxM,aAAa3B,QAAQ;QAC9C,IAAMoO,IAASD,EAAMxM,aAAawM,EAAM3C;QACxC,KAAKpI,cAAcgL,GAAQJ,KAAKpB,IAAIM,oBAE7B,IAAIkB,EAAO9O,SAASC,EAAKoO,OAAO;UAErC,IAAMU,IACJD,EAAO9O,SAASC,EAAKC,kBACjBwO,KAAKpB,IAAIzJ,UAAU/B,QAAQgN,MAC3BA;UACN,IAAIC,GAAU;YACZ,IAAMC,KACHD,EAAS/M,kBACT0M,KAAKpB,IAAIK,MAAMhJ,SACZS,kBACEsJ,KAAKpB,IAAIK,MAAMhJ,QACfoK,GACAL,KAAK7O,YAEe,WAArBkH,KACCkI,mBACEF,EAAS/M,cAAc5B,KAAKC,OAC5BqO,KAAK7O,aAETuO,gCACEW,GACAL,KAAK7O,UACL6O,KAAKjI,WACLiI,KAAKpB,IAAIM,WACTc,KAAKpB,IAAIK,MAAMpM;YAEvB,IACEyN,KACsB,YAArBjI,MAAiC2H,KAAKpB,IAAIK,MAAMhJ,QACjD;cACA,IAA6B,iBAAzB1D,QAAQC,IAAIC;gBACdvB,cAAc8O,KAAK7O,UAAUkP;;cAC/B,IAAMG,IAAqB5K,WAAWwK;cACtC,IACEE,KACAD,EAAS/M,iBACT0M,KAAK7O,aAAakP,EAAS/M,cAAc5B,KAAKC;gBAE9CiL,kBACEyD,EAAS/M,cAAc5B,KAAKC,OAC5BqO,KAAK7O;;cAIT6O,KAAKC,MAAMnO,KACRqO,IAAQ;gBACPxM,cAAcD,gBAAgB2M;gBAC9B7C,OAAO;gBACP9H,OAAOyK,EAAMzK,SAASD,WAAW2K,GAAQJ,KAAKpB,IAAIM;gBAClDrJ,eACyBjB,MAAvB4L,IACIA,IACAL,EAAMtK;;AAGlB;AACF;AACD,eAAM,IAAyB,YAArBwC,MAAiC+H,EAAOK,YAAY;UAC7DhC,IAAW0B,EAAMzK;UACjBgJ,IAAcyB,EAAMtK;UACpB,OAAOuK;AACT;AACF;MACAJ,KAAKC,MAAMhP;MACX,IAA6B,iBAAzBsB,QAAQC,IAAIC;QAA2BzB;;AAC7C;IACA;AACF;;;AAGF,IAAMuP,qBAAqBA,CAACjN,GAAuBnC;EACjD,KAAKA;IAAU,QAAO;;EACtB,IAAImC,MAAkBnC;IAAU,QAAO;;EAEvC,IAAMuP,KDuM2BvP,MACjCgH,EAAaxB,MAAM7D,IAAI3B,GCxMSwP,CAAmBrN;EACnD,KAAKoN;IAAwB,QAAO;;EAEpC,IAAM/J,IDiMyBxF,MAC/BgH,EAAa6E,sBAAsBpG,IAAIzF,MAAaqJ,EClMtCoG,CAAiBtN;EAC/B,OAAOqD,EAAMkK,QAAQlK,EAAM7D,IAAI3B;AAAS;;AAGnC,IAAM2P,aAAc7C,KACpB,QAALA,IAAY,OAAQA;;AAEf,IAAM8C,aAAaA,CAAC9B,GAAc+B;EACvC,KAAKA;IACH,OAAOA,KAAO;SACT,IAAIzF,MAAM5C,QAAQqI,IAAM;IAC7B,IAAM3F,IAAO,IAAIE,MAAMyF,EAAIhP;IAC3B,KAAK,IAAIkC,IAAI,GAAGC,IAAIkH,EAAKrJ,QAAQkC,IAAIC,GAAGD;MACtCmH,EAAKnH,KAAK6M,WAAW9B,GAAO+B,EAAI9M;;IAClC,OAAOmH;AACT;EAEA,IAAMA,IAAO4D,EAAMgC,YAAYD;EAAK,IAAA,iBAAAzO,QAAAC,IAAAC;IACpC,KAAK4I,KAAQ2F,KAAsB,mBAARA;MACzBpO,KACE,6HAEEoO,EAAI9E,aACJ,MACF,IACA+C,EAAMpM;;;EAIV,OAAOwI;AAAI;;ACvPN,IAAM6F,SAASA,CACpBjC,GACAkC,GACA5M,GACA7B;EAEA,IAAM0O,IAAQC,EAAeF,EAAQC;EACrC,IAAMxP,IAAYmD,iBAAiBqM;EACnC,IAAME,IAAUrC,EAAMsC,WAAW3P,EAAUA;EAC3C,IAAM4P,IAAa9N,gBAAgB9B;EAEnC,IAAMgN,IAAMI,YACVC,GACAvK,mBAAmB9C,GAAWuP,EAAQjC,YACtChK,aAAakM,IACbE,GACAA,GACA5O;EAGF,IAA6B,iBAAzBH,QAAQC,IAAIC;IACdvB,cAAcoQ,GAAS1P;;EAOzB,IAAM8G,IACJ4I,MAAY1C,EAAIK,MAAMsC,WAAkB,QACpCE,SAAS7C,GAAK0C,GAASE,GAAYjN,KAASmN,cAC5CC,cACE/C,GACA0C,GACAE,GACAjN,KAASmN;EAGjB,IAA6B,iBAAzBnP,QAAQC,IAAIC,UAA2B;IACzCzB;IACA0Q;AACF;EAEA,OAAO;IACLE,cAAcF;IACdpC,SAASV,EAAIU,YAAY5G;IACzB6E,SAASqB,EAAIrB;IACb7E,MAAMA,KAAQ;;AACf;;AAGH,IAAM+I,WAAWA,CACf7C,GACA7G,GACAqI,GACA7L;EAKA,IAAwB,oBAHPqK,EAAIK,MAAM4C,UAAU9J,KACjCA,IACAxD,EAAM2H;IAER,OAAO3H;;EAGT,IAAMuN,IAAY,IAAIlC,kBACpB7H,GACAA,IACA,QACAnD,GACAwL,GACAxB;EAGF,IAAIxN;EACJ,IAAI2Q,IAAaL;EACjB,IAAMM,IAASN,SAAsBnN;EACrC,OAAQnD,IAAO0Q,EAAU5B,QAAS;IAChC,IAAM+B,IAAa1O,cAAcnC;IACjC,IAAM8Q,IAAa3N,EAAM0N;IAEzBrD,EAAIC,WAAWC,KAAKhN,KAAKmQ;IAGzB,IAAIE,SAAgC;IACpC,IAAI/Q,EAAKuC,gBAA+B,SAAfuO;MACvBC,IAAiBC,cACfxD,GACAlL,gBAAgBtC,IAChB0P,WAAWoB;;MAGbC,IAAiBD;;IAInBH,IAAaA,KAAcI,MAAmBD;IAC9C,SAAuBtN,MAAnBuN;MAA8BH,EAAOC,KAAcE;;IAGvDvD,EAAIC,WAAWC,KAAK7N;AACtB;EAEA,OAAO8Q,IAAaC,IAASzN;AAAK;;AAGpC,IAAM6N,gBAAgBA,CACpBxD,GACAwB,GACAiC;EAEA,IAAI9G,MAAM5C,QAAQ0J,IAAe;IAC/B,IAAMzJ,IAAU,IAAI2C,MAAM8G,EAAarQ;IACvC,IAAI+P,IAAaL;IACjB,KAAK,IAAIxN,IAAI,GAAGC,IAAIkO,EAAarQ,QAAQkC,IAAIC,GAAGD,KAAK;MAEnD0K,EAAIC,WAAWC,KAAKhN,KAAKoC;MAEzB0E,EAAQ1E,KAAKkO,cAAcxD,GAAKwB,GAAQiC,EAAanO;MACrD6N,IAAaA,KAAcnJ,EAAQ1E,OAAOmO,EAAanO;MAEvD0K,EAAIC,WAAWC,KAAK7N;AACtB;IAEA,OAAO8Q,IAAanJ,IAAUyJ;AAChC,SAAO,IAAqB,SAAjBA;IACT,OAAO;;EAIT,IAAMtK,IAAY6G,EAAIK,MAAMgC,YAAYoB;EACxC,IAAkB,SAAdtK;IAGF,OAAO4J,cAAc/C,GAAK7G,GAAWqI,GAAQiC,MAAiB;;IAE9D,OAAOZ,SAAS7C,GAAKyD,EAAanG,YAAYkE,GAAQiC;;AACxD;;AAyFF,SAASC,iBACPjN,GACAlE,GACA+E,GACA0I;EAEA,IAAM2D,IAAY3D,EAAIK,MAAMsD,UAAUpR;EACtC,IAAMqR,IAAgBD,KAAaA,EAAUrM;EAE7C,IAAIuM;EACJ,KAAK,IAAM/Q,KAAQ2D,GAAY;IAC7B,IAAMqN,IAAgBrN,EAAW3D;IACjC,IACEgR,KACS,cAAThR,KACS,WAATA,KACAkN,EAAIK,MAAM5J,WAAW3D,IACrB;MACA+Q,IAAoB7D,EAAIK,MAAM5J,WAAW3D,GACvCoC,kBAAkB4O,GAAe9D,EAAIM;MAEvC,IAA6B,iBAAzB3M,QAAQC,IAAIC;QAA2B,OAAOgQ;;MAClD;AACF;AACF;EAAC,IAAA,iBAAAlQ,QAAAC,IAAAC;IAED,IAAI+P,KAAiBC;MACnB7P,KACE,8CAA8CzB,KAAY+E,qDAC1D,IACA0I,EAAIK,MAAMpM;;;EAId,OAAO4P,KAAqBD;AAC9B;;AAEA,IAAMb,gBAAgBA,CACpB/C,GACA9J,GACAsL,GACA7L,GACAoO;EAEA,KAAM1D,OAAEA,KAAUL;EAClB,IAAMgE,IAAU9N,MAAQmK,EAAMsC,WAAWH;EAEzC,IAAMrJ,IAAa4K,KAAU1D,EAAMgC,YAAY0B,MAAY7N;EAAI,IAAA,iBAAAvC,QAAAC,IAAAC;IAC/D,KAAKmQ,KAAahE,EAAIK,MAAM4C,UAAU9J;MACpCnF,KACE,4DACEmF,IADF,6CAIE6G,EAAIK,MAAMsC,WAAWsB,WACrB,YACAjE,EAAIK,MAAMsC,WAAWuB,eANvB,oFASA,IACA7D,EAAMpM;;;EAIV,IAAM1B,KAAYyR,IACdlB,WAAwB3J,GAAW,iBAClC4K,KAAUA,EAAOzG,aAClBpH;EAEJ,IAAwB,mBAAb3D;IACT;SACK,IAAIwR,KAAUxR,MAAawR,EAAOzG,YAAY;qBACnD3J,QAAAC,IAAAC,YAAAG,KACE,6CACEmF,IADF,+EAIA,GACAkH,EAAMpM;IAGR;AACF;EAEA,IAAMiP,IAAY,IAAIlC,kBACpBzO,GACA4G,IACA,QACAnD,GACAwL,GACAxB;EAGF,IAAImE,KAAY;EAChB,IAAIxF,KAAU;EACd,IAAIwE,IAAaL;EACjB,IAAItQ;EACJ,IAAM4R,IAAcpE,EAAIU;EACxB,IAAM0C,IAASN,SAAsBnN;EACrC,YAAqCK,OAA7BxD,IAAO0Q,EAAU5B,SAAuB;IAE9C,IAAMhK,IAAY9C,QAAQhC;IAC1B,IAAM6R,IAAYnP,kBAAkB1C,GAAMwN,EAAIM;IAC9C,IAAM+C,IAAa1O,cAAcnC;IACjC,IAAMiE,IAAanC,cAAc9B;IACjC,IAAM8R,IAAWZ,iBAAiBjN,GAAYlE,GAAU+E,GAAW0I;IACnE,IAAMpH,IAAWL,WAAWjB,GAAW+M;IACvC,IAAMnO,IAAMuC,SAASU,GAAWP;IAChC,IAAM0K,IAAaR,WAAwB3J,GAAWP;IACtD,IAAM2L,IAAcR,IAASA,EAAOzM,UAAatB;IAEjD,IAA6B,iBAAzBrC,QAAQC,IAAIC,YAA6BwM,EAAMhJ,UAAU9E;MAC3DqF,uBACEyI,EAAMhJ,QACN9E,GACA+E,GACA0I,EAAIK,MAAMpM;;IAKd+L,EAAIC,WAAWC,KAAKhN,KAAKmQ;IAGzB,IAAIE,SAAmCvN;IAEvC,IAAkB,iBAAdsB;MAEFiM,IAAiBhR;WACZ,SAAoByD,MAAhBuO,UAAmDvO,MAAtBxD,EAAKuC;MAE3CwO,IAAiBgB;WACZ,IAAsC,WAAlCzB,KAA4CwB,GAAU;MAK/D,IAAI/D,IAAS6C;MACb,SAA0BpN,MAAtBxD,EAAKuC,qBAA6CiB,MAAfsN;QACrC/C,IAAS;aACJ6C;UACHC,CAACA,IAAaC;UACdhM,CAACA,IAAYgM;;;MAMjBzC,cAAcb,GAAKO,GAAQhO,GAAU4G,GAAWP,GAAUtB;MAE1DiM,IAAiBe,EACf/D,GACA8D,KAAc,CAAA,GACdhE,GACAL;MAGF,IAAIxN,EAAKuC;QAGPwO,IAAiBiB,sBACfxE,GACAzN,GACA+E,GACApB,GACApB,gBAAgBtC,SACQwD,MAAvBoN,EAAOC,KACJD,EAAOC,KACP1N,EAAM0N,IACVE,GACAT,SAAsBnN;;MAI1B,IACE0K,EAAMhJ,UACa,SAAnBkM,MACCnM,gBAAgBiJ,EAAMhJ,QAAQ9E,GAAU+E,GAAW0I,EAAIK,MAAMpM;QAI9D;;AAEJ,WAAO,KAAKzB,EAAKuC;MAEfwO,IAAiBD;WACZ,SAAoBtN,MAAhBuO;MAEThB,IAAiBiB,sBACfxE,GACAzN,GACA+E,GACApB,GACApB,gBAAgBtC,SACQwD,MAAvBoN,EAAOC,KACJD,EAAOC,KACP1N,EAAM0N,IACVkB,GACAzB,SAAsBnN;WAEnB;MAEL,IAAM8G,IAAOqG,SAAsB3J,GAAWP;MAE9C,SAAa5C,MAATyG;QACF8G,IAAiBkB,YACfzE,GACAvD,GACAlK,GACA+E,GACAxC,gBAAgBtC,SACQwD,MAAvBoN,EAAOC,KACJD,EAAOC,KACP1N,EAAM0N,IACVP,SAAsBnN;aAEnB,IAA0B,mBAAf2N,KAA0C,SAAfA;QAE3CC,IAAiBD;;AAErB;IAKA,KACGzD,UACkB7J,MAAnBuN,MACC9M,EAAWQ,YACT6I,MAAgBrJ,EAAWS,YAC1B6I,cAAcC,OACdvJ,EAAWS,YACXmJ,EAAMhJ,UACND,gBAAgBiJ,EAAMhJ,QAAQ9E,GAAU+E,GAAW0I,EAAIK,MAAMpM,UACjE;MAEA+L,EAAIU,WAAU;MACd6C,IAAiB;AACnB,WAAO,IACc,SAAnBA,MACC9M,EAAWS,aAA4B,MAAhB4I,IACxB;MACA,IACEE,EAAIK,MAAMpM,UACe,iBAAzBN,QAAQC,IAAIC,YACsB,WAAlCiP;QAEA9C,EAAIK,MAAMpM,OACR,SACA,wCAAwCqD,KACtC+M,IAAY,cAActL,KAAK2L,UAAUL,OAAe,iBAC3ClL;;MAGnBoK,SAAiBvN;AACnB;MACEmO,IAAYA,KAA2B,iBAAd7M;;IAI3B0I,EAAIC,WAAWC,KAAK7N;IAEpB8Q,IAAaA,KAAcI,MAAmB5N,EAAM0N;IACpD,SAAuBrN,MAAnBuN;MACFH,EAAOC,KAAcE;WAChB,IAAI1D;MACTlB,KAAU;WACL;MACL,IACEqB,EAAIK,MAAMpM,UACe,iBAAzBN,QAAQC,IAAIC,YACsB,WAAlCiP;QAEA9C,EAAIK,MAAMpM,OACR,SACA,uBAAuBqD,KACrB+M,IAAY,cAActL,KAAK2L,UAAUL,OAAe,iBAC3ClL;;MAKnB6G,EAAIU,UAAU0D;MACd;AACF;AACF;EAEApE,EAAIU,UAAUV,EAAIU,WAAW0D;EAC7BpE,EAAIrB,UAAUqB,EAAIrB,WAAWA;EAC7B,OAAOqF,KAAWhE,EAAIU,YAAYyD,SAC9BnO,IACAmN,IACEC,IACAzN;AAAK;;AAGb,IAAM6O,wBAAwBA,CAC5BxE,GACAzN,GACA+E,GACApB,GACAsL,GACAmD,GACAZ,GACAa;EAEA,IAAIjI,MAAM5C,QAAQgK,IAAS;IACzB,KAAM1D,OAAEA,KAAUL;IAGlB,IAAM6E,IAAkBxE,EAAMhJ,SAC1BK,eAAe2I,EAAMhJ,QAAQ9E,GAAU+E,GAAW0I,EAAIK,MAAMpM,WAC5D;IACJ,IAAMmQ,IAAcpE,EAAIU;IACxB,IAAM5G,IAAOgJ,SAAsB6B,IAAU;IAC7C,IAAIxB,IACFL,MACCnG,MAAM5C,QAAQ4K,MACfZ,EAAO3Q,WAAWuR,EAASvR;IAC7B,KAAK,IAAIkC,IAAI,GAAGC,IAAIwO,EAAO3Q,QAAQkC,IAAIC,GAAGD,KAAK;MAE7C0K,EAAIC,WAAWC,KAAKhN,KAAKoC;MAEzB,IAAMwP,IAAcN,sBAClBxE,GACAzN,GACA+E,GACAmB,SAASvC,GAAK,GAAGZ,MACjBkM,GACY,QAAZmD,IAAmBA,EAASrP,UAAKU,GACjC+N,EAAOzO,IACPsP;MAGF5E,EAAIC,WAAWC,KAAK7N;MAEpB,SAAoB2D,MAAhB8O,MAA8BD,GAAiB;QACjD7E,EAAIU,UAAU0D;QACd;AACF,aAAO;QACLpE,EAAIU,UACFV,EAAIU,gBAA4B1K,MAAhB8O,KAA6BD;QAC/C/K,EAAKxE,KAAoB,QAAfwP,IAAsBA,IAAc;QAC9C3B,IAAaA,KAAcrJ,EAAKxE,OAAOqP,EAAUrP;AACnD;AACF;IAEA,OAAO6N,IAAarJ,IAAO6K;AAC5B,SAAM,IAAIZ;IACT,OAAOA;SACF,IAAIa,KAA4B,SAAbD;IACxB,OAAO;SACF,IAAII,YAAYhB,IAAS;IAC9B,IAAMjK,IAAQ6K,KAAY7B,SAAsB6B;IAChD,OAAyB,mBAAXZ,IACVhB,cAAc/C,GAAK+D,GAAQvC,GAAQ1H,KACnCiJ,cAAc/C,GAAK9J,GAAKsL,GAAQ1H,GAAMiK;AAC5C,SAAO;qBACLpQ,QAAAC,IAAAC,YAAAG,KACE,2CACEkC,IADF,uGAIA,GACA8J,EAAIK,MAAMpM;IAGZ;AACF;AAAA;;AAGF,IAAMwQ,cAAcA,CAClBzE,GACAvD,GACAlK,GACA+E,GACAkK,GACAmD,GACAC;EAEA,IAAIjI,MAAM5C,QAAQ0C,IAAO;IACvB,KAAM4D,OAAEA,KAAUL;IAClB,IAAM6E,IAAkBxE,EAAMhJ,SAC1BK,eAAe2I,EAAMhJ,QAAQ9E,GAAU+E,GAAW0I,EAAIK,MAAMpM,WAC5D;IACJ,IAAM+Q,IAAUlC,SAAsB6B,IAAU;IAChD,IAAMP,IAAcpE,EAAIU;IACxB,IAAIyC,IACFL,MACCnG,MAAM5C,QAAQ4K,MACflI,EAAKrJ,WAAWuR,EAASvR;IAC3B,KAAK,IAAIkC,IAAI,GAAGC,IAAIkH,EAAKrJ,QAAQkC,IAAIC,GAAGD,KAAK;MAE3C0K,EAAIC,WAAWC,KAAKhN,KAAKoC;MAEzB,IAAM2P,IAAYR,YAChBzE,GACAvD,EAAKnH,IACL/C,GACA+E,GACAkK,GACY,QAAZmD,IAAmBA,EAASrP,UAAKU,GACjC4O;MAGF5E,EAAIC,WAAWC,KAAK7N;MAEpB,SAAkB2D,MAAdiP,MAA4BJ,GAAiB;QAC/C7E,EAAIU,UAAU0D;QACd;AACF,aAAO;QACLpE,EAAIU,UACFV,EAAIU,gBAA0B1K,MAAdiP,KAA2BJ;QAC7CG,EAAQ1P,KAAK2P,KAAa;QAC1B9B,IAAaA,KAAc6B,EAAQ1P,OAAOqP,EAAUrP;AACtD;AACF;IAEA,OAAO6N,IAAa6B,IAAWL;AAChC,SAAM,IAAa,SAATlI,KAA+B,SAAbkI,KAAqBC;IAChD,OAAO;;EAGT,OAAO7B,cACL/C,GACAvD,GACA+E,GACCmD,KAAY7B,SAAsB6B;AACpC;;AAGH,IAAMI,cAAe1F,KACN,mBAANA,KACO,mBAANA,KAAmD,mBAAzBA,EAAU/B;;AC1tBvC,IAAM4H,mBAAmBA,CAC9B/L,GACA5B,GACAnC;EAEA,IAAMgD,IAA6Bb,IAC/B,EAAC;IAAEqB,UAAUL,WAAWhB,GAAOnC;QAC/B0N,cAA2B3J;EAE/B,KAAK,IAAI7D,IAAI,GAAGC,IAAI6C,EAAOhF,QAAQkC,IAAIC,GAAGD,KAAK;IAC7C,KAAMsD,UAAEA,KAAaR,EAAO9C;IAC5B,SAAmDU,MAA/C8M,SAAsB3J,GAAWP;MACnCkK,UAAuB3J,GAAWP,QAAU5C;;MAE5C8M,YAAyB3J,GAAWP,QAAU5C;;AAElD;AAAA;;AAGK,IAAMmP,iBAAiBA,CAC5B5S,GACA6S;EAEA,IAAMrN,IH8b2BxF,MACjCgH,EAAaxB,MAAMC,IAAIzF,MAAaqJ,EG/btBkH,CAAgCvQ;EAC9C,KAAK,IAAM2J,KAAUnE,GAAO;IAC1B,IAAIqN,EAAiBC,SAASnJ;MAAS;;IACvCgJ,iBAAiBhJ;AACnB;AAAA;;ACwDK,IAAMoJ,SAASA,CACpBjF,GACAkC,GACAzI,GACAhG;EAEA,IAA6B,iBAAzBH,QAAQC,IAAIC;IACdiP;;EAGF,IAAMN,IAAQC,EAAeF,EAAQC;EACrC,IAAMxP,IAAYmD,iBAAiBqM;EACnC,IAAMuB,IAAsB;IAC1BjK,MAAMA,KAAQgJ;IACdE,cAAcF;;EAEhB,IAAMpQ,IAAO2N,EAAMsC,WAAW3P,EAAUA;EAExC,IAAMgN,IAAMI,YACVC,GACAvK,mBAAmB9C,GAAWuP,EAAQjC,YACtChK,aAAakM,IACb9P,GACAA,GACAoB;EAGF,IAA6B,iBAAzBH,QAAQC,IAAIC;IACdvB,cAAcI,GAAMM;;EAGtBuS,eAAevF,GAAKtN,GAAMoC,gBAAgB9B,IAAY+Q,EAAOjK;EAE7D,IAA6B,iBAAzBnG,QAAQC,IAAIC;IACdzB;;EAGF,OAAO2R;AAAM;;AA6Ef,IAAMwB,iBAAiBA,CACrBvF,GACA7G,GACAqI,GACA1H;EAMA,IAAM0L,IAAYxF,EAAIK,MAAM4C,UAAU9J,MAAe;EACrD,IAAMsM,MAAWzF,EAAIK,MAAM4C,UAAU9J;EAErC,IAAI5G,IAAWkT,IAAStM,IAAYW,EAAKwD;EACzC,KAAK/K,KAAY4G,KAAa6G,EAAIhE;IAChCzJ,IAAWuQ,WAAwB3J,GAAW;;EAKhD,KAAK5G,GAAU;IACbyB,iBAAAL,QAAAC,IAAAC,YAAAG,KACE,qJAEA,IACAgM,EAAIK,MAAMpM;IAEZ;AACF,SAAO,KAAKwR,KAAUtM,GAAW;IAC/B2J,YAAyB3J,GAAW,cAAc5G;IJsP7BmT,EAACnT,GAAkB4G;MAC1C,IAAMgF,IAAgB5E,EAAaxB,MAAMC,IAAIzF;MAC7C,KAAK4L,GAAe;QAClB,IAAME,IAAU,IAAInM;QACpBmM,EAAQjK,IAAI+E;QACZI,EAAaxB,MAAMkC,IAAI1H,GAAU8L;AACnC;QACEF,EAAc/J,IAAI+E;;AACpB,MI7PE2J,CAAuBvQ,GAAU4G;AACnC;EAEA,IAAMwM,IAAU3F,EAAIK,MAAMsF,QAAQpT;EAClC,IAAM2Q,IAAY,IAAIlC,kBACpBzO,GACA4G,KAAa5G,IACb,QACAyD,GACAwL,GACAxB;EAGF,IAAIxN;EACJ,OAAQA,IAAO0Q,EAAU5B,QAAS;IAChC,IAAMhK,IAAY9C,QAAQhC;IAC1B,IAAM6R,IAAYnP,kBAAkB1C,GAAMwN,EAAIM;IAC9C,IAAM1H,IAAWL,WAAWjB,GAAW+M;IACvC,IAAMhB,IAAa1O,cAAcnC;IACjC,IAAI8Q,IAAaxJ,EAAKkG,EAAIhE,aAAa1E,IAAY+L;IAEnD,IAEgB,iBAAd/L,UAGgBtB,MAAfsN,MACEzD,KAAaG,EAAIhE,cAA4B,YAAdwJ;MAElC;;IAGF,IAA6B,iBAAzB7R,QAAQC,IAAIC;MACd,IAAImM,EAAIK,MAAMhJ,UAAU9E,KAA0B,iBAAd+E;QAClCM,uBACEoI,EAAIK,MAAMhJ,QACV9E,GACA+E,GACA0I,EAAIK,MAAMpM;;;IAMhB+L,EAAIC,WAAWC,KAAKhN,KAAKmQ;IAIzB,IAAIiB,SAAgD;IACpD,IAAItE,EAAIhE,cAA4B,eAAdwJ;MAEpB,MADAlB,IAAWtE,EAAIK,MAAMuF,oBAAoBtO;QAC1B;;WACV,IAAI0I,EAAIhE,cAAoC,qBAAfsH;MAClCgB,IAAWhB;;IAIb,IAAIgB,GAAU;MAEZzD,cACEb,GACAlG,GACAvH,GACA4G,KAAa5G,GACbqG,GACAtB;MAEFgM,IAAapB,WAAWoC,EAASD,KAAa,CAAE,GAAErE,EAAIK,OAAOL;AAC/D;IAEA,SAAmBhK,MAAfsN,GAA0B;MAC5B,IAA6B,iBAAzB3P,QAAQC,IAAIC;QACd,KACGsF,MACA2J,SAAsB3J,GAAWP,MACjCoH,EAAIhE,eAAe8G,WAAwB3J,GAAW,eACvD;UAMA,iBAAAxF,QAAAC,IAAAC,YAAAG,KACE,sCACE4E,IACA,6DAPoB5C,MAAtBxD,EAAKuC,eACD,kCACA,mBAOF,oBACF,IACAiL,EAAIK,MAAMpM;AAEd;;MAGF;AACF;IAEA,IAAIzB,EAAKuC;MAEP,IAAIoE,KAA2B,YAAdqM,GAAuB;QACtC,IAAMtP,IAAMuC,SAASU,GAAWP;QAChC,IAAM6D,IAAOoJ,WACX7F,GACAlL,gBAAgBtC,IAChB0P,WAAWoB,IACXpN,GACA8J,EAAIhE,aACA8G,SAAsB3J,KAAa5G,GAAUqG,UAC7C5C;QAGN8M,UAAuB3J,KAAa5G,GAAUqG,GAAU6D;AAC1D;QACEoJ,WAAW7F,GAAKlL,gBAAgBtC,IAAO0P,WAAWoB;;WAE/C,IAAInK,KAA2B,YAAdqM;MAEtB1C,YACE3J,KAAa5G,GACbqG,GACgB,SAAf0K,MAAwBvD,cAAcC,KACnCsD,SACAtN;;IAMR,IAAM8P,IAAUH,KAAWA,EAAQrO;IACnC,IAAIwO,GAAS;MAEXjF,cACEb,GACAlG,GACAvH,GACA4G,KAAa5G,GACbqG,GACAtB;MAGFwC,EAAKxC,KAAagM;MAClBwC,EAAQhM,GAAMuK,KAAa,CAAA,GAAIrE,EAAIK,OAAOL;AAC5C,WAAO,IACLzN,MAAayN,EAAIK,MAAMsC,WAAqB,aAC3C3C,EAAIhE;MAML,IAAIsH,KAAc3G,MAAM5C,QAAQuJ,IAAa;QAC3C,IAAM8B,IAA6B9B,EAAWxH,KAC5CI,KAAU8D,EAAIK,MAAMgC,YAAYnG,MAAW;QAE7C,KAAK,IAAI5G,IAAI,GAAGC,IAAI+N,EAAWlQ,QAAQkC,IAAIC,GAAGD,KAAK;UACjD,IAAMY,IAAMkP,EAAiB9P;UAC7B,IAAIY,KAAOoN,EAAWhO,GAAGgI,YAAY;YACnC,IAAMyI,IAAWjD,WAAwB5M,GAAK;YAC9C,IAAM2G,IAAQiG,YAA0B5M;YACxC,IAAI6P,MAAalJ;cACfsI,eAAe7B,EAAWhO,GAAGgI,YAAY8H;;AAE7C;AACF;AACD,aAAM,IAAI9B,KAAoC,mBAAfA,GAAyB;QACvD,IAAMpN,IAAM8J,EAAIK,MAAMgC,YAAYiB;QAClC,IAAIpN,GAAK;UACP,IAAM6P,IAAWjD,WAAwB5M,GAAK;UAC9C,IAAM2G,IAAQiG,YAAyB5M;UACvC,MAAM6P,MAAalJ,MAAUyG,EAAWhG;YACtC6H,eAAe7B,EAAWhG,YAAY,EAACpH;;AAE3C;AACF;;IAIF8J,EAAIC,WAAWC,KAAK7N;AACtB;AAAA;;AAIF,IAAM2T,IAAkB;;AAExB,IAAMH,aAAaA,CACjB7F,GACAwB,GACA1H,GACA2G,GACAwF;EAEA,IAAItJ,MAAM5C,QAAQD,IAAO;IACvB,IAAME,IAAU,IAAI2C,MAAM7C,EAAK1G;IAC/B,KAAK,IAAIkC,IAAI,GAAGC,IAAIuE,EAAK1G,QAAQkC,IAAIC,GAAGD,KAAK;MAE3C0K,EAAIC,WAAWC,KAAKhN,KAAKoC;MAEzB,IAAM4Q,IAAWzF,IACbhI,SAASgI,GAAgB,GAAGnL,YAC5BU;MAGJ,IAAMwH,IAAQqI,WAAW7F,GAAKwB,GAAQ1H,EAAKxE,IAAI4Q,GADjB,QAAZD,IAAmBA,EAAS3Q,UAAKU;MAGnDgE,EAAQ1E,KAAKkI;MAEbwC,EAAIC,WAAWC,KAAK7N;AACtB;IAEA,OAAO2H;AACT,SAAO,IAAa,SAATF;IACT,OAAOiG,cAAcC,UAAOhK,IAAY;;EAG1C,IAAMmD,IACJ6G,EAAIK,MAAMgC,YAAYvI,OACD,mBAAbmM,IAAwBA,IAAW;EAC7C,IAAM1T,IAAWuH,EAAKwD;EAAW,IAAA,iBAAA3J,QAAAC,IAAAC;IAEjC,IACE4M,MACCT,EAAIK,MAAMlD,KAAKrD,EAAKwD,eACP,SAAdnE,KACoB,mBAAb5G,MACNyT,EAAgBG,KAAK5T;MAEtByB,KACE,qDACEyM,IADF,6LAMElO,IANF,mIAUEA,IACA,+BACF,IACAyN,EAAIK,MAAMpM;;;EAId,IAAMmS,IAAWjN,KAAasH;EAC9B8E,eAAevF,GAAKoG,GAAU5E,GAAQ1H;EACtC,OAAOsM,KAAY;AAAI;;ACpblB,MAAMC;EAkBXpF,WAAAA,CAAYqF;IACV,KAAKA;MAAMA,IAAO;;IAElBlF,KAAKnN,SAASqS,EAAKrS;IACnBmN,KAAKuC,YAAY2C,EAAK3C,aAAa,CAAA;IACnCvC,KAAK3K,aAAa6P,EAAK7P,cAAc,CAAA;IACrC2K,KAAKwE,sBAAsBU,EAAKtK,cAAc,CAAA;IAC9CoF,KAAKjE,OAAOmJ,EAAKnJ,QAAQ,CAAA;IAEzBiE,KAAKmF,YAAY5J,MAAM5C,QAAQuM,EAAKC,aAChC,IAAIrU,IAAIoU,EAAKC,eACXD,EAAKC;IAEX,IAAIC,IAAY;IAChB,IAAIC,IAAe;IACnB,IAAIC,IAAmB;IACvB,IAAIJ,EAAKjP,QAAQ;MACf,IAAMA,ICnCqBsP,GAC/BC;QAEA,IAAMC,IAAmD,IAAI9H;QAE7D,IAAM+H,eACJC;UAEA,IAAIjL;UACJ,OAAO;YACL,KAAKA,GAAK;cACRA,IAAM,CAAA;cACN,KAAK,IAAIxG,IAAI,GAAGA,IAAIyR,EAAI3T,QAAQkC;gBAAKwG,EAAIiL,EAAIzR,GAAGxC,QAAQiU,EAAIzR;;AAC9D;YACA,OAAOwG;AAAG;AACX;QAGH,IAAMkL,YACJvP;UAEA,QAAQA,EAAK/E;WACX,KAAK;WACL,KAAK;YACH,OAAO;cACLI,MAAM2E,EAAK3E;cACXJ,MAAM+E,EAAK/E;cACXuU,YAAYH,aAAarP,EAAKwP,cAAc;cAC5C7O,QAAQ0O,aACNrP,EAAKW,OAAQ0D,KAAKvE,MAAgB;gBAChCzE,MAAMyE,EAAMzE;gBACZ2E,MAAMF,EAAME;gBACZrC,MAAM0R,aAAavP,EAAMnC;;;;WAIjC,KAAK;YACH,OAAO;cACLtC,MAAM2E,EAAK3E;cACXJ,MAAM+E,EAAK/E;cACXqF,OAAO+O,aAAarP,EAAKyP,iBAAiB;;;AAEhD;QAGF,IAAM7P,IAA6B;UACjCmL,OAAOoE,EAASO,YAAYP,EAASO,UAAUrU,OAAO;UACtDmR,UAAU2C,EAASQ,eAAeR,EAASQ,aAAatU,OAAO;UAC/DoR,cAAc0C,EAASS,mBACnBT,EAASS,iBAAiBvU,OAC1B;UACJiF,YAAO/B;UACPmC,SAAAA,CAAUmP,GAAkBC;YAC1B,IAAMtJ,IAAe4I,EAAQ7O,IAAIsP;YACjC,IAAME,IAAeX,EAAQ7O,IAAIuP;YACjC,KAAKtJ,MAAiBuJ;cACpB,QAAO;mBACF,IAA0B,YAAtBvJ,EAAavL;cACtB,SAASuL,EAAalG,QAAQwP;mBACzB,IACiB,aAAtBtJ,EAAavL,QACS,aAAtB8U,EAAa9U;cAEb,SAAS8U,EAAaP,aAAaK;;cAEnC,OAAOA,MAAaC;;AAExB;;QAGF,IAAIX,EAAS7O,OAAO;UAClBV,EAAOU,QAAQ8O;UACf,KAAK,IAAIvR,IAAI,GAAGA,IAAIsR,EAAS7O,MAAM3E,QAAQkC,KAAK;YAC9C,IAAMmC,IAAOmP,EAAS7O,MAAMzC;YAC5B,IAAImC,KAAQA,EAAK3E,MAAM;cACrB,IAAM2U,IAAMT,UAAUvP;cACtB,IAAIgQ;gBAAKZ,EAAQ5M,IAAIxC,EAAK3E,MAAM2U;;AAClC;AACF;AACF;QAEA,OAAOpQ;AAAM,QD9CMsP,CAAkBL,EAAKjP;MACtCmP,IAAYnP,EAAOmL,SAASgE;MAC5BC,IAAepP,EAAO4M,YAAYwC;MAClCC,IAAmBrP,EAAO6M,gBAAgBwC;MAE1C,IAAIrP,EAAOU;QAAOqJ,KAAK/J,SAASA;;AAClC;IAEA+J,KAAKuE,UAAUW,EAAKX,WAAW,CAAA;IAE/BvE,KAAKuB,aAAa;MAChBH,OAAOgE;MACPvC,UAAUwC;MACVvC,cAAcwC;;IAGhBtF,KAAK6B,YAAY;MACfuD,CAACA,IAAY;MACbC,CAACA,IAAe;MAChBC,CAACA,IAAmB;;IAGtBtF,KAAKtH,QL2IY4D,IK3Ia8I,GL2I2B;MAC3D9L,YAAW;MACX5D,QAAO;MACP0E,IAAI,IAAItJ;MACR6F,OAAO,IAAIgH;MACXnB,SAAS,IAAI1L;MACbwL;MACAnB,UAAU,IAAIwC;MACdvB,OAAO;QACLxB,YAAY,IAAI+C;QAChB9C,MAAM,IAAI8C;;MAEZX,uBAAuB,IAAIW;MAC3B1B,SAAS;QACPrB,YAAY,IAAI+C;QAChB9C,MAAM,IAAI8C;;MAEZpD,cAAc,IAAIzJ;MAClB0I,iBAAiB,IAAI1I;MACrBkJ,WAAW,IAAIlJ;MACfyI,iBAAiB;MACjBW,SAAS;;IArBUoC;IKzIjB,IAAI0D,KAAK/J,UAAmC,iBAAzB1D,QAAQC,IAAIC,UAA2B;OP0BvD,SAAS6T,wBACdrQ,GACA8F,GACAlJ;QAEA,IAA6B,iBAAzBN,QAAQC,IAAIC;UACd,KAAK,IAAMqC,KAAOiH;YAAM,IAAA,iBAAAxJ,QAAAC,IAAAC;cACtB,KAAKwD,EAAOU,MAAO7D,IAAIgC;gBACrBlC,KACE,oCACEkC,IACA,sFACF,IACAjC;;;;;AAKV,OO3CMyT,CAAwBtG,KAAK/J,QAAQ+J,KAAKjE,MAAMiE,KAAKnN;OP6CpD,SAAS0T,yBACdtQ,GACAsO,GACA1R;QAEA,IAA6B,iBAAzBN,QAAQC,IAAIC;UACd;;QAGF,KAAK,IAAMtB,KAAYoT,GAAS;UAC9B,KAAKA,EAAQpT;YACX;iBACK,KAAK8E,EAAOU,MAAO7D,IAAI3B,IAAW;YACvC,IAAIqV,IAAW;YAEf,IACe,eAAbrV,KACA8E,EAAO4M,YACa,eAApB5M,EAAO4M;cAEP2D,KACE,2CAA2CvQ,EAAO4M,WAAW;mBAC1D,IACQ,mBAAb1R,KACA8E,EAAO6M,gBACiB,mBAAxB7M,EAAO6M;cAEP0D,KACE,2CAA2CvQ,EAAO6M,eAAe;;YAGrE,OAAA,iBAAAvQ,QAAAC,IAAAC,WAAOG,KACL,qCACEzB,IACA,0FACAqV,GACF,IACA3T,UACD;AACH;UAEA,IAAMmE,IAAUf,EAAOU,MAAOC,IAAIzF,GAA4B6F;UAC9D,KAAK,IAAMd,KAAaqO,EAAQpT;YAAY,IAAA,iBAAAoB,QAAAC,IAAAC;cAC1C,KAAKuE,EAAOd;gBACVtD,KACE,6BACEsD,IACA,WACA/E,IACA,+EACF,IACA0B;;;;AAIR;AACF,OOpGM0T,CAAyBvG,KAAK/J,QAAQ+J,KAAKuE,SAASvE,KAAKnN;OP4HxD,SAAS4T,2BACdxQ,GACAsM,GACA1P;QAEA,IAA6B,iBAAzBN,QAAQC,IAAIC;UACd;;QAGF,KAAK,IAAMqC,KAAOyN;UAChB,IAAY,YAARzN;YACF,IAAImB,EAAOmL,OAAO;cAChB,IAAMsF,IACJzQ,EAAOU,MAAOC,IAAIX,EAAOmL,OACzBpK;cACF,KAAK,IAAM2P,KAAiBpE,EAAUqE,SAAS,CAAA;gBAC7C,KAAKF,EAAaC;kBAChB1P,kBAAkB,WAAW0P,GAAe9T;;;AAGlD;cACEoE,kBAAkB,SAASpE;;iBAG7B,KAAKoD,EAAOU,MAAO7D,IAAIgC;YACrBmC,kBAAkBnC,GAAKjC;iBAClB,IAC4B,gBAAjCoD,EAAOU,MAAOC,IAAI9B,GAAMxD,QACS,YAAjC2E,EAAOU,MAAOC,IAAI9B,GAAMxD;YAExB4F,0BACEpC,GACAmB,EAAOU,MAAOC,IAAI9B,GAAMxD,MACxBuB;iBAEG;YACL,IAAMgU,IACJ5Q,EAAOU,MAAOC,IAAI9B,GAClBkC;YACF,KAAK,IAAM8P,KAAoBvE,EAAUzN,MAAQ,CAAA;cAC/C,KAAK+R,EAAoBC;gBACvB7P,kBAAkBnC,IAAM,MAAMgS,GAAkBjU;;;AAGtD;;AAGN,OO1KM4T,CAA2BzG,KAAK/J,QAAQ+J,KAAKuC,WAAWvC,KAAKnN;OP4K5D,SAASkU,qCACd9Q,GACAuO,GACA3R;QAEA,IAA6B,iBAAzBN,QAAQC,IAAIC;UACd;;QAGF,IAAIwD,EAAO4M,UAAU;UACnB,IAAMmE,IACJ/Q,EAAOU,MAAOC,IAAIX,EAAO4M,UACzB7L;UACF,KAAK,IAAM6L,KAAY2B;YAAqB,IAAA,iBAAAjS,QAAAC,IAAAC;cAC1C,KAAKuU,EAAenE;gBAClBjQ,KACE,wCAAwCiQ,uGACxC,IACAhQ;;;;AAIR;AACF,OOlMMkU,CACE/G,KAAK/J,QACL+J,KAAKwE,qBACLxE,KAAKnN;AAET;AACF;EAEAsE,UAAAA,CAAWjB,GAAmB+M;IAC5B,OAAO9L,WAAWjB,GAAW+M;AAC/B;EAEAhC,WAAAA,CAAYvI;IAIV,IAAI8F,KAAc9F,MAAS8F,EAAWW;MACpC,OAAOX,EAAWlH;WACb,IAAY,QAARoB,KAAgC,mBAATA;MAChC,OAAOA,KAAQ;WACV,KAAKA,EAAKwD;MACf,OAAO;WACF,IAAI8D,KAAK6B,UAAUnJ,EAAKwD;MAC7B,OAAOxD,EAAKwD;;IAGd,IAAIpH,IAAqB;IACzB,IAAIkL,KAAKjE,KAAKrD,EAAKwD;MACjBpH,IAAMkL,KAAKjE,KAAKrD,EAAKwD,YAAYxD,MAAS;WACrC,IAAe,QAAXA,EAAKuO;MACdnS,IAAM,GAAG4D,EAAKuO;WACT,IAAgB,QAAZvO,EAAKwO;MACdpS,IAAM,GAAG4D,EAAKwO;;IAGhB,IAAM/V,IAAWuH,EAAKwD;IAItB,QAFqB,MAAnB8D,KAAKmF,aACJnF,KAAKmF,aAAanF,KAAKmF,UAAUrS,IAAI3B,OACpB2D,IAAMA,IAAM,GAAG3D,KAAY2D;AACjD;EAEAqS,OAAAA,CACErM,GACA3E,GACAnC;IAEA,IAAM+D,IAAYiI,KAAKiB,YAAYnG;IACnC,IAAI/C,GAAW;MACb,IAAMP,IAAWL,WAAWhB,GAAOnC;MACnC,IAAMkO,IAAaR,WAAwB3J,GAAWP;MACtD,SAAmB5C,MAAfsN;QAA0B,OAAOA;;MACrC,IAAIkF,IAAY1F,SAAsB3J,GAAWP;MACjD,SAAkB5C,MAAdwS;QAAyBA,IAAYrG,WAAWf,MAAMoH;;MAC1D,OAAOA;AACT;AACF;EAEAC,UAAAA,CAAWvM,GAAgB3E,GAAgBnC;IACzC,IAAM+D,IAAYiI,KAAKiB,YAAYnG;IAQnC,IANEA,KACkB,mBAAXA,MACN3E,MACAnC,MACAgM,KAAKmH,QAAQrM,GAAQ;MAGtBiJ,eAAejJ,GAAQ;WAClB;MACL5I,UACE6F,GACA,iBADSxF,QAAAC,IAAAC,WACT,0HAEqB,mBAAXqI,IACHA,EAAgBoB,aACjBpB,IAAS,QACf,IAAA;MAGFgJ,iBAAiB/L,GAAW5B,GAAOnC;AACrC;AACF;EAEAgK,aAAAA,CAAclD;IACZ,IAAM/C,IAAYiI,KAAKiB,YAAYnG;IACnC,OAAO/C,IAAY2J,cAA2B3J,KAAa;AAC7D;EAEAuP,WAAAA,CACE/S,GACAmQ;IAEA,IAAMvD,IAAUoG,EAAchT,EAAM6M,OAAO7M,EAAM2K;IACjD,IAAM8C,IAAS0C,EAAQ1E,KAAKwH,UAAUrG;IACtC,IAAe,SAAXa;MACFkC,OAAOlE,MAAMmB,GAASa,QAAepN;;AAEzC;EAEA4S,SAAAA,CAAmCjT;IACjC,IAAM4M,IAAUoG,EAAchT,EAAM6M,OAAO7M,EAAM2K;IACjD,OAAOgC,OAAOlB,MAAMmB,QAASvM,QAAWA,GAAW8D;AACrD;EAEA+O,YAAAA,CACEpH,GACAvF,GACAoE,GACAwI;IAEA,OHA0BC,EAC5B1I,GACAmC,GACAtG,GACAoE,GACAwI;MAEA,IAAMvS,IAAYD,aAAakM;MAE/B,IAAIf;MACJ,IAAIqH;QAEF,MADArH,IAAWlL,EAAUuS,KACN;2BACbnV,QAAAC,IAAAC,YAAAG,KACE,0FAEE8U,IACA,0BACA3M,OAAOgB,KAAK5G,GAAWlD,KAAK,QAC5B,KACF,GACAgN,EAAMpM;UAGR,OAAO;AACT;aAIA,MADAwN,IAAWlL,EADG4F,OAAOgB,KAAK5G,GACC,MACZ;QACb,iBAAA5C,QAAAC,IAAAC,YAAAG,KACE,kIAEA,GACAqM,EAAMpM;QAGR,OAAO;AACT;MAGF,IAAM1B,IAAWkC,oBAAoBgN;MACrC,IAAsB,mBAAXvF,MAAwBA,EAAOoB;QACxCpB,EAAOoB,aAAa/K;;MACtB,IAAM4G,IAAYkH,EAAMgC,YAAYnG;MACpC,KAAK/C,GAAW;yBACdxF,QAAAC,IAAAC,YAAAG,KACE,gIAEEzB,IACA,MACF,GACA8N,EAAMpM;QAGR,OAAO;AACT;MAEA,IAA6B,iBAAzBN,QAAQC,IAAIC;QACdvB,cAAcC,GAAUkP;;MAG1B,IAAMzB,IAAMI,YACVC,GACAC,KAAa,IACb/J,GACAhE,GACA4G,QACAnD;MAGF,IAAM+N,IACJhB,cACE/C,GACA7G,GACArE,gBAAgB2M,IAChBqB,eACG;MAEP,IAA6B,iBAAzBnP,QAAQC,IAAIC;QACdzB;;MAGF,OAAO2R;AAAM,MGnFJgF,CACL3H,MACAqB,EAAehB,IACfvF,GACAoE,GACAwI;AAEJ;EAEAE,aAAAA,CACEvH,GACA3H,GACAwG,GACAwI;IDrG0BG,EAC5B5I,GACAmC,GACA1I,GACAwG,GACAwI;MAEA,IAAMvS,IAAYD,aAAakM;MAC/B,IAAIf;MACJ,IAAIqH;QAEF,MADArH,IAAWlL,EAAUuS,KACN;2BACbnV,QAAAC,IAAAC,YAAAG,KACE,2FAEE8U,IACA,0BACA3M,OAAOgB,KAAK5G,GAAWlD,KAAK,QAC5B,KACF,IACAgN,EAAMpM;UAGR,OAAO;AACT;aAIA,MADAwN,IAAWlL,EADG4F,OAAOgB,KAAK5G,GACC,MACZ;QACb,iBAAA5C,QAAAC,IAAAC,YAAAG,KACE,mIAEA,IACAqM,EAAMpM;QAGR,OAAO;AACT;MAGF,IAAM1B,IAAWkC,oBAAoBgN;MACrC,IAAMyH,IAAc;QAAE5L,YAAY/K;WAAauH;;MAC/C,IAAMX,IAAYkH,EAAMgC,YAAY6G;MACpC,KAAK/P;QACH,OAAOnF,iBAAPL,QAAAC,IAAAC,WAAOG,KACL,sIAEEzB,IACA,MACF,IACA8N,EAAMpM,eACP;;MAGH,IAA6B,iBAAzBN,QAAQC,IAAIC;QACdvB,cAAcC,GAAUkP;;MAG1B,IAAMzB,IAAMI,YACVC,GACAC,KAAa,IACb/J,GACAhE,GACA4G,QACAnD;MAGFuP,eAAevF,GAAK7G,GAAWrE,gBAAgB2M,IAAWyH;MAE1D,IAA6B,iBAAzBvV,QAAQC,IAAIC;QACdzB;;AACF,MCgCE6W,CACE7H,MACAqB,EAAehB,IACf3H,GACAwG,GACAwI;AAEJ;EAWArM,IAAAA,CACEP,GACA3E,MACG4R;IAEH,IAAM/T,IAAuB,MAAhB+T,EAAK/V,SAAe+V,EAAK,KAAK;IAC3C,IAAM1M,IAAuB,MAAhB0M,EAAK/V,SAAe+V,EAAK,KAAKA,EAAK;IAChD,IAAMhQ,IAAYiI,KAAKiB,YAAYnG;IACnC,IAAI/C;MACF2J,UACE3J,GACAZ,WAAWhB,GAAOnC,IAClB+M,WAAWf,MAAM3E;;AAGvB;;;AEvQK,IAAM2M,cAAcA,CACzBpW,GACAqW,MAEAC,EAActW,EAAUN,MAAMM,GAAW;KACpCA,EAAUuW;EACbF,MAAM;OACDrW,EAAUuW,QAAQF;OAClBA;;;;AAKF,IAAMG,kBAAkBA,CAC7BxW,GACAyW,MAEOH,EAActW,EAAUN,MAAMM,GAAW;KAC3CA,EAAUuW;EACbE;;;AC4CSC,IAAAA,gBAC4BpD,KACvC,EAAGqD,YAASC,WAAQC;EAClB,IAAMxJ,IAAQ,IAAIgG,MAASC;EAE3B,IAAIA,KAAQA,EAAKhL,SAAS;IACxB+E,EAAMvG,KAAKY,aAAY;IACvB4L,EAAKhL,QAAQwO,WAAWC,MAAK7K;MRqnBR8K,EACzBlQ,GACAwB,GACA4D;QAEA/E,cAAc,SAASL,GAAM;QAE7B,KAAK,IAAM5D,KAAOgJ,GAAS;UACzB,IAAMnM,IAAQmM,EAAQhJ;UACtB,SAAcF,MAAVjD,GAAqB;YACvB,KAAMoG,WAAEA,GAASP,UAAEA,KAAaK,mBAAmB/C;YACnD,IAAiB,QAAbnD,EAAM;cACR,SAAsCiD,MAAlC+H,SAAS5E,GAAWP;gBACtB6F,UAAUtF,GAAWP,GAAUG,KAAKC,MAAMjG,EAAM+F,MAAM;;mBAExD,SAAwC9C,MAApC8H,WAAW3E,GAAWP;cACxB0F,YAAYnF,GAAWP,GAAUG,KAAKC,MAAMjG;;AAElD;AACF;QAEA+G,EAAKwB,UAAUA;QACfxB,EAAKY,aAAY;QACjBQ;AAAgB,QQ3oBV8O,CAAY3J,EAAMvG,MAAMwM,EAAMhL,SAAU4D;MACxC,IAAIoH,EAAKhL,QAAS2O;QAAiB3D,EAAKhL,QAAS2O;;AAAiB;AAEtE;EAEA,IAAMC,IAAuD,IAAInL;EACjE,IAAMoL,IAA0C;EAChD,IAAMC,IAA2B,IAAIrL;EACrC,IAAMsL,IAAqB,IAAItL;EAC/B,IAAMuL,IAAoC,IAAIpY;EAC9C,IAAMqY,IAA+B,IAAIrY;EACzC,IAAMsY,IAA4B,IAAIzL;EAEtC,IAAI0L,IAAoC,IAAIvY;EAC5C,IAAIwY,IAAkC,IAAIxY;EAE1C,IAAMyY,8BACJ3H;IAEA,KAAK,IAAM4H,KAAO5H,EAAa6H;MAC7B,IAAIP,EAAoBpW,IAAI0W;QAAM,QAAO;;;IAC3C,QAAO;AAAK;EAGd,IAAME,2BAA2BA,CAC/BC,GACA/H;IAEA,IAAIA;MAEF,KAAK,IAAM4H,KAAO5H,EAAa6H,UAAU;QACvC,IAAM1N,IAAOqN,EAAKxS,IAAI4S;QACtB,IAAIzN;UAAM,KAAK,IAAMjH,KAAOiH,EAAK0N;YAAUE,EAAkB3W,IAAI8B;;;AACnE;;AACF;EAGF,IAAM8U,2BAA2BA,CAC/BhY,GACA+X,GACAzQ;IAGA,KAAK,IAAMpE,KAAO6U,EAAkBF;MAClC,IAAI3U,MAAQlD,EAAUkD,KAAK;QACzB,IAAM+U,IAAKb,EAAWpS,IAAI9B;QAC1B,IAAI+U,GAAI;UAEN,IAAuB,YAAnBjY,EAAUN;YAAkBgY,EAAoBtW,IAAI8B;;UACxD,IAAIgV,IAAwB;UAC5B,IAAIX,EAAiBrW,IAAIgC,IAAM;YAC7BqU,EAAiBxP,OAAO7E;YACxBgV,IAAS;AACX;UACAtB,EAAOuB,mBAAmB3B,gBAAgByB,GAAIC;AAChD;AACF;;IAGF,KAAK5Q,GAAc;MAGjB,IAAM8Q,IAAyBX;MAC/BA,IAAwBC;MACxB,IAAuB,YAAnB1X,EAAUN;QACZ+X,EAAsBrW,IAAIpB,EAAUkD;;OAErCwU,IAAsBU,GAAwB7L;AACjD;AAAA;EAIF,IAAM8L,4BAA6BrY;IACjC,IAAIgJ,KAAa;IACjB,IAAuB,YAAnBhJ,EAAUN,MAAkB;MAE9BmI,aAAawF,EAAMvG,MAAM9G,EAAUkD;MACnCkU,EAAWnQ,IAAIjH,EAAUkD,KAAKlD;AAChC,WAAO,IAAuB,eAAnBA,EAAUN,MAAqB;MAExC0X,EAAWrP,OAAO/H,EAAUkD;MAC5BmU,EAAQtP,OAAO/H,EAAUkD;MACzBuU,EAAsB1P,OAAO/H,EAAUkD;MAEvCwF,cAAc2E,EAAMvG,MAAM9G,EAAUkD;MACpC,OAAOlD;AACT,WAAO,IACc,eAAnBA,EAAUN,QAC0B,mBAApCM,EAAUuW,QAAQE,eAClB;MACAW,EAAWnQ,IAAIjH,EAAUkD,KAAKlD;MAE9BmH,cAAc,SAASkG,EAAMvG,MAAM9G,EAAUkD,MAAK,IAAM;MACxD,KAAM8M,cAAEA,KAAiBsC,OACvBjF,GACArN,QACAgD,QACAA;MAEFkF;MACA,IAAI8H,EAAaf,MAAM;QAErB,KAAK,IAAM2I,KAAO5H,EAAa6H;UAAUP,EAAoBlW,IAAIwW;;QAEjEV,EAA6BjQ,IAAIjH,EAAUkD,KAAK8M;QAEhD,IAAM+H,IAAgC,IAAI7Y;QAC1C4Y,yBAAyBC,GAAmB/H;QAC5CgI,yBAAyBhY,GAAW+X,IAAmB;QAEvD/O,KAAa;AACf;AACF;IAEA,OAAOsN,EACLtW,EAAUN,MACV;MACEwD,KAAKlD,EAAUkD;MACfsM,OAAOC,EAAezP,EAAUwP;MAChClC,WAAWtN,EAAUsN,YACjB5K,gBACES,iBAAiBnD,EAAUwP,QAC3BxP,EAAUsN,aAEZtN,EAAUsN;OAEhB;SAAKtN,EAAUuW;MAASvN;;AACzB;EAIH,IAAMyB,qBAAqBA,CAACwN,GAAejI;IACzC,KAAK,IAAM4H,KAAO5H,EAAa6H,UAAU;MACvC,IAAIS,IAASd,EAAKxS,IAAI4S;MACtB,KAAKU;QAAQd,EAAKvQ,IAAI2Q,GAAMU,IAAS,IAAIpZ;;MACzCoZ,EAAOlX,IAAI6W,EAAG/U;AAChB;AAAA;EAKF,IAAMqV,2BACJvY;IAEAmH,cAAc,QAAQkG,EAAMvG,WAAM9D,IAAW,IAAO;IACpD,IAAM+N,IAASzB,OACbjC,GACArN,GACAqX,EAAQrS,IAAIhF,EAAUkD,WACtBF;IAEFkF;IACA,IAAMsQ,IAA6BzH,EAAOjK,QACrCiK,EAAOrD,YAAYqD,EAAOpF,UACzB,QACA,YACF;IAEJ0L,EAAQpQ,IAAIjH,EAAUkD,KAAK6N,EAAOjK;IAClCsQ,EAAWnQ,IAAIjH,EAAUkD,KAAKlD;IAC9ByK,mBAAmBzK,GAAW+Q,EAAOf;IAErC,OAAO;MACLyI,SAASD;MACTxY;MACA8G,MAAMiK,EAAOjK;MACbkJ,cAAce,EAAOf;MACrBrE,SAASoF,EAAOpF;;AACjB;EAIH,IAAM+M,wBAAwBA,CAC5B3H,GACAgH;IAGA,IAAM/X,IACJoX,EAAWpS,IAAI+L,EAAO/Q,UAAUkD,QAAQ6N,EAAO/Q;IACjD,IAAuB,eAAnBA,EAAUN,MAAqB;MAEjC,IAAMsQ,IAAekH,EAA6BlS,IAAIhF,EAAUkD;MAChE4U,yBAAyBC,GAAmB/H;MAC5CkH,EAA6BnP,OAAO/H,EAAUkD;AAChD;IAEA,IAAuB,mBAAnBlD,EAAUN,QAA2BqR,EAAOpF;MAC9C9D,aAAawF,EAAMvG,MAAM9G,EAAUkD,MAAK;;IAE1C,IAAIyV;IACJ,IAAI7R,IAAoBiK,EAAOjK;IAC/B,IAAIA,GAAM;MAGRK,cAAc,SAASkG,EAAMvG,MAAM9G,EAAUkD,MAAK,IAAO;MACzD,IAAM0V,IAAoBtG,OACxBjF,GACArN,GACA8G,GACAiK,EAAOjQ,OACPkP;MACF9H;MACA4P,yBAAyBC,GAAmBa;MAC5C,IAAMjH,IACe,YAAnB3R,EAAUN,OAAmB2X,EAAQrS,IAAIhF,EAAUkD,OAAO;MAC5DiE,cACE,QACAkG,EAAMvG,MACN9G,EAAUkD,MACV,GACAyO,MAAa7K;MAEf,IAAM+R,IAAcvJ,OAClBjC,GACArN,GACA2R,KAAY7K,GACZiK,EAAOjQ;MAEToH;MACApB,IAAO+R,EAAY/R;MACnB,IAAuB,YAAnB9G,EAAUN,MAAkB;QAG9BoY,yBAAyBC,GADzBY,IAAoBE,EAAY7I;QAEhCqH,EAAQpQ,IAAIjH,EAAUkD,KAAK4D;AAC7B;AACF;MACE4B,cAAc2E,EAAMvG,MAAM9G,EAAUkD;;IAItC,IAAIyV;MACFlO,mBAAmBsG,EAAO/Q,WAAW2Y;;IAGvC,OAAO;MACL3Y;MACA8G;MACAhG,OAAOiQ,EAAOjQ;MACdgY,YAAY/H,EAAO+H;MACnBnN,SAASoF,EAAOpF;MAChBoN,OAAOhI,EAAOgI;;AACf;EAGH,OAAOC;IAEL,IAAMC,IAOJC,EADApQ,EAAIyP,yBAAJzP,CAJAqQ,GACElB,KACc,YAAZA,EAAGvY,QAAiD,mBAA7BuY,EAAG1B,QAAQE,eAFtC0C,CADAH;IASF,IAAMI,IAEJD,GACElB,KACc,YAAZA,EAAGvY,QAAiD,mBAA7BuY,EAAG1B,QAAQE,eAFtC0C,CADAH;IAQF,IAAMK,IASJvQ,GAAIwQ;MACF,iBAAA3Y,QAAAC,IAAAC,YAAAgW,EAAc;QACZpS,MAAM;QACNjE,SAAS;QACTR,WAAWsZ,EAAItZ;QAASuZ,QAAA;;MAE1B,OAAOnD,iBAAPzV,QAAAC,IAAAC,WAAOuV,YAAYkD,EAAItZ,WAAW;QAAEwY,cAAc;WAA/Bc,EAAItZ;AAAS,OANlC8I,CAPAqQ,GACEG,KACkB,WAAhBA,EAAIb,WACoC,iBAAxCa,EAAItZ,UAAUuW,QAAQE,kBACrBkB,4BAA4B2B,EAAItJ,kBAChCyH,EAAsBvW,IAAIoY,EAAItZ,UAAUkD,MAL7CiW,CADAF;IAoBF,IAAMO,IAOJ1Q,GAAKwQ;MACH,KAAM7C,eAAEA,KAAkB6C,EAAItZ,UAAUuW;MAIxC,IAAMkD,IACc,iBAAlBhD,MACC6C,EAAI3N,WACe,wBAAlB8K,KACmB,kBAAlBA,KACiB,cAAhB6C,EAAIb,YACHhB,EAAsBvW,IAAIoY,EAAItZ,UAAUkD;MAG/C,IAAM6V,IACc,iBAAlBtC,MACCgD,KACkB,cAAhBH,EAAIb,WACHhB,EAAsBvW,IAAIoY,EAAItZ,UAAUkD,URgN/B4D,IQ/MAuG,EAAMvG,MRgNxBc,gBAAgB1G,IADsBmG,IQ/MRiS,EAAItZ,UAAUkD,QRiNjD4D,EAAKa,gBAAgB9C,QAAQwC,MAAa;MAFpBqS,IAAC5S,GAAoBO;MQ7MnC,IAAM0J,IAA0B;QAC9B/Q,WAAWoW,iBAAFzV,QAAAC,IAAAC,WAAEuV,YAAYkD,EAAItZ,WAAW;UACpCwY,cAAcc,EAAIb;aADGa,EAAItZ;QAG3B8G,MAAMwS,EAAIxS;QACVhG,OAAOwY,EAAIxY;QACXgY,YAAYQ,EAAIR;QAChBC,OAAOA,MAAUO,EAAI3N;QACrBA,SAAS8N,KAAmBH,EAAI3N;;MAGlC,KAAK8N,WAEE,KAAK9B,4BAA4B2B,EAAItJ;QAC1C4G,EAAOuB,mBACL3B,gBACEY,EAAWpS,IAAIsU,EAAItZ,UAAUkD,QAAQoW,EAAItZ,WACzC;aAGC,IAAsB,wBAAlByW;QACTc,EAAiBnW,IAAIkY,EAAItZ,UAAUkD;;MAGrC,iBAAAvC,QAAAC,IAAAC,YAAAgW,EAAc;QACZpS,MAAM;QACNjE,SAAS;QACTR,WAAWsZ,EAAItZ;QACf8G,MAAM;UACJ/G,OAAOgR;;QACRwI,QAAA;;MAGH,OAAOxI;AAAM,OAtDfjI,CALAqQ,GACEG,KACkB,WAAhBA,EAAIb,WACoC,iBAAxCa,EAAItZ,UAAUuW,QAAQE,eAH1B0C,CADAF;IAkEF,IAAMU,IAGJhD,EADA7N,EAAIuP,0BAAJvP,CADA8Q,EAAM,EAACR,GAAcC;IAMvB,IAAMQ,IAKJ/Q,GAAIiI;MACF,IAAMgH,IAAgC,IAAI7Y;MAE1C,IAAM4a,IAAcpB,sBAAsB3H,GAAQgH;MAElDC,yBAAyBjH,EAAO/Q,WAAW+X,IAAmB;MAC9D,OAAO+B;AAAW,OANpBhR,CAHAqQ,GACEpI,MAAWmG,EAA6BhW,IAAI6P,EAAO/Q,UAAUkD,MAD/DiW,CADAQ;IAgBF,IAAMI,IAKJC,GAAUjJ;MAER,IADeoG,EAAqBjX,KAAK6Q,KAC5BmG,EAA6BjI;QACxC,OAAOgL;;MAGT,KAAK,IAAI3X,IAAI,GAAGA,IAAI6U,EAAqB/W,QAAQkC;QAC/CuF,aAAawF,EAAMvG,MAAMqQ,EAAqB7U,GAAGtC,UAAUkD;;MAG7DoU,EAAoB/K;MAEpB,IAAM8K,IAA6B;MACnC,IAAMU,IAAgC,IAAI7Y;MAE1C,IAAIgb;MACJ,OAAQA,IAAiB/C,EAAqBgD;QAC5C9C,EAAQnX,KACNwY,sBAAsBwB,GAAgBnC;;MAI1CC,yBAAyBjH,EAAO/Q,WAAW+X,IAAmB;MAE9D,OAAOqC,EAAU/C;AAAQ,OAxB3B2C,CAHAb,GAAOpI,KACLmG,EAA6BhW,IAAI6P,EAAO/Q,UAAUkD,MADpDiW,CADAQ;IAgCF,OAAOC,EAAM,EACXC,GACAE,GACAP;AACA;AACH;;ACvdL,IAAMa,IAAc;EAClB,cAAc;EACd,eAAe;EACf,gBAAgB;EAChB,qBAAqB;;;IA8CVC,kBACqBhH,KAChC3Q;EACE,KAAM2F,SAAEA,KAAYgL;EAEpB,IAAMiH,IACJjH,EAAKiH,mBACHzZ,KACAA,KACAA,EAAM0Z,iBACL1Z,EAAM2Z,aACgB,sBAAdC,cAAkD,MAArBA,UAAUC,UAC9C,kDAAkDxH,KAChDrS,EAAM0Z,aAAaha;EAG3B,IACE8H,KACAA,EAAQsS,YACRtS,EAAQuS,gBACRvS,EAAQwS,eACR;IACA,KAAQnE,SAASoE,GAAYnE,QAAEA,GAAMC,eAAEA,KAAkBlU;IACzD,KAAQ4W,QAAQyB,GAAW1M,MAAEA,KAAS2M;IACtC,IAAMC,IAA2B;IACjC,IAAIC,KAAgB;IACpB,IAAIC,KAAkB;IAEtB,IAAMC,iBAAiBA;MACrB,IAAIF,GAAe;QACjB,IAAMG,IAAgC;QACtC,KAAK,IAAIhZ,IAAI,GAAGA,IAAI4Y,EAAY9a,QAAQkC,KAAK;UAC3C,IAAMtC,IAAYkb,EAAY5Y;UAC9B,IAAuB,eAAnBtC,EAAUN;YACZ4b,EAASpb,KAAK;cACZsP,OAAO+L,EAAkBvb,EAAUwP;cACnClC,WAAWtN,EAAUsN;cACrBwL,YAAY9Y,EAAU8Y;;;AAG5B;QACAxQ,EAAQwS,cAAeQ;AACzB;AAAA;IAGF,IAAME,cAAetY;MACnB,KAAK,IAAIZ,IAAI4Y,EAAY9a,SAAS,GAAGkC,KAAK,GAAGA;QAC3C,IAAI4Y,EAAY5Y,GAAGY,QAAQA;UAAKgY,EAAYpT,OAAOxF,GAAG;;;AAAE;IAG5D,IAAMmZ,aAAaA;MACjB,KAAKL,GAAiB;QACpB,IAAMM,IAAO,IAAIxc;QACjBkc,KAAkB;QAClB,KAAK,IAAI9Y,IAAI,GAAGA,IAAI4Y,EAAY9a,QAAQkC,KAAK;UAC3C,IAAMtC,IAAYkb,EAAY5Y;UAC9B,IAAuB,eAAnBtC,EAAUN,SAAwBgc,EAAKxa,IAAIlB,EAAUkD,MAAM;YAC7DwY,EAAKta,IAAIpB,EAAUkD;YACnB,IAAuB,mBAAnBlD,EAAUN,MAAyB;cACrC4O,EAAKgI,EAAc,YAAYtW;cAC/B,IAAI2b,IAAgC;cACpC,KAAK,IAAIrZ,IAAI,GAAGA,IAAI4Y,EAAY9a,QAAQkC,KAAK;gBAC3C,KAAMmU,eAAEA,KAAkByE,EAAY5Y,GAAGiU;gBACzC,IAAI8D,EAAY5D,KAAiB4D,EAAYsB;kBAC3CA,IAAiBlF;;AACrB;cACAnI,EAAKkI,gBAAgBxW,GAAW2b;AAClC;cACErN,EAAKkI,gBAAgBxW,GAAW;;AAEpC;AACF;QACAob,KAAkB;QAClBF,EAAY9a,SAAS;QACrBib;AACF;AAAA;IAwBF,IAAMO,IAAgBlF,cAAc;SAC/BpD;MACHhL,SAAS;WACJA;QACHwO,QAAAA;UACE,IAAM+E,IAAUvT,EAAQwO;UACxB,OAAO;YACL,UAAMC,CAAK+E;cACT,IAAMC,UAAkBzT,EAAQuS;cAChC,KAAK,IAAIvY,IAAI,GAAGyZ,KAAazZ,IAAIyZ,EAAU3b,QAAQkC;gBACjD4Y,EAAYhb,KACV0W,EAAOoF,uBACL,YACArG,EAAcoG,EAAUzZ,GAAGkN,OAAOuM,EAAUzZ,GAAGgL,YAC/CyO,EAAUzZ,GAAGwW;;cAInBgD,QAAiBD;cACjBvT,EAAQsS,SAAUa;cAClBN,KAAgB;cAChBM;AACF;;AAEJ;;MAxBkB/E,CA0BnB;MACDE;MACAC;MACAF,SAlD0BsF,KAiBxB/C,EAdAC,GAAOG;QACL,IACE6B,KACuB,eAAvB7B,EAAItZ,UAAUN,QACd4Z,EAAItZ,UAAUuW,QAAQvN,cACtBuR,EAAejB,EAAIxY,OAAOwY,IAC1B;UACA4B,EAAYhb,KAAKoZ,EAAItZ;UACrBqb;UACA,QAAO;AACT;QAEA,QAAO;AAAI,SAZblC,CADA4B,EAAakB;;IAmDjB,OAAOjD;MACL,IAAMkD,IAAiBtC,EAAM,EAC3BoB,GAGEmB,GAAOnc;QACL,IAAuB,YAAnBA,EAAUN,SAAqByb;UACjCD,EAAYhb,KAAKF;eACZ,IAAuB,eAAnBA,EAAUN;UACnB8b,YAAYxb,EAAUkD;;AACxB,SALFiZ,CADAnD;MAWJ,OAEEG,GAAOG;QACL,IAA2B,YAAvBA,EAAItZ,UAAUN;UAChB,IAAI6a,EAAejB,EAAIxY,OAAOwY,IAAM;YAClChL,EAAKkI,gBAAgB8C,EAAItZ,WAAW;YACpCkb,EAAYhb,KAAKoZ,EAAItZ;YACrB,QAAO;AACT,iBAAO,KAAKmb;YACVK,YAAYlC,EAAItZ,UAAUkD;;;QAG9B,QAAO;AAAI,SAVbiW,CADAyC,EAAcM;AAAe;AAenC;EAEA,OAAOxF,cAAcpD,EAAdoD,CAAoB/T;AAAM;;"}